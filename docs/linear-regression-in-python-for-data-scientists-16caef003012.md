# Python ä¸­çš„çº¿æ€§å›å½’åŸºç¡€

> åŸæ–‡ï¼š<https://towardsdatascience.com/linear-regression-in-python-for-data-scientists-16caef003012>

## UCL æ•°æ®ç§‘å­¦å­¦ä¼šç ”è®¨ä¼š 10:ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ã€æ•°æ®æ¢ç´¢ã€Scikit å­¦ä¹ å®æ–½å’Œå¤šå…ƒçº¿æ€§å›å½’

![](img/7233478f2e11edd1625e1a622dcd7845.png)

è‰¾è¨å…‹Â·å²å¯†æ–¯åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

ä»Šå¹´ï¼Œä½œä¸º UCL æ•°æ®ç§‘å­¦åä¼šçš„ç§‘å­¦è´Ÿè´£äººï¼Œè¯¥åä¼šçš„ç›®æ ‡æ˜¯åœ¨æ•´ä¸ªå­¦å¹´ä¸¾åŠä¸€ç³»åˆ— 20 åœºç ”è®¨ä¼šï¼Œæ¶µç›–çš„ä¸»é¢˜åŒ…æ‹¬ Pythonã€æ•°æ®ç§‘å­¦å®¶å·¥å…·åŒ…å’Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„ä»‹ç»ã€‚æ¯ä¸€ç¯‡æ–‡ç« çš„ç›®æ ‡éƒ½æ˜¯åˆ›å»ºä¸€ç³»åˆ—çš„å°åšå®¢ï¼Œè¿™äº›å°åšå®¢å°†æ¦‚è¿°è¦ç‚¹ï¼Œå¹¶ä¸ºä»»ä½•å¸Œæœ›è·Ÿè¿›çš„äººæä¾›å®Œæ•´ç ”è®¨ä¼šçš„é“¾æ¥ã€‚æ‰€æœ‰è¿™äº›éƒ½å¯ä»¥åœ¨æˆ‘ä»¬çš„ [GitHub](https://github.com/UCL-DSS) èµ„æºåº“ä¸­æ‰¾åˆ°ï¼Œè¯¥èµ„æºåº“å°†åœ¨å…¨å¹´æ›´æ–°æ–°çš„ç ”è®¨ä¼šå’ŒæŒ‘æˆ˜ã€‚

æœ¬ç³»åˆ—çš„ç¬¬åæ¬¡ç ”è®¨ä¼šä»‹ç»äº† Python ä¸­çš„çº¿æ€§å›å½’ï¼Œå¹¶ä»‹ç»äº†æˆ‘ä»¬çš„æ•°æ®ç§‘å­¦ä¸ Python ç ”è®¨ä¼šç³»åˆ—ã€‚è¿™ä¸ªç‰¹å®šçš„ç ”è®¨ä¼šå°†æ¶µç›–ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Œæ¢ç´¢æ•°æ®ï¼Œå®æ–½æ¨¡å‹å’Œæ¨¡å‹è¯„ä¼°ã€‚è™½ç„¶äº®ç‚¹å°†åœ¨è¿™ç¯‡åšæ–‡ä¸­å‘ˆç°ï¼Œä½†å®Œæ•´çš„ç ”è®¨ä¼šå¯ä»¥åœ¨æˆ‘ä»¬çš„ GitHub è´¦æˆ·[è¿™é‡Œ](https://github.com/UCL-DSS/linear-regression-workshop)æ‰¾åˆ°ã€‚

å¦‚æœæ‚¨é”™è¿‡äº†æˆ‘ä»¬ä¹‹å‰çš„ä»»ä½•ç ”è®¨ä¼šï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°:

[](/an-introduction-to-sql-for-data-scientists-e3bb539decdf)  [](/git-and-github-basics-for-data-scientists-b9fd96f8a02a)  [](/an-introduction-to-plotting-with-matplotlib-in-python-6d983b9ba081)  

# ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Ÿ

çº¿æ€§å›å½’æ˜¯ä¸€ç§ç»Ÿè®¡æ–¹æ³•ï¼Œç”¨äºæ¨¡æ‹Ÿä¸¤ä¸ªæˆ–æ›´å¤šæ•°é‡ä¹‹é—´çš„ç›¸å…³æ€§æˆ–å…³ç³»ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç°æœ‰çš„å…³ç³»ï¼Œæˆ–è€…èƒ½å¤Ÿé¢„æµ‹æˆ‘ä»¬ç›®å‰æ²¡æœ‰æ•°æ®çš„ç‚¹çš„è¡Œä¸ºã€‚

å¯¹äºä¸€ç»„æ•°æ®ç‚¹ x å’Œ yï¼Œæˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬è¦å»ºæ¨¡çš„çº¿çš„æ–¹ç¨‹å†™æˆ:

> *y(x) = mx + c*

å…¶ä¸­ y(x)æ˜¯æ¨¡å‹çš„é¢„æµ‹ y å€¼ï¼Œæ¢¯åº¦(m)å’Œ y æˆªè·(c)ç§°ä¸ºæ‹Ÿåˆå‚æ•°ã€‚é€šè¿‡ä½¿ç”¨çº¿æ€§å›å½’æ–¹æ³•(ä¹Ÿç§°ä¸ºæœ€å°äºŒä¹˜æ‹Ÿåˆ)ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä¸¤ä¸ªå‚æ•°çš„å€¼ï¼Œå¹¶ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿ï¼Œä»¥å®ç°æˆ‘ä»¬æ›´å¥½åœ°ç†è§£å…³ç³»æˆ–æ‰¾åˆ°æœªçŸ¥ç‚¹çš„ä¼°è®¡å€¼çš„ç›®æ ‡ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¿…é¡»èƒ½å¤Ÿè®¡ç®—æ–œç‡(m)å’Œæˆªè·(c ),ä»¥ç»™å‡ºæ•°æ®çš„æœ€ä½³æ‹Ÿåˆçº¿ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ç­‰å¼æ¥å®ç°:

![](img/7ccd9a74ce00d565d5275b88fee29389.png)

ä½œè€…å›¾ç‰‡

å…¶ä¸­ x å’Œ y ä»£è¡¨æ•°æ®çš„å¹³å‡å€¼ã€‚ç„¶è€Œï¼Œè¿™é€šè¿‡å·²ç»å®ç°çš„åº“å˜å¾—ç®€å•ï¼Œä¾‹å¦‚ Scikit-Learn å’Œ Statsmodels Apiï¼Œå®ƒä»¬å…·æœ‰å†…ç½®çš„çº¿æ€§å›å½’åŠŸèƒ½ã€‚æˆ‘ä»¬å°†é¦–å…ˆå±•ç¤ºå¦‚ä½•åœ¨ Python ä¸­å®ç°è¿™äº›å…¬å¼ï¼Œç„¶åå±•ç¤ºå¦‚ä½•ä½¿ç”¨ Scikit Learn åº“æ‰§è¡Œæ›´å¤æ‚çš„åˆ†æã€‚

# æ•°æ®æ¢ç´¢

æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®æ˜¯ä¸€ä¸ªç”Ÿæˆçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬é¦–å…ˆåªå…³æ³¨ X å’Œ Y ä¸¤ä¸ªå˜é‡æ¥æ‰§è¡Œç®€å•çš„çº¿æ€§å›å½’ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ç»˜åˆ¶æ•°æ®ï¼Œä»¥äº†è§£æˆ‘ä»¬å¯èƒ½æœŸæœ›çœ‹åˆ°çš„å…³ç³»:

```
# Generates data frame from csv file
df = pd.read_csv("RegressionData.csv")# Turning the columns into arrays
x = df["x"].values
y = df["y"].values# Plots the graph from the above data
plt.figure()
plt.grid(True)
plt.plot(x,y,'r.')
```

![](img/52713f93822fc2b846f5a7569145dbf7.png)

ä½œè€…å›¾ç‰‡

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒX å’Œ Y å˜é‡æ˜¾ç¤ºäº†ä¸€ç§å…³ç³»ï¼ŒY å˜é‡ä¼¼ä¹éšç€ X çš„å˜åŒ–è€Œçº¿æ€§å˜åŒ–ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°è¯•ç”¨çº¿æ€§æ‹Ÿåˆæ¥æ¨¡æ‹Ÿï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨çº¿æ€§å›å½’ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸Šé¢è¯¦è¿°çš„ç­‰å¼ï¼Œå°è¯•æ ¹æ®æ•°æ®è®¡ç®—æ¢¯åº¦å’Œ y è½´æˆªè·ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
# calculating the means of the x and y data
mean_x = np.mean(x) 
mean_y = np.mean(y)# calculating the slope
slope = np.sum((y - mean_y)*x) / np.sum((x - mean_x)*x) 
print ("Gradient:", slope)# calculating the intercept
intercept = mean_y - slope*mean_x 
print ("Intercept", intercept)#out:
Gradient: 0.9773554490236186
Intercept 0.33323427076670953
```

ç„¶åæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥ç»˜åˆ¶æ•°æ®çš„æœ€ä½³æ‹Ÿåˆçº¿:

```
x_max = max(x)
plt.figure("") # start a new figure
plt.grid(True) # add a grid
# generate two points for the fitted line
x_points = np.linspace(0, x_max*2., 2) 
y_points = slope*x_points + intercept
plt.plot(x, y,'r.') # plotting data as points
plt.line = plt.plot(x_points, y_points, 'b-') #plotting the line of best fit
# setting limits for the axes
plt.xlim(-10,110) 
plt.ylim(-10,110)
```

![](img/4781197e0db313e209d3c7f87531c8d7.png)

ä½œè€…å›¾ç‰‡

ç”±æ­¤æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬åœ¨ç¬¬ä¸€ä¸ªæ•°æ®å›¾ä¸­ç¡®å®šçš„é¢„æœŸçº¿æ€§å…³ç³»ã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ï¼Œæˆªè·çº¦ä¸º 0.3ï¼Œæ–œç‡æ¥è¿‘ 1ï¼Œå‡ ä¹æ˜¯å•ä½çº¿æ€§å…³ç³»ã€‚

# Scikit å­¦ä¹ å®ç°

ç„¶è€Œï¼Œæ›´æœ‰æ•ˆå’Œæœ‰ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨ Python çš„ Scikit å­¦ä¹ åº“ï¼Œè¯¥åº“å…·æœ‰æ›´æ·±å…¥è¯„ä¼°çº¿æ€§å›å½’çš„å¹¿æ³›åŠŸèƒ½ã€‚è™½ç„¶æˆ‘ä»¬å·²ç»è®¡ç®—äº†æ¢¯åº¦`m`å’Œæˆªè·`c`ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Scikit Learn æ¥å®Œæˆè¿™é¡¹å·¥ä½œï¼Œç„¶åä½¿ç”¨è¿™ä¸ªåº“æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹ä»å½“å‰æ ¼å¼é‡æ–°è°ƒæ•´ä¸ºæ•°ç»„ï¼Œç„¶åå°†æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ã€‚æˆ‘ä»¬è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹å¦‚ä½•é€‚åº”çœ‹ä¸è§çš„æ•°æ®ï¼Œè€Œä¸æ˜¯è®©å®ƒè¿‡åº¦é€‚åº”æˆ‘ä»¬æ‰€æœ‰çš„æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶æƒ³è±¡å®ƒæ˜¯ä»€ä¹ˆæ ·å­:

```
# Independant variable or features
X = x.reshape(-1,1)# Dependant variable or labels
y = y.reshape(-1,1)# Seperates the data into test and training sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)# Plotting the training and testing splits
plt.scatter(X_train, y_train, label = "Training Data", color = 'r')
plt.scatter(X_test, y_test, label = "Testing Data", color = 'b')
plt.legend()
plt.grid("True")
plt.title("Test/Train Split")
plt.show()
```

![](img/56744ab28e18a0734ec605d08a2c772e.png)

ä½œè€…å›¾ç‰‡

è¿™è¡¨æ˜ï¼Œæˆ‘ä»¬å·²ç»å°†å¤§éƒ¨åˆ†æ•°æ®(80%)ä½œä¸ºæ¨¡å‹å°†è¦è®­ç»ƒçš„æ•°æ®ï¼ŒåŒæ—¶ä¿ç•™äº†å¯ç”¨äºè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„å°‘æ•°æ•°æ®(20%)ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå¯ä»¥çœ‹åˆ°ï¼Œæµ‹è¯•æ•°æ®è™½ç„¶å¾ˆå°ï¼Œä½†è¦†ç›–äº†å¤§èŒƒå›´çš„æ•´ä½“æ•°æ®ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºå¾ˆå¥½çš„æµ‹è¯•æ•°æ®æ¥æŸ¥çœ‹æ¨¡å‹çš„è¡¨ç°ã€‚

æ—¢ç„¶æˆ‘ä»¬å·²ç»å°†æ•°æ®åˆ†ä¸ºæµ‹è¯•å’Œè®­ç»ƒæ•°æ®é›†ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ç°çº¿æ€§å›å½’æ¨¡å‹äº†ã€‚ä¸ºäº†é€šè¿‡ Scikit Learn å®ç°çº¿æ€§å›å½’ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡è°ƒç”¨`LinearRegression`å‡½æ•°æ¥å®šä¹‰ä¸€ä¸ª`regressor`å˜é‡ã€‚ç„¶åæˆ‘ä»¬ä¼ é€’`regressor.fit(X_train, y_train)`ï¼Œå®ƒå°†è®­ç»ƒæ•°æ®ä¼ é€’ç»™å›å½’ï¼Œä»¥ä¾¿è®­ç»ƒå®ƒã€‚

```
# Defining our regressor
regressor = LinearRegression()# Train the regressor
fit = regressor.fit(X_train, y_train)
```

å’Œä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯ä»æˆ‘ä»¬çš„æ•°æ®ä¸­æå–çš„æ¢¯åº¦å’Œæˆªè·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨æˆ‘ä»¬è®­ç»ƒçš„å›å½’å¯¹è±¡çš„å±æ€§`.coef_`å’Œ`.intercept_`æ¥æå–è¿™äº›æ•°æ®ã€‚ç”±æ­¤æˆ‘ä»¬å¯ä»¥å¾—åˆ°:

```
# Returns gradient and intercept
print("Gradient:",fit.coef_)
print("Intercept:",fit.intercept_)#out
Gradient: [[0.98952479]]
Intercept: [-0.1328508]
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè™½ç„¶æ¢¯åº¦ä¸ä¹‹å‰çš„ç›¸ä¼¼ï¼Œä½†æˆªè·ä¸åŒã€‚è¿™ä¸»è¦æ˜¯å› ä¸ºæˆ‘ä»¬å°†æ•°æ®åˆ†æˆäº†è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬ä¸æ˜¯åœ¨å¤„ç†æ•´ä¸ªæ•°æ®é›†ã€‚

è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ã€‚ä¸ºæ­¤ï¼Œåƒä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬æƒ³æå–æœ€ä½³æ‹Ÿåˆçº¿ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`regressor.predict(X_test)`æ–¹æ³•ï¼Œè€Œä¸æ˜¯åƒä»¥å‰ä¸€æ ·è®¡ç®—ç›´çº¿ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è¿™æ ·å®ç°:

```
# Predicted values 
y_pred = regressor.predict(X_test)# Plot of the data with the line of best fit
plt.plot(X_test,y_pred)
plt.plot(x,y, "rx")
plt.grid(True)
```

![](img/e4a3b29235ecce9f2d627ff8728bf10e.png)

ä½œè€…å›¾ç‰‡

ç„¶åï¼Œé€šè¿‡åˆ›å»ºä¸€ä¸ªæ•°æ®æ¡†æ¶ï¼Œå°†é¢„æµ‹å€¼ä¸å®é™…æµ‹è¯•ç»“æœè¿›è¡Œæ¯”è¾ƒï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
# Converts predicted values and test values to a data frame
df = pd.DataFrame({"Predicted": y_pred[:,0], "Actual": y_test[:,0]})
df
```

![](img/c588b3269b70ed19482de792c134b00d.png)

ä½œè€…å›¾ç‰‡

ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼ é€’`regressor.score(X_test, y_test)`ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æä¾›ä¸€ä¸ªåˆ†æ•°ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œè¿™æ˜¯å›å½’å™¨æ²¡æœ‰è®­ç»ƒè¿‡çš„æ•°æ®ï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥ä¸ºæ¨¡å‹åœ¨æ•°æ®æœ¬èº«ä¸Šçš„è¡¨ç°æä¾›è‰¯å¥½çš„åŸºç¡€ã€‚è¿™æ˜¯ R åˆ†æ•°ï¼Œå®ƒæ˜¾ç¤ºäº†æ¨¡å‹æ•è·çš„ç›®æ ‡å˜é‡çš„å˜åŒ–é‡ã€‚è¿™æ–¹é¢çš„æœ€ä½³å¾—åˆ†ä¸º 1ï¼Œå…¶ä¸­å¤§äº 0.8 é€šå¸¸è¢«è§†ä¸ºæ¨¡å‹æ‹Ÿåˆè‰¯å¥½çš„æŒ‡æ ‡ï¼Œè€Œ 0 åˆ™è¢«è§†ä¸ºæœ€å·®çš„æ€§èƒ½ã€‚

å¯¹äºæˆ‘ä»¬å½“å‰çš„æ¨¡å‹ï¼Œç»“æœå¦‚ä¸‹æ‰€ç¤º:

```
# Determines a score for our model
score = regressor.score(X_test, y_test)
print(score)#out:
0.9763002831471521
```

è¿™è¡¨æ˜æˆ‘ä»¬æœ‰ä¸€ä¸ªå¾ˆå¥½çš„æ¨¡å‹ã€‚

# Scikit å­¦ä¹ å¤šå…ƒçº¿æ€§å›å½’

æˆ‘ä»¬ä¸Šé¢ä½¿ç”¨çš„ä¾‹å­åªæ¶‰åŠä¸¤ä¸ªå˜é‡ï¼Œè¿™åœ¨æˆ‘ä»¬è‡ªå·±çš„ä»£ç ä¸­ç›¸å¯¹å®¹æ˜“å®ç°ï¼Œä½†åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œå•ç‹¬æµ‹é‡æˆ–ä½¿ç”¨ä¸€ä¸ªç‰¹å¾æˆ–ç‹¬ç«‹å˜é‡æ˜¯æä¸å¯èƒ½çš„ã€‚è¿™ä½¿å¾—å®ç°å’Œç­‰å¼æ›´åŠ å¤æ‚ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä¾é  Scikit äº†è§£æ›´å¤šæ¥å®ç°è¿™ä¸€ç‚¹ã€‚

æˆ‘ä»¬æœ‰å¤šä¸ªç‹¬ç«‹å˜é‡çš„æ–°æ–¹ç¨‹é‡‡ç”¨ä»¥ä¸‹å½¢å¼

![](img/e87e1209655140ca945e9a4c53e35307.png)

è¿™æ„å‘³ç€å®é™…ä¸Šæˆ‘ä»¬æœ‰å¤šä¸ªæ¢¯åº¦å€¼ï¼Œè¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ğœ–é¡¹ï¼Œè¿™å°±æ˜¯è¯¯å·®ã€‚å®é™…ä¸Šï¼Œğœ–è€ƒè™‘äº†ä»»ä½•å¯èƒ½ä¸é€‚åˆçº¿æ€§æ¨¡å‹çš„æ½œåœ¨ç‚¹ã€‚

ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ç”Ÿæˆçš„å¹¿å‘Šæ•°æ®åŠå…¶å¯¹é”€å”®çš„å½±å“ã€‚è¿™é‡Œï¼Œè‡ªå˜é‡ç”±`TV`ã€`Radio`å’Œ`Newspaper`åˆ—ç»™å‡ºï¼Œè€Œ`Sales`æ˜¯æˆ‘ä»¬çš„è‡ªå˜é‡ã€‚è¿™æ–¹é¢çš„æ•°æ®å¦‚ä¸‹:

```
# Converts advertising csv to a data frame
df = pd.read_csv("advertising.csv")
df
```

![](img/ae7fb87d7d3b9d5374326a2d47b1a7ad.png)

ä½œè€…å›¾ç‰‡

ç„¶ååœ¨ Scikit Learn library ä¸‹åº”ç”¨çº¿æ€§å›å½’ç®—æ³•çš„è¿‡ç¨‹é‡‡å–äº†ç±»ä¼¼çš„è·¯å¾„ï¼Œæˆ‘ä»¬è·å– X å’Œ Y å˜é‡ï¼Œå¯¹å…¶è¿›è¡Œæ•´å½¢ï¼Œåˆ†æˆè®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼Œå®æ–½æ¨¡å‹ï¼Œé¢„æµ‹æœªçŸ¥æ•°æ®ï¼Œç„¶åæå–åˆ†æ•°ã€‚è¿™éƒ½å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®ç°:

```
# Independent variables
X = df.drop("Sales",axis=1)# Dependent variable
y = df["Sales"].values.reshape(-1,1)# Splitting into test and training data
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)# Defining regressor
regressor = LinearRegression()# Training our regressor
fit = regressor.fit(X_train,y_train)# Predicting values
y_pred = fit.predict(X_test)# Scoring our regressor
fit.score(X_test,y_test)#out:
0.9174440089730509
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹é€šå¸¸ä¸æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®éå¸¸å»åˆï¼Œå¾—åˆ†ä¸º 0.917ï¼Œå®æ–½ç›¸å¯¹ç®€å•ã€‚

å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä½¿ç”¨ Scikit Learn åº“ä¸­å†…ç½®çš„å…¶ä»–æŒ‡æ ‡æˆ–è¯„ä¼°æ–¹æ³•ä»¥æ›´è¯¦ç»†çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè¯„ä¼°ï¼Œæ›´å¤šä¿¡æ¯å¯åœ¨æ­¤å¤„æ‰¾åˆ°ã€‚æ­¤å¤–ï¼Œé™¤äº† Scikit Learn ä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨ Statsmodels Api åº“ï¼Œè¯¥åº“ä¸ºæ‚¨å†…ç½®çš„å›å½’å®ç°æä¾›äº†æ›´è¯¦ç»†çš„æ‘˜è¦ï¼Œå¯ç”¨äºè¯„ä¼°æ‚¨çš„æ¨¡å‹ï¼Œå…¶å®ç°å¯åœ¨[æ­¤å¤„](https://www.statsmodels.org/stable/regression.html)æ‰¾åˆ°ã€‚

å¦‚æœæ‚¨æƒ³äº†è§£æˆ‘ä»¬åä¼šçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶å…³æ³¨æˆ‘ä»¬çš„ç¤¾äº¤ç½‘ç«™:

https://www.facebook.com/ucldata[è„¸ä¹¦](https://www.facebook.com/ucldata)

insta gram:[https://www.instagram.com/ucl.datasci/](https://www.instagram.com/ucl.datasci/)

é¢†è‹±:[https://www.linkedin.com/company/ucldata/](https://www.linkedin.com/company/ucldata/)

å¦‚æœä½ æƒ³äº†è§£ UCL æ•°æ®ç§‘å­¦åä¼šå’Œå…¶ä»–ä¼˜ç§€ä½œè€…çš„æœ€æ–°ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨æˆ‘ä¸‹é¢çš„æ¨èä»£ç æ³¨å†Œ mediumã€‚

[](https://philip-wilkinson.medium.com/membership)  

æˆ–è€…çœ‹çœ‹æˆ‘å†™çš„å…¶ä»–æ•…äº‹:

[](/bias-and-variance-for-machine-learning-in-3-minutes-4e5770e4bf1b)  [](/an-introduction-to-object-oriented-programming-for-data-scientists-879106d90d89)  [](/univariate-outlier-detection-in-python-40b621295bc5) 