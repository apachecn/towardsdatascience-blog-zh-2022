# å¼ é‡æµå›¾åƒåˆ†ç±»ç®€ä»‹(äºŒ)

> åŸæ–‡ï¼š<https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef>

## Python è®¡ç®—æœºè§†è§‰åˆå­¦è€…å®ç”¨æŒ‡å—

[åœ¨](/introduction-to-image-classification-with-tensorflow-part-1-381d0a373b8f)ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬åœ¨åŒ…å«æ‰‹å†™æ•°å­—é»‘ç™½å›¾åƒçš„ MNIST æ•°æ®é›†ä¸Šæ„å»ºäº†åŸºæœ¬çš„å›¾åƒåˆ†ç±»æ¨¡å‹ã€‚è¿™äº›æ•°æ®å¾ˆå®¹æ˜“é€šè¿‡ TensorFlow è·å¾—ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œç°å®ç”Ÿæ´»ä¸­çš„å›¾åƒæ˜¯ä¸°å¯Œå¤šå½©çš„ï¼Œæ•°æ®é€šå¸¸ä¸å®¹æ˜“è·å¾—ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»ƒä¹ è‡ªå·±åŠ è½½å›¾åƒæ•°æ®ï¼Œå¹¶åœ¨å½©è‰²å›¾åƒä¸Šå»ºç«‹æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†å­¦ä¹ ä¸€ç‚¹å…³äºè¿ç§»å­¦ä¹ çš„çŸ¥è¯†ã€‚

![](img/a53ab1189ff9618dc9710a08e4c593ee.png)

ç…§ç‰‡ç”± [Mae Mu](https://unsplash.com/@picoftasty?utm_source=medium&utm_medium=referral) åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

# ğŸ“¦æ•°æ®

æˆ‘ä»¬å°†ä½¿ç”¨ä»è”¬èœå†œåœºå’Œå¸‚åœºæ”¶é›†çš„ 15 ç§è”¬èœçš„å›¾åƒã€‚å…³äºè¯¥æ•°æ®é›†çš„å®˜æ–¹è®ºæ–‡å¯åœ¨[è¿™é‡Œ](https://www.researchgate.net/publication/352846889_DCNN-Based_Vegetable_Image_Classification_Using_Transfer_Learning_A_Comparative_Study)è·å¾—ã€‚æ•°æ®é›†å¯é€šè¿‡ [CC BY-SA 4.0 è®¸å¯è¯](https://creativecommons.org/licenses/by-sa/4.0/)è·å¾—ã€‚

å¦‚æœæ‚¨æƒ³è·Ÿéšæ•™ç¨‹ï¼Œè¯·ä»[è”¬èœå›¾åƒæ•°æ®é›†| Kaggle](https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset) ä¸‹è½½æ•°æ®é›†ï¼Œå¹¶å°†æ•°æ®ä¿å­˜åœ¨ä¸æ‚¨çš„ç¬”è®°æœ¬ä½äºåŒä¸€ç›®å½•çš„åä¸º`data`çš„æ–‡ä»¶å¤¹ä¸­ï¼Œå¹¶å°†`validation`å­ç›®å½•é‡å‘½åä¸º`valid`ã€‚å®Œæˆåï¼Œæ‚¨çš„å·¥ä½œç›®å½•å°†å¦‚ä¸‹æ‰€ç¤º:

```
image_classification
â”œâ”€â”€ *.ipynb
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ train
â”‚   â”‚   â”œâ”€â”€ class 1
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ class n
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
â”‚   â”œâ”€â”€ valid
â”‚   â”‚   â”œâ”€â”€ class 1
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ class n
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
â”‚   â”œâ”€â”€ test
â”‚   â”‚   â”œâ”€â”€ class 1
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ class n
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg
```

è¿™æ˜¯ç»„ç»‡å›¾åƒçš„å®Œç¾æ ¼å¼ã€‚æ¯ä¸ªåˆ†åŒºæ•°æ®é›†å°†ä¸åŒç±»åˆ«çš„å›¾åƒä¿å­˜åœ¨ä»¥ç±»åˆ«å‘½åçš„å•ç‹¬å­ç›®å½•ä¸­ã€‚

æˆ‘ä»¬ç°åœ¨å°†åŠ è½½å›¾åƒåº“å¹¶æ£€æŸ¥å›¾åƒæ€»æ•°:

```
import pathlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
sns.set(style='darkgrid', context='talk')import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Input, Rescaling, Conv2D, 
                                     MaxPooling2D, Flatten, Dense)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.resnet import ResNet50images = [*pathlib.Path('data').glob('**/*.jpg')]
print(f"There are {len(images)} images.")
```

![](img/aca20f14fa4f41f3d27e965d1129f026.png)

æˆ‘ä»¬æ€»å…±æœ‰ 21K å¼ å›¾ç‰‡ã€‚è®©æˆ‘ä»¬ç¡®è®¤åœ¨åˆ†åŒºçš„æ•°æ®é›†ä¸­ç±»åæ˜¯ç›¸åŒçš„:

```
train_classes = [item.name for item in 
                 pathlib.Path('data/train').glob('*')]
valid_classes = [item.name for item in 
                 pathlib.Path('data/valid').glob('*')]
test_classes = [item.name for item in 
                pathlib.Path('data/test').glob('*')]if train_classes==valid_classes==test_classes:
    print("All datasets have the same classes.")
print(f"There are total of {len(train_classes)} classes.")
```

![](img/ab717ad5876c3a29929b55fd1ec8f353.png)

å¤ªæ£’äº†ï¼Œæ•°æ®é›†ä¸Šçš„ç±»åéƒ½åŒ¹é…ã€‚æˆ‘ä»¬ç°åœ¨å°†åˆ›å»º [TensorFlow æ•°æ®é›†](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)ï¼Œå®ƒå°†åœ¨éœ€è¦æ—¶æ‰¹é‡åŠ è½½æ•°æ®ã€‚æˆ‘ä»¬å°†æ··æ´—è®­ç»ƒå›¾åƒï¼Œä»¥ä¾¿åœ¨æ¯ä¸€æ‰¹ä¸­æˆ‘ä»¬éƒ½æœ‰æ··åˆçš„è”¬èœã€‚

```
image_size = (224, 224)
shape = image_size + (3,)
batch_size = 32print("========== Training data ==========")
train_data = image_dataset_from_directory(
    directory='data/train', label_mode='categorical',
    image_size=image_size, batch_size=batch_size,
    seed=42
)
print("\n========== Validation data ==========")
valid_data = image_dataset_from_directory(
    directory='data/valid', label_mode='categorical',
    image_size=image_size, batch_size=batch_size,
    shuffle=False
)print("\n========== Test data ==========")
test_data = image_dataset_from_directory(
    directory='data/test', label_mode='categorical',
    image_size=image_size, batch_size=batch_size,
    shuffle=False
)len(train_data.class_names)==len(valid_data.class_names)==len(test_data.class_names)
```

![](img/ca3b6d75e261b98108bfa7fd488f663e.png)

ä»å›¾åƒçš„çˆ¶ç›®å½•æ¨æ–­å›¾åƒçš„ç±»åã€‚æˆ‘ä»¬çœ‹åˆ°è¿™äº›æ¨æ–­çš„ç±»åå¯ä»¥é€šè¿‡`.class_names`å±æ€§è®¿é—®ã€‚è®©æˆ‘ä»¬æŒ‰ç±»æ£€æŸ¥æ¯ä¸ªæ•°æ®é›†çš„å›¾åƒæ•°é‡:

```
summary = pd.DataFrame()
for d in ['train', 'valid', 'test']:
    for c in train_classes:
        n = len([i for i in 
                 pathlib.Path(f'data/{d}/{c}').glob('*.jpg')])
        summary.loc[c, d] = n
summary.style.format("{:.0f}")
```

![](img/17522318910ec1b61e897e8f527e2996.png)

æ¯å ‚è¯¾æœ‰ 1000 ä¸ªè®­ç»ƒã€200 ä¸ªéªŒè¯å’Œ 200 ä¸ªæµ‹è¯•å›¾åƒã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨å¼€å§‹å»ºæ¨¡ä¹‹å‰çœ‹çœ‹ç¤ºä¾‹å›¾åƒ:

```
n_rows = 2
n_cols = 3train_path = pathlib.Path('data/train')
train_images = [item for item in train_path.glob('*/*.jpg')]
np.random.seed(42)
sample_images = np.random.choice(train_images, n_rows*n_cols, 
                                 replace=False)plt.figure(figsize=(12,8))
for i, image in enumerate(sample_images):
    ax = plt.subplot(n_rows, n_cols, i+1)
    plt.imshow(mpimg.imread(image))
    plt.axis('off')
    plt.title(image.parts[2])
plt.suptitle('Sample training images', fontsize=20);
```

![](img/7668605b6f5ea8f8fce813bc12039cae.png)

# ğŸ”¨ç³»ç»Ÿæ¨¡å‹åŒ–

## ğŸ”§å‹å· 0

åœ¨ç¬¬ 1 éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬æ„å»ºçš„ CNN æ¶æ„è¢«è¯æ˜æ˜¯ MNIST æ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä»å¯¹è”¬èœæ•°æ®åº”ç”¨ä¸åŸºçº¿æ¨¡å‹ç›¸åŒçš„ä½“ç³»ç»“æ„å¼€å§‹:

```
n_classes = len(train_data.class_names)model_0 = Sequential([
    Rescaling(1./255, input_shape=shape),
    Conv2D(32, 5, padding='same', activation='relu'),
    Conv2D(32, 5, padding='same', activation='relu'),
    MaxPooling2D(), 
    Conv2D(32, 5, padding='same', activation='relu'),
    Conv2D(32, 5, padding='same', activation='relu'),
    MaxPooling2D(), 
    Flatten(),
    Dense(128, activation='relu'),
    Dense(n_classes, activation='softmax')
])model_0.compile(loss='categorical_crossentropy', optimizer='Adam', 
                metrics=['accuracy'])
model_0.summary()
```

![](img/d2e4993529e57abee27a55e02b29e2a7.png)

è®©æˆ‘ä»¬è®­ç»ƒç½‘ç»œã€‚æˆ‘ä»¬å°†åªè¿è¡Œä¸¤ä¸ªé˜¶æ®µï¼Œå› ä¸ºç°åœ¨åŸ¹è®­æ›´åŠ è€—æ—¶:

```
hist_0 = model_0.fit(train_data, epochs=2, 
                     validation_data=valid_data)
```

![](img/f3f80c8d3e07c52e17b46d16646eeffe.png)

å¯¹äº 15 ä¸ªç±»åˆ«ï¼Œå¤§çº¦ 87%çš„å‡†ç¡®ç‡ç›¸å½“ä¸é”™ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸åŒæ—¶æœŸçš„å‡†ç¡®æ€§:

```
def clean_history(hist):
    epochs = len(hist.history['accuracy'])
    df = pd.DataFrame(
        {'epochs': np.tile(np.arange(epochs), 2),
         'accuracy': hist.history['accuracy'] + 
                     hist.history['val_accuracy'], 
         'loss': hist.history['loss'] + 
                 hist.history['val_loss'], 
         'dataset': np.repeat(['train', 'valid'], epochs)}
    )
    return dfsns.lineplot(data=clean_history(hist_0), x='epochs', y='accuracy', 
             hue='dataset');
```

![](img/032d55954056cdc11786d54341c29e04.png)

æˆ‘ä»¬å°†ä¸ºæ¯ä¸ªæµ‹è¯•å›¾åƒå‡†å¤‡æ ‡ç­¾ã€‚è¿™å°†æœ‰åŠ©äºè¿›ä¸€æ­¥è¯„ä¼°æ¨¡å‹:

```
test_path = pathlib.Path('data/test')
test_images = [item for item in test_path.glob('*/*.jpg')]test_labels = []
for _, labels in test_data.unbatch():
    test_labels.append(labels.numpy().argmax())
test_labels[:10]
```

![](img/4b5af0b8ac8eab79b55e8cd6f8193303.png)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ ¹æ®æµ‹è¯•æ•°æ®æ£€æŸ¥æ¨¡å‹çš„æ€§èƒ½:

```
test_preds_0 = model_0.predict(test_data)
test_classes_0 = test_preds_0.argmax(axis=1)
test_metrics = pd.DataFrame(columns=['Test accuracy'])
test_metrics.loc['model_0'] = np.mean(test_labels==test_classes_0)
test_metrics
```

![](img/5047b6dc1408395afde1fe73ed12b29e.png)

ç¬¬ä¸€ä¸ªæ¨¡å‹çº¦ 87%çš„å‡†ç¡®ç‡æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹ã€‚è®©æˆ‘ä»¬é€šè¿‡è¯¾å ‚æ¥ç†è§£è¡¨æ¼”:

```
def show_confusion_matrix(labels, classes):
    cm = (pd.crosstab(pd.Series(labels, name='actual'), 
                      pd.Series(classes, name='predicted'))
            .style.background_gradient('binary'))
    return cmshow_confusion_matrix(test_labels, test_classes_0)
```

![](img/7c6e793e27823740729bdcd4d5141d16.png)

å¾ˆé«˜å…´çœ‹åˆ°å¤§éƒ¨åˆ†å›¾åƒéƒ½é›†ä¸­åœ¨å¯¹è§’çº¿ä¸Šã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©ä¸å‘½åç±»ï¼Œå› ä¸ºæœ‰ç©ºæ ¼(ç”¨ç±»åä»£æ›¿æ•°å­—ä¼šæ‰©å¤§è¡¨æ ¼çš„å°ºå¯¸)ã€‚å¯¹è§’çº¿ä¸Šæœ‰ä¸€äº›è¾ƒæ·±çš„ç°è‰²å•å…ƒæ ¼ã€‚ä¾‹å¦‚ï¼Œ3 ç­æœ‰æ—¶ä¼šä¸ 10 ç­æ··æ·†ã€‚æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥æ‰¾åˆ° 3 çº§å’Œ 10 çº§çš„æ ‡ç­¾:

```
print(f"Class 3 is {train_data.class_names[3]}")
print(f"Class 10 is {train_data.class_names[10]}")
```

![](img/32ed4000ba40a4f58034639d8c4fb271.png)

æ‰€ä»¥å¸ƒæ—å“ˆå°”å¶å°”ä¼šè¢«è¯¯è®¤ä¸ºæ˜¯æœ¨ç“œã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ç¤ºä¾‹å›¾åƒåŠå…¶é¢„æµ‹:

```
def inspect_sample_predictions(images, preds, dataset='test', 
                               seed=42, n_rows=2, n_cols=3):
    np.random.seed(seed)
    indices = np.random.choice(range(len(images)), n_rows*n_cols, 
                               replace=False)
    plt.figure(figsize=(12,8))
    for i, index in enumerate(indices):
        ax = plt.subplot(n_rows, n_cols, i+1)
        image = images[index]
        plt.imshow(mpimg.imread(image))
        plt.axis('off')

        proba = preds[index].max()
        pred = preds[index].argmax()
        pred_class = test_data.class_names[pred]
        if pred_class == image.parts[2]:
            colour = 'green'
        else:
            colour = 'red'
        plt.title(f"Actual: {image.parts[2]} \nPredicted: {pred_class} ({proba:.1%})", color=colour, fontsize=14)
    plt.suptitle(f'Sample {dataset} images with prediction', fontsize=20)
    plt.tight_layout();

inspect_sample_predictions(test_images, test_preds_0)
```

![](img/6ca58ab79ff564b3a432dbf291a0aa4a.png)

å¾ˆé«˜å…´çœ‹åˆ°æ‰€æœ‰è¿™äº›æ ·æœ¬å›¾åƒéƒ½è¢«æ­£ç¡®é¢„æµ‹ã€‚æˆ‘ä»¬çœ‹åˆ°å„ç§é¢„æµ‹çš„ç½®ä¿¡åº¦ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹æœ€ä¸æ­£ç¡®çš„é¢„æµ‹:

```
def see_most_incorrect(data, images, preds, dataset='test', seed=42, 
                       n_rows=2, n_cols=3):
    df = pd.DataFrame()    
    df['true_class'] = [image.parts[2] for image in images]
    df['pred_class'] = [data.class_names[pred] for 
                        pred in preds.argmax(axis=1)]
    df['proba'] = preds.max(axis=1)
    incorrect_df = df.query("true_class!=pred_class")\
                     .nlargest(n_rows*n_cols, 'proba')

    plt.figure(figsize=(8,5))
    for i, (ind, row) in enumerate(incorrect_df.iterrows()):
        ax = plt.subplot(n_rows, n_cols, i+1)
        plt.imshow(plt.imread(images[ind]), cmap='binary')
        plt.axis('off')
        true = row['true_class']
        proba = row['proba']
        pred = row['pred_class']

        plt.title(f"Actual: {true}\nPred: {pred} ({proba:.1%})", fontsize=14, color='red')
    plt.suptitle(f'Most incorrect {dataset} predictions', fontsize=20)
    plt.tight_layout();

see_most_incorrect(test_data, test_images, test_preds_0)
```

![](img/8fa7ef8aea065363feaad6aa6c83e98a.png)

åœ¨ä¸Šé¢çš„ä¸­é—´å›¾åƒä¸­ï¼Œæ‚¨èƒ½é©¬ä¸Šåˆ†è¾¨å‡ºæ˜¯è¥¿çº¢æŸ¿å—ï¼Ÿè¥¿çº¢æŸ¿çš„é¢œè‰²ä¸æ˜¯ä½ æ‰€æœŸæœ›çš„ã€‚

æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æ‰€äº†è§£åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•é€šè¿‡æ·»åŠ å±‚ã€æ›´å¤šå•å…ƒã€è¿è¡Œæ›´å¤šæ—¶ä»£æ¥å¢åŠ æ¨¡å‹çš„å¤æ‚æ€§ã€‚å¦‚æœæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿‡æ‹Ÿåˆï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­åŠ å…¥[è„±è½å±‚](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)æœ‰åŠ©äºå‡å°‘è¿‡æ‹Ÿåˆã€‚æˆ–è€…ï¼Œé€šè¿‡æ•°æ®å¢å¼ºç­‰æŠ€æœ¯è·å–æ›´å¤šæ•°æ®æˆ–å¢åŠ æ•°æ®çš„å¤šæ ·æ€§ä¹Ÿæœ‰åŠ©äºæœ€å°åŒ–è¿‡åº¦æ‹Ÿåˆã€‚[æ•°æ®å¢å¼º](https://www.tensorflow.org/tutorials/images/data_augmentation)æ˜¯ä¸€ç§é€šè¿‡å˜æ¢å›¾åƒä½¿è®­ç»ƒæ•°æ®å¤šæ ·åŒ–çš„æŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œä½œä¸ºæ•°æ®å¢å¼ºçš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥éšæœºæ—‹è½¬ã€è£å‰ªã€å¹³ç§»ã€ç¼©æ”¾å’Œç¿»è½¬å›¾åƒã€‚å½“æ²¡æœ‰æ›´å¤šæ•°æ®å¯ç”¨æ—¶ï¼Œé€šè¿‡æ•°æ®å¢å¼ºä½¿æ•°æ®å¤šæ ·åŒ–å¯ä»¥å¸®åŠ©åœ¨æ›´å…·æ™®éæ€§çš„å›¾åƒä¸Šè®­ç»ƒæ¨¡å‹ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹æ˜¯å¦èƒ½æ”¹è¿›è¿™ä¸ªæ¨¡å‹ã€‚

## ğŸ”§å‹å· 1

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨è‡ªå·±æ„å»ºæ¨¡å‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å¦ä¸€ç§é€‰æ‹©:è¿ç§»å­¦ä¹ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é‡ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚å¯¹äºè¿™ä¸ªè¿­ä»£ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿ç§»å­¦ä¹ ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç§ç§°ä¸ºç‰¹å¾æå–çš„è¿ç§»å­¦ä¹ ã€‚åœ¨ç‰¹å¾æå–ä¸­ï¼Œæˆ‘ä»¬å°†ä¿æŒé¢„è®­ç»ƒæ¨¡å‹ä¸å˜ï¼Œåªæ”¹å˜è¾“å‡ºå±‚ä»¥é€‚åº”æˆ‘ä»¬çš„ç”¨ä¾‹ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ [ResNet-50 å‹å·](https://paperswithcode.com/method/resnet)ã€‚è¯¥æ¨¡å‹åœ¨é€šè¿‡ [ImageNet](https://image-net.org/) æ•°æ®åº“è·å¾—çš„æ•°åƒå¼ å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒã€‚åœ¨ TensorFlow ä¸­ï¼Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•æ¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸‹é¢çš„ç®€å•æ–¹æ³•æ¥åŠ è½½ä¸€ä¸ªæ¨¡å‹ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®š ResNet æ¨¡å‹ä¸åŒ…æ‹¬é¡¶å±‚ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è¦æ„å»ºè‡ªå·±çš„è¾“å‡ºå±‚ï¼Œå®ƒé€‚ç”¨äº 15 ä¸ªè”¬èœç±»ã€‚æˆ‘ä»¬å°†åœ¨ ResNet æ¨¡å‹ä¸Šæ·»åŠ å±•å¹³å±‚å’Œè¾“å‡ºå±‚ã€‚

```
model_1 = Sequential([
    ResNet50(include_top=False, weights='imagenet', 
             input_shape=shape),
    Flatten(),
    Dense(n_classes, activation='softmax')
])model_1.compile(optimizer=Adam(learning_rate=0.0001), 
                loss='categorical_crossentropy', 
                metrics=['accuracy'])
model_1.summary()
```

![](img/768dad68f0b71ac52d420252ddada58f.png)

ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç¡®ä¿æ‰€æœ‰å±‚éƒ½è¢«è®¾ç½®ä¸ºä¸å¯è®­ç»ƒï¼Œä»¥ä¾¿ä» ImageNet å­¦ä¹ çš„æ¨¡å‹çš„æƒé‡å’Œåå·®ä¿æŒä¸å˜ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®­ç»ƒæ¨¡å‹:

```
for layer in model_1.layers[0].layers:
    layer.trainable=False
hist_1 = model_1.fit(train_data, validation_data=valid_data, 
                     epochs=2)
```

![](img/0560da49ba6aea5192fa890b670ecfba.png)

å“‡ï¼Œæ¨¡å‹ç²¾åº¦æ˜æ˜¾æé«˜äº†ï¼å³ä½¿æœ‰ 1 epochï¼Œæ€§èƒ½çœ‹èµ·æ¥ä¹Ÿå¾ˆæ£’ã€‚

è®©æˆ‘ä»¬æŒ‰æ—¶ä»£æ¥çœ‹æ€§èƒ½:

```
sns.lineplot(data=clean_history(hist_1), x='epochs', y='accuracy', 
                                hue='dataset');
```

![](img/b57653886964d5f7dd5f87085fc77834.png)

éšç€ç¬¬äºŒä¸ªçºªå…ƒï¼Œæˆ‘ä»¬å¼€å§‹ç¨å¾®è¿‡åº¦æ‹Ÿåˆã€‚

```
test_preds_1 = model_1.predict(test_data)
test_classes_1 = test_preds_1.argmax(axis=1)
test_metrics.loc['model_1'] = np.mean(test_labels==test_classes_1)
test_metrics
```

![](img/b45e6ff17c2cf23fa924c15c11fd748e.png)

15 ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡è¾¾åˆ° 98%å·¦å³ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ€§èƒ½ã€‚è®©æˆ‘ä»¬æŒ‰ç±»è¿›ä¸€æ­¥æŒ–æ˜:

```
show_confusion_matrix(test_labels, test_classes_1)
```

![](img/65a47a214e9ae798fe6230e4afccd306.png)

å¾ˆé«˜å…´çœ‹åˆ°å¤§å¤šæ•°å€¼éƒ½é›†ä¸­åœ¨å¯¹è§’çº¿ä¸Šã€‚é€šè¿‡é‡ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è¾¾åˆ°äº‹åŠåŠŸå€çš„æ•ˆæœã€‚

```
inspect_sample_predictions(test_images, test_preds_1)
```

![](img/f7608ccfc583e940e422260695d8501f.png)

ä¸ä¸Šä¸€æ¬¡è¿­ä»£ä¸€æ ·ï¼Œæ ·æœ¬å›¾åƒè¢«æ­£ç¡®é¢„æµ‹ã€‚é¢„æµ‹æ¦‚ç‡æ¯”ä»¥å‰æ›´é«˜ã€‚

```
see_most_incorrect(test_data, test_images, test_preds_1)
```

![](img/7a2e22a6cec31ff335bccc48b341d0d1.png)

æœ‰è¶£çš„æ˜¯ï¼Œçº¢åº•èåœå’Œèƒ¡èåœè¢«æ··æ·†äº†ã€‚è¿™æœ‰åŠ©äºäº†è§£æ¨¡å‹çš„é”™è¯¯ä¹‹å¤„ã€‚

è¿ç§»å­¦ä¹ ä¹Ÿé€‚ç”¨äºè¾ƒå°çš„æ•°æ®é›†(å³è¾ƒå°‘çš„å›¾åƒ)ï¼Œåªè¦æ‚¨ä½¿ç”¨çš„æ¨¡å‹æ˜¯åœ¨ç›¸ä¼¼çš„æ•°æ®é›†ä¸Šé¢„å…ˆè®­ç»ƒçš„ã€‚å·²ç»å¯¹è¿ç§»å­¦ä¹ æœ‰äº†ä¸€ä¸ªå¿«é€Ÿçš„ä»‹ç»ï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿ç§»å­¦ä¹ çš„çŸ¥è¯†ï¼Œ[è¿™ä¸ªèµ„æº](https://www.tensorflow.org/tutorials/images/transfer_learning)å¯èƒ½ä¼šæœ‰å¸®åŠ©ã€‚å¦‚æœæ‚¨æƒ³å°è¯•å…¶ä»–é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·ä»[è¿™é‡Œ](https://www.tensorflow.org/api_docs/python/tf/keras/applications)æŸ¥çœ‹å…¶ä»–å¯ç”¨æ¨¡å‹ã€‚

è¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å…¨éƒ¨å†…å®¹ï¼å¸Œæœ›ä½ å·²ç»å­¦åˆ°äº†ä¸€äº›å®ç”¨çš„æŠ€èƒ½ï¼Œå¯ä»¥å¼€å§‹ä½ çš„è®¡ç®—æœºè§†è§‰ä¹‹æ—…ã€‚å¦‚æœä½ æƒ³é€šè¿‡åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šåº”ç”¨æˆ‘ä»¬ä½œä¸ºç³»åˆ—çš„ä¸€éƒ¨åˆ†æ‰€å­¦çš„çŸ¥è¯†æ¥è·å¾—æ›´å¤šçš„å›¾åƒåˆ†ç±»ç»éªŒï¼ŒKaggle ä¸­çš„è¿™ä¸ª[å¼€æ”¾æ•°æ®é›†å¯èƒ½å¯¹ä½ æœ‰ç”¨ã€‚](https://www.kaggle.com/datasets?tags=13207-Computer+Vision)

![](img/7516c6e0134b6b2778f564be0d6bd06e.png)

å®‰å¨œÂ·ä½©å°”æ³½åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

*æ‚¨æƒ³è®¿é—®æ›´å¤šè¿™æ ·çš„å†…å®¹å—ï¼Ÿåª’ä½“ä¼šå‘˜å¯ä»¥æ— é™åˆ¶åœ°è®¿é—®åª’ä½“ä¸Šçš„ä»»ä½•æ–‡ç« ã€‚å¦‚æœä½ ä½¿ç”¨* [*æˆ‘çš„æ¨èé“¾æ¥*](https://zluvsand.medium.com/membership) ï¼Œ*æˆä¸ºä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šè´¹ä¼šç›´æ¥å»æ”¯æŒæˆ‘ã€‚*

è°¢è°¢ä½ çœ‹æˆ‘çš„å¸–å­ã€‚å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¿™é‡Œæœ‰æˆ‘çš„ä¸€äº›å¸–å­çš„é“¾æ¥:

â—¼ï¸ï¸ [ç®¡é“ã€ColumnTransformer å’Œ FeatureUnion è®²è§£](/pipeline-columntransformer-and-featureunion-explained-f5491f815f?source=your_stories_page-------------------------------------)
â—¼ï¸ï¸ [FeatureUnionã€ColumnTransformer &ç®¡é“ç”¨äºé¢„å¤„ç†æ–‡æœ¬æ•°æ®](/featureunion-columntransformer-pipeline-for-preprocessing-text-data-9dcb233dbcb6)
â—¼ï¸ [ç”¨è¿™äº›æç¤ºä¸°å¯Œæ‚¨çš„ Jupyter ç¬”è®°æœ¬](/enrich-your-jupyter-notebook-with-these-tips-55c8ead25255)
â—¼ï¸ [ç”¨è¿™äº›æç¤ºæ•´ç†æ‚¨çš„ Jupyter ç¬”è®°æœ¬](/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f)
â—¼ï¸ [è®²è§£ Scikit-ç”¨ SHAP å­¦ä¹ æ¨¡å‹](/explaining-scikit-learn-models-with-shap-61daff21b12a)
â—¼ï¸ï¸ [åœ¨ scikit ä¸­é€‰æ‹©ç‰¹æ€§](/feature-selection-in-scikit-learn-dc005dcf38b7)

å†è§ğŸƒ ğŸ’¨