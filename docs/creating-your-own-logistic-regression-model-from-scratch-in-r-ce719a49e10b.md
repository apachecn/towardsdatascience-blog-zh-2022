# åœ¨ R ä¸­ä»å¤´å¼€å§‹åˆ›å»ºè‡ªå·±çš„é€»è¾‘å›å½’æ¨¡å‹

> åŸæ–‡ï¼š<https://towardsdatascience.com/creating-your-own-logistic-regression-model-from-scratch-in-r-ce719a49e10b>

## åœ¨æ²¡æœ‰å¤–éƒ¨åŒ…çš„æƒ…å†µä¸‹ç”¨ R æ„å»ºäºŒè¿›åˆ¶åˆ†ç±»æ¨¡å‹çš„åˆå­¦è€…æŒ‡å—

![](img/bb372b594260dd92e5f9fe6a21ff40f7.png)

ç±³åˆ©å®‰Â·è€¶è¥¿è€¶åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

> è¿™ç¯‡æ–‡ç« ç€é‡äºä»å¤´å¼€å§‹å¼€å‘ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è™šæ‹Ÿæ•°æ®æ¥ç ”ç©¶ä¼—æ‰€å‘¨çŸ¥çš„åˆ¤åˆ«æ¨¡å‹(å³é€»è¾‘å›å½’)çš„æ€§èƒ½ï¼Œå¹¶éšç€æ•°æ®é‡çš„å¢åŠ åæ˜ å…¸å‹åˆ¤åˆ«æ¨¡å‹çš„å­¦ä¹ æ›²çº¿çš„è¡Œä¸ºã€‚æ•°æ®é›†å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°[ã€‚è¯·æ³¨æ„ï¼Œè¯¥æ•°æ®æ˜¯ä½¿ç”¨éšæœºæ•°ç”Ÿæˆå™¨åˆ›å»ºçš„ï¼Œç”¨äºåœ¨æ¦‚å¿µä¸Šè®­ç»ƒæ¨¡å‹ã€‚](https://github.com/angeleastbengal/Data-Collection)

# ä»‹ç»

é€»è¾‘å›å½’ç›´æ¥å°†ç›®æ ‡å˜é‡ y å¯¹è¾“å…¥ x çš„é¢„æµ‹å»ºæ¨¡ä¸ºå®šä¹‰ä¸º **p(y|x)** çš„æ¡ä»¶æ¦‚ç‡ã€‚ä¸çº¿æ€§å›å½’æ¨¡å‹ç›¸æ¯”ï¼Œåœ¨é€»è¾‘å›å½’ä¸­ï¼Œç›®æ ‡å€¼é€šå¸¸è¢«é™åˆ¶ä¸º 0 åˆ° 1 ä¹‹é—´çš„å€¼ï¼›æˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ¿€æ´»å‡½æ•°(sigmoid)å°†æˆ‘ä»¬çš„é¢„æµ‹è½¬æ¢æˆä¸€ä¸ªæœ‰ç•Œå€¼ã€‚

å‡è®¾å‡½æ•° sigmoid åº”ç”¨äºæ•°æ®çš„çº¿æ€§å‡½æ•°æ—¶ï¼Œå°†å…¶è½¬æ¢ä¸º:

![](img/9ba827f28054ad6d611192f9c88cb663.png)

**æ–¹ç¨‹å¼ 1ã€‚**è¯´æ˜äº†åº”ç”¨äºçº¿æ€§å‡½æ•°çš„ sigmoid å˜æ¢ã€‚ä½œè€…ä½¿ç”¨ Markdown & Latex åˆ¶ä½œçš„å›¾ç‰‡ã€‚

æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†ç±»åˆ«æ¦‚ç‡å»ºæ¨¡ä¸º:

![](img/88bf6edd4973f1dfa5fa037a25270c9c.png)

**æ–¹ç¨‹å¼ 2ã€‚**ä½¿ç”¨é€»è¾‘å‡½æ•°è¯´æ˜äº†ç±»åˆ«æ¦‚ç‡ Cã€‚å›¾ç‰‡ç”±ä½œè€…ä½¿ç”¨ Markdown &ä¹³èƒ¶åˆ¶ä½œã€‚

æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†ç±»åˆ«æ¦‚ç‡ C=1 æˆ– C=0 å»ºæ¨¡ä¸º:

![](img/b459b91e53570ddd6c1fcc0627181a5a.png)

**æ–¹ç¨‹å¼ 3ã€‚**ä½¿ç”¨é€»è¾‘å‡½æ•°ï¼Œè¯´æ˜ç±»åˆ«æ¦‚ç‡ C=1|X å’Œ C=0|Xã€‚å›¾ç‰‡ç”±ä½œè€…ä½¿ç”¨ Markdown & Latex åˆ¶ä½œã€‚

é€»è¾‘å›å½’æœ‰ä¸€ä¸ªçº¿æ€§å†³ç­–è¾¹ç•Œï¼›å› æ­¤ï¼Œä½¿ç”¨æœ€å¤§ä¼¼ç„¶å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šæ¨¡å‹å‚æ•°ï¼Œå³æƒé‡ã€‚**æ³¨ P(C|x) = y(x)ï¼Œä¸ºç®€å•èµ·è§ï¼Œè®°ä¸º yâ€™ã€‚**

![](img/0ed310933928182e32d3b41119c21bee.png)

**æ–¹ç¨‹å¼ 4ã€‚**è¯´æ˜äº†æŸå¤±å‡½æ•°ã€‚ä½œè€…ä½¿ç”¨ Markdown & Latex åˆ¶ä½œçš„å›¾ç‰‡ã€‚

æœ€å¤§ä¼¼ç„¶å‡½æ•°å¯ä»¥è®¡ç®—å¦‚ä¸‹:

![](img/cb3acd4afae77f0fc151e7c4626baae5.png)

**æ–¹ç¨‹å¼ 5ã€‚**ä½œè€…ä½¿ç”¨ Markdown & Latex åˆ¶ä½œçš„å›¾ç‰‡ã€‚

ç°åœ¨æˆ‘ä»¬å°†ä½¿ç”¨è™šæ‹Ÿæ•°æ®æ¥ç©é€»è¾‘å›å½’æ¨¡å‹ã€‚

# 1.åœ¨ R ä¸­åŠ è½½ç›¸å…³çš„åº“

```
#---------------------------------Loading Libraries---------------------------------
library(mvtnorm)
library(reshape2)
library(ggplot2)
library(corrplot)
library(gridExtra)
```

è¿™äº›åº“å°†ç”¨äºåˆ›å»ºå¯è§†åŒ–å’Œæ£€æŸ¥æ•°æ®ä¸å¹³è¡¡ã€‚

# 2.è¯»å–ç›¸å…³æ•°æ®

```
#---------------------------------Set Working Directory---------------------------------setwd("C:/Users/91905/LR/")#---------------------------------Loading Training & Test Data---------------------------------train_data = read.csv("Train_Logistic_Model.csv", header=T)
test_data = read.csv("Test_Logistic_Model.csv", header=T)#---------------------------------Set random seed (to produce reproducible results)---------------------------------
set.seed(1234)#---------------------------------Create  training and testing labels and data---------------------------------
train.len = dim(train_data)[1]
train.data <- train_data[1:2]
train.label <- train_data[,3]test.len = dim(test_data)[1]
test.data <- test_data[1:2]
test.label <- test_data[ ,3]#---------------------------------Defining Class labels---------------------------------
c0 <- '1'; c1 <- '-1'
```

# 3.åˆ›å»ºå›¾:è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„ç‹¬ç«‹å˜é‡æ•£ç‚¹å›¾

```
#------------------------------Function to define figure size---------------------------------
fig <- function(width, heigth){
     options(repr.plot.width = width, repr.plot.height = heigth)
}
```

è§‚å¯Ÿæ•°æ®çš„åˆ†å¸ƒã€‚

```
# â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Creating a Copy of Training Data â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -
data=train_data
data[â€˜labelsâ€™]=lapply(train_data[â€˜yâ€™], as.character)fig(18,8)
plt1=ggplot(data=data, aes(x=x1, y=x2, color=labels)) + 
geom_point()+
 ggtitle (â€˜Scatter Plot of X1 and X2: Training Dataâ€™) +
 theme(plot.title = element_text(size = 10, hjust=0.5), legend.position=â€™topâ€™)data=test_data
data[â€˜labelsâ€™]=lapply(test_data[â€˜yâ€™], as.character)fig(18,8)
plt2=ggplot(data=data, aes(x=x1, y=x2, color=labels)) + 
geom_point()+
 ggtitle (â€˜Scatter Plot of X1 and X2: Test Dataâ€™) +
 theme(plot.title = element_text(size = 10, hjust=0.5), legend.position=â€™topâ€™)grid.arrange(plt1, plt2, ncol=2)
```

![](img/07a3de6df8a8995bd6f3af791d9e70b8.png)

**å›¾ä¸€ã€‚**è¯´æ˜äº†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¸Šé¢çš„å›¾ä¸­è§‚å¯Ÿåˆ°æ•°æ®æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚è¿™æ˜¯ä¼ªæ•°æ®ã€‚çœŸå®ä¸–ç•Œçš„æ•°æ®å¯èƒ½ä¸åƒç±»ä¼¼çš„åˆ†å¸ƒï¼Œè‡ªå˜é‡çš„æ•°é‡ä¹Ÿä¸ä¼šé™åˆ¶ä¸ºä¸¤ä¸ªã€‚Image credit â€”ç”±ä½œè€…ä½¿ç”¨ rã€‚

# 4.æ£€æŸ¥é˜¶çº§ä¸å¹³è¡¡

```
#------------------------------Function to define figure size---------------------------------
fig <- function(width, heigth){
     options(repr.plot.width = width, repr.plot.height = heigth)
}
```

çœ‹æ•°æ®ä¸å¹³è¡¡ã€‚æˆ‘ä»¬æ£€æŸ¥æ¥è‡ªè®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„å‰ 100 è¡Œã€‚

```
library(â€˜dplyrâ€™)data_incr=100
fig(8,4)# â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Creating a Copy of Training Data â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” -
data=train_data
data[â€˜labelsâ€™]=lapply(train_data[â€˜yâ€™], as.character)# â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Looping 100 iterations (500/5) â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” 
# â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Since increment is 5 â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” 
for (i in 1:2)

 {interim=data[1:data_incr,]

 # â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Count of Records by class balance â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” 
 result<-interim%>%
 group_by(labels) %>%
 summarise(Records = n())

 # â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” Plot â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” â€” 
 if (i==1)
 {
 plot1=ggplot(data=result, aes(x=labels, y=Records)) +
 geom_bar(stat=â€identityâ€, fill=â€steelblueâ€)+
 geom_text(aes(label=Records), vjust=-0.3, size=3.5)+
 ggtitle(â€œDistribution of Class (#Training Data=5) â€œ)+
 theme(plot.title = element_text(size = 10, hjust=0.5), legend.position=â€™topâ€™)
 }

 else
 {
 plot2=ggplot(data=result, aes(x=labels, y=Records)) +
 geom_bar(stat=â€identityâ€, fill=â€steelblueâ€)+
 geom_text(aes(label=Records), vjust=-0.3, size=3.5)+
 ggtitle(â€œDistribution of Class (#Training Data=10) â€œ)+
 theme(plot.title = element_text(size = 10, hjust=0.5), legend.position=â€™topâ€™)
 }

 data_incr=data_incr+5

 }
grid.arrange(plot1, plot2, ncol=2)
```

![](img/0275d438c8beb674115b0b6cd46b622e.png)

**å›¾äºŒã€‚**è¯´æ˜äº†äºŒè¿›åˆ¶ç±»çš„åˆ†å¸ƒã€‚æ­£å¦‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬çš„ç§¯æç±»åœ¨æ•°æ®ä¸­å å¤šæ•°ï¼›å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ä¸å¹³è¡¡çš„ã€‚Credit â€”ç”±ä½œè€…ä½¿ç”¨ rã€‚

# 5.é€»è¾‘å›å½’

æ¦‚ç‡åˆ¤åˆ«æ¨¡å‹ä½¿ç”¨å¹¿ä¹‰çº¿æ€§æ¨¡å‹æ¥è·å¾—ç±»åˆ«çš„åéªŒæ¦‚ç‡ï¼Œå¹¶æ—¨åœ¨ä½¿ç”¨æœ€å¤§ä¼¼ç„¶æ¥å­¦ä¹ å‚æ•°ã€‚é€»è¾‘å›å½’æ˜¯ä¸€ç§æ¦‚ç‡åˆ¤åˆ«æ¨¡å‹ï¼Œå¯ç”¨äºåŸºäºåˆ†ç±»çš„ä»»åŠ¡ã€‚

![](img/06a1404f30a02680fbc2686dd3615f5a.png)

**å›¾ä¸‰ã€‚**å±•ç¤ºäº†è®¾è®¡é€»è¾‘å›å½’æ¨¡å‹çš„é€æ­¥æ–¹æ³•ã€‚Credit â€”ç”±ä½œè€…ä½¿ç”¨ markdown å’Œ latex å¼€å‘ã€‚

## 5.1 å®šä¹‰è¾…åŠ©åŠŸèƒ½

## é¢„æµ‹åŠŸèƒ½

ä½¿ç”¨æ¦‚ç‡åˆ†æ•°è¿”å›-1 æˆ–+1ã€‚è¿™é‡Œä½¿ç”¨çš„é˜ˆå€¼æ˜¯ 0.5ï¼Œå³å¦‚æœä¸€ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡> 0.5ï¼Œé‚£ä¹ˆè¯¥ç±»åˆ«è¢«æ ‡è®°ä¸º-1ï¼Œå¦åˆ™ä¸º+1ã€‚

```
#-------------------------------Auxiliary function that predicts class labels-------------------------------predict <- function(w, X, c0, c1)
{
    sig <- sigmoid(w, X)

    return(ifelse(sig>0.5, c1, c0))

}
```

## æˆæœ¬å‡½æ•°

è®¡ç®—æˆæœ¬çš„è¾…åŠ©åŠŸèƒ½ã€‚

```
#-------------------------------Auxiliary function to calculate cost function-------------------------------cost <- function (w, X, T, c0)
{
    sig <- sigmoid(w, X)
    return(sum(ifelse(T==c0, 1-sig, sig)))

}
```

## ä¹™çŠ¶ç»“è‚ åŠŸèƒ½

```
#-------------------------------Auxiliary function to implement sigmoid function-------------------------------sigmoid <- function(w, x)
{
    return(1.0/(1.0+exp(-w%*%t(cbind(1,x)))))    
}
```

## 5.1.4 è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹

è¯¥ç®—æ³•çš„å·¥ä½œåŸç†å¦‚ä¸‹ã€‚æœ€åˆï¼Œè®¾ç½®å‚æ•°ã€‚ç„¶åï¼Œåœ¨å¤„ç†æ¯ä¸ªæ•°æ®ç‚¹ Xnï¼ŒTn ä¹‹åï¼Œå‚æ•°å‘é‡è¢«æ›´æ–°ä¸º:

ğ‘¤(ğœ+1):=ğ‘¤ğœâˆ’ğœ‚ğœ(ğ‘¦ğ‘›âˆ’ğ‘¡ğ‘›)(ğ‘¥ğ‘›)å…¶ä¸­ï¼Œ(ğ‘¦ğ‘›âˆ’ğ‘¡ğ‘›)(ğ‘¥ğ‘›)æ˜¯è¯¯å·®å‡½æ•°çš„æ¢¯åº¦ï¼Œğœæ˜¯è¿­ä»£æ¬¡æ•°ï¼Œğœ‚ğœæ˜¯ç‰¹å®šäºè¿­ä»£çš„å­¦ä¹ é€Ÿç‡ã€‚

```
Logistic_Regression <- function(train.data, train.label, test.data, test.label)
{

    #-------------------------------------Initializations-----------------------------------------
    train.len = nrow(train.data)

    #-------------------------------------Iterations-----------------------------------------
    tau.max <- train.len * 2

    #-------------------------------------Learning Rate-----------------------------------------
    eta <- 0.01

    #-------------------------------------Threshold On Cost Function to Terminate Iteration-----------------------------------
    epsilon <- 0.01

    #-------------------------------------Counter for Iteration-----------------------------------
    tau <- 1

    #-------------------------------------Boolean to check Terimination-----------------------------------
    terminate <- FALSE#-------------------------------------Type Conversion-----------------------------------

    #-------------------------------------Convert Training Data to Matrix-----------------------------------
    X <- as.matrix(train.data)

    #-------------------------------------Train Labels-----------------------------------
    T <- ifelse(train.label==c0,0,1)

    #-------------------------------------Declaring Weight Matrix-----------------------------------
    #-------------------------------------Used to Store Estimated Coefficients-----------------------------------
    #-------------------------------------Dimension of the Matrix = Iteration x Total Columns + 1-----------------------------

    W <- matrix(,nrow=tau.max, ncol=(ncol(X)+1))

    #-------------------------------------Initializing Weights-----------------------------------
    W[1,] <- runif(ncol(W))#-------------------------------------Project Data Using Sigmoid function-----------------------------------
    #-------------------------------------Y includes the probability values-----------------------------------
    Y <- sigmoid(W[1,],X)

    #-------------------------------------Creating a data frame for storing Cost-----------------------------------
    costs <- data.frame('tau'=1:tau.max)

    #-------------------------------------Threshold On Cost Function to Terminate Iteration-----------------------------------
    costs[1, 'cost'] <- cost(W[1,],X,T, c0)

  #-------------------------------------Checking Termination of Iteration-----------------------------------
  while(!terminate){

      #-------------------------------------Terminating Criterion----------------------------------
      #-------------------------------------1\. Tau > or = Tau Max (Iteration 1 is done before)----------------------------------
      #-------------------------------------Cost <=minimum value called epsilon-----------------------------------

      terminate <- tau >= tau.max | cost(W[tau,],X,T, c0)<=epsilon#-------------------------------------Shuffling Data-----------------------------------
      train.index <- sample(1:train.len, train.len, replace = FALSE)

      #-------------------------------------Obtaing Indexes of Dependent and Independent Variable------------------------------
      X <- X[train.index,]
      T <- T[train.index]#-------------------------------------Iterating for each data point-----------------------------------
      for (i in 1:train.len){

        #------------------------------------Cross check termination criteria-----------------------------------
        if (tau >= tau.max | cost(W[tau,],X,T, c0) <=epsilon) {terminate<-TRUE;break}

        #-------------------------------------Predictions using Current Weights-----------------------------------
        Y <- sigmoid(W[tau,],X)#-------------------------------------Updating Weights-----------------------------------
        #-------------------------------------Refer to the Formula above-----------------------------------

        W[(tau+1),] <- W[tau,] - eta * (Y[i]-T[i]) * cbind(1, t(X[i,]))#-------------------------------------Calculate Cost-----------------------------------
        costs[(tau+1), 'cost'] <- cost(W[tau,],X,T, c0)# #-------------------------------------Updating Iteration-----------------------------------
        tau <- tau + 1# #-------------------------------------Decrease Learning Rate-----------------------------------
        eta = eta * 0.999
      }
      }

    #-------------------------------------Remove NAN from Cost vector if it stops early-----------------------------------
      costs <- costs[1:tau, ]#-------------------------------------Final Weights-----------------------------------
    # #-------------------------------------We use the last updated weight since it is most optimized---------------------
      weights <- W[tau,]#-------------------------------------Calculating misclassification-----------------------------------

    train.predict<-predict(weights,train.data,c0,c1)
    test.predict<-predict(weights,test.data,c0,c1)

      errors = matrix(,nrow=1, ncol=2)

      errors[,1] = (1-sum(train.label==train.predict)/nrow(train.data))
      errors[,2] = (1-sum(test.label==test.predict)/nrow(test.data))

  return(errors)
}
```

é€»è¾‘å›å½’ï¼Œä½¿ç”¨æœ€å¤§ä¼¼ç„¶å­¦ä¹ å‚æ•°ã€‚è¿™æ„å‘³ç€åœ¨å­¦ä¹ æ¨¡å‹å‚æ•°(æƒé‡)æ—¶ï¼Œå¿…é¡»å¼€å‘å¹¶æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ã€‚ç„¶è€Œï¼Œç”±äºéçº¿æ€§æ–¹ç¨‹ç³»ç»Ÿæ²¡æœ‰è§£æè§£ï¼Œæ‰€ä»¥ä½¿ç”¨è¿­ä»£è¿‡ç¨‹æ¥å¯»æ‰¾æœ€ä¼˜è§£ã€‚

éšæœºæ¢¯åº¦ä¸‹é™è¢«åº”ç”¨äºé€»è¾‘å›å½’çš„è®­ç»ƒç›®æ ‡ï¼Œä»¥å­¦ä¹ å‚æ•°å’Œè¯¯å·®å‡½æ•°ï¼Œä»è€Œæœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚

## 5.2 ä½¿ç”¨ä¸åŒæ•°æ®å­é›†çš„è®­ç»ƒæ¨¡å‹

æˆ‘ä»¬å°†åœ¨ä¸åŒçš„æ•°æ®å­é›†ä¸Šè®­ç»ƒæ¨¡å‹ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†åœ¨ç ”ç©¶æ•°æ®é‡å¯¹æ¨¡å‹é”™è¯¯åˆ†ç±»ç‡çš„å½±å“æ—¶è€ƒè™‘æ–¹å·®å’Œåå·®ã€‚

```
#------------------------------------------Creating a dataframe to track Errors--------------------------------------acc_train <- data.frame('Points'=seq(5, train.len, 5), 'LR'=rep(0,(train.len/5)))
acc_test <- data.frame('Points'=seq(5, test.len, 5), 'LR'=rep(0,(test.len/5)))data_incr=5#------------------------------------------Looping 100 iterations (500/5)--------------------------------------
#------------------------------------------Since increment is 5--------------------------------------
for (i in 1:(train.len/5))

    {
        #---------------------------------Training on a subset and test on whole data-----------------------------
        error_Logistic = Logistic_Regression(train.data[1:data_incr, ], train.label[1:data_incr], test.data, test.label)

        #------------------------------------------Creating accuarcy metrics--------------------------------------

        acc_train[i,'LR'] <- round(error_Logistic[ ,1],2)acc_test[i,'LR'] <- round(error_Logistic[ ,2],2)

        #------------------------------------------Increment by 5--------------------------------------
        data_incr = data_incr + 5
}
```

æ¨¡å‹çš„å‡†ç¡®æ€§å¯é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œæ£€éªŒ:

```
head(acc_train)
head(acc_test)
```

# 6.ç»“è®º

åœ¨å¤„ç†æ¯ä¸ªæ•°æ®ç‚¹ä¹‹åæ›´æ–°å‚æ•°å‘é‡ï¼›å› æ­¤ï¼Œåœ¨é€»è¾‘å›å½’ä¸­ï¼Œè¿­ä»£çš„æ¬¡æ•°å–å†³äºæ•°æ®çš„å¤§å°ã€‚å½“å¤„ç†è¾ƒå°çš„æ•°æ®é›†æ—¶(å³æ•°æ®ç‚¹çš„æ•°é‡è¾ƒå°‘)ï¼Œæ¨¡å‹éœ€è¦æ›´å¤šçš„è®­ç»ƒæ•°æ®æ¥æ›´æ–°æƒé‡å’Œå†³ç­–è¾¹ç•Œã€‚å› æ­¤ï¼Œå½“è®­ç»ƒæ•°æ®é‡å¾ˆå°æ—¶ï¼Œå®ƒçš„å‡†ç¡®æ€§å¾ˆå·®ã€‚

*å…³äºä½œè€…:é«˜çº§åˆ†æä¸“å®¶å’Œç®¡ç†é¡¾é—®ï¼Œå¸®åŠ©å…¬å¸é€šè¿‡å¯¹ç»„ç»‡æ•°æ®çš„å•†ä¸šã€æŠ€æœ¯å’Œæ•°å­¦çš„ç»„åˆæ‰¾åˆ°å„ç§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚ä¸€ä¸ªæ•°æ®ç§‘å­¦çˆ±å¥½è€…ï¼Œåœ¨è¿™é‡Œåˆ†äº«ã€å­¦ä¹ ã€è´¡çŒ®ï¼›ä½ å¯ä»¥å’Œæˆ‘åœ¨* [*ä¸Šè”ç³»*](https://www.linkedin.com/in/angel-das-9532bb12a/) *å’Œ* [*ä¸Šæ¨ç‰¹*](https://twitter.com/dasangel07_andy)*ï¼›*