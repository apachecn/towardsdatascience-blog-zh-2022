# åŸºç¡€ RL:æ±‚è§£é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹

> åŸæ–‡ï¼š<https://towardsdatascience.com/foundational-rl-solving-markov-decision-process-d90b7e134c0b>

## å¼ºåŒ–å­¦ä¹ ä¹‹è·¯

![](img/d831ef77f8991309ad3880b7e69ac93e.png)

ä½œè€…ä½¿ç”¨äººå·¥æ™ºèƒ½å·¥å…· Dreamstudio ç”Ÿæˆçš„å°é¢ç…§ç‰‡(æˆæƒä¸º[https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/)

åœ¨[çš„ç¬¬ä¸€éƒ¨åˆ†](/foundational-rl-markov-states-markov-chain-and-markov-decision-process-be8ccc341005)ä¸­ï¼Œæˆ‘è®¨è®ºäº†ä¸€äº›åŸºæœ¬æ¦‚å¿µæ¥ä¸ºå¼ºåŒ–å­¦ä¹ (RL)å»ºç«‹åŸºç¡€ï¼Œå¦‚é©¬å°”å¯å¤«çŠ¶æ€ã€é©¬å°”å¯å¤«é“¾å’Œé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)ã€‚å¼ºåŒ–å­¦ä¹ é—®é¢˜æ˜¯å»ºç«‹åœ¨ MDP ä¹‹ä¸Šçš„ã€‚

[](/foundational-rl-markov-states-markov-chain-and-markov-decision-process-be8ccc341005)  

MDP æ˜¯ä¸€ä¸ª 4 å…ƒç»„æ¨¡å‹(ğ“¢ã€ğ“ã€ğ“Ÿã€ğ“¡)ï¼Œå…¶ä¸­ *s* âˆˆ ğ“¢æ˜¯ä¸€ä¸ªçŠ¶æ€ï¼Œ *a* âˆˆ ğ“æ˜¯å½“ä»£ç†æ˜¯ä¸€ä¸ªçŠ¶æ€ *s* æ—¶é‡‡å–çš„ä¸€ä¸ªåŠ¨ä½œï¼Œğ“Ÿ*(sâ€œ| sï¼Œa)* æ˜¯åœ¨åŠ¨ä½œ *a* çš„å½±å“ä¸‹ä» *s* è½¬ç§»åˆ°çŠ¶æ€*sâ€™*çš„è½¬ç§»æ¦‚ç‡çŸ©é˜µ(æˆ–è€…

**ç­–ç•¥å‡½æ•°:**ç­–ç•¥å‡½æ•°ï¼Œåœ¨ RL æ–‡çŒ®ä¸­é€šå¸¸ç”¨Ï€è¡¨ç¤ºï¼Œè§„å®šäº†ä»çŠ¶æ€ç©ºé—´ğ“¢åˆ°åŠ¨ä½œç©ºé—´ğ“.çš„æ˜ å°„

> MDP çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªæœ€å¤§åŒ–é•¿æœŸå›æŠ¥çš„æœ€ä¼˜ç­–ç•¥ã€‚

# è´´ç°å› ç´ 

MDP éœ€è¦ä¸€ä¸ªç¦»æ•£æ—¶é—´çš„æ¦‚å¿µï¼Œå› æ­¤ MDP è¢«å®šä¹‰ä¸ºä¸€ä¸ªç¦»æ•£æ—¶é—´éšæœºæ§åˆ¶è¿‡ç¨‹ã€‚åœ¨ RL çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¯ä¸ª MDP ç”±æŠ˜æ‰£å› å­Î³ (gamma)æ¥å‚æ•°åŒ–ï¼Œè¯¥æŠ˜æ‰£å› å­Î³ç¡®å®šæœªæ¥å¥–åŠ±ç›¸å¯¹äºå½“å‰å¥–åŠ±çš„é‡è¦æ€§ã€‚æ¢å¥è¯è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡¡é‡æœªæ¥çš„å›æŠ¥ç›¸å¯¹äºç°åœ¨çš„å›æŠ¥å¯¹ä»£ç†äººæœ‰å¤šå¤§ä»·å€¼çš„æŒ‡æ ‡ã€‚æŠ˜æ‰£å› å­æ˜¯ä¸€ä¸ªä»‹äº 0 å’Œ 1 ä¹‹é—´çš„å€¼ï¼Œå…¶ä¸­å€¼ 0 æ„å‘³ç€ä»£ç†äººåªå…³å¿ƒçœ¼å‰çš„å¥–åŠ±ï¼Œå¹¶å°†å®Œå…¨å¿½ç•¥ä»»ä½•æœªæ¥çš„å¥–åŠ±ï¼Œè€Œå€¼ 1 æ„å‘³ç€ä»£ç†äººå°†æŠŠæœªæ¥çš„å¥–åŠ±è§†ä¸ºä¸ç°åœ¨è·å¾—çš„å¥–åŠ±åŒç­‰é‡è¦ã€‚

ä¾‹å¦‚ï¼Œåœ¨ä»£ç†äººåœ¨ä¸¤ä¸ªè¡ŒåŠ¨ A å’Œ B ä¹‹é—´åšå‡ºå†³å®šçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸¤ä¸ªè¡ŒåŠ¨å°†å¯¼è‡´ä¸åŒçš„æœªæ¥å¥–åŠ±åºåˆ—ï¼ŒæŠ˜æ‰£å› å­å¯ä»¥ç”¨äºç¡®å®šè¿™äº›ä¸åŒå¥–åŠ±åºåˆ—çš„ç›¸å¯¹å€¼ã€‚å¦‚æœæŠ˜æ‰£å› å­ä½ï¼Œé‚£ä¹ˆä»£ç†äººå°†æ›´æœ‰å¯èƒ½é€‰æ‹©å¯¼è‡´å³æ—¶å¥–åŠ±çš„è¡ŒåŠ¨ï¼Œè€Œå¦‚æœæŠ˜æ‰£å› å­é«˜ï¼Œä»£ç†äººå°†æ›´æœ‰å¯èƒ½é€‰æ‹©å¯¼è‡´æ›´å¤§é‡‘é¢çš„æœªæ¥å¥–åŠ±çš„è¡ŒåŠ¨ã€‚

ä¸€èˆ¬æ¥è¯´ï¼ŒæŠ˜æ‰£å› å­æ˜¯ MDP ä¸­çš„ä¸€ä¸ªé‡è¦è€ƒè™‘å› ç´ ï¼Œå› ä¸ºå®ƒå…è®¸ä»£ç†äººç”¨é•¿æœŸå¥–åŠ±æ¥æ¢å–çŸ­æœŸå¥–åŠ±ï¼Œå¹¶å¹³è¡¡å³æ—¶æ»¡è¶³çš„éœ€æ±‚å’Œå»¶è¿Ÿæ»¡è¶³çš„æ½œåœ¨å¥½å¤„ã€‚

å› æ­¤ï¼Œåœ¨ RL ç¯å¢ƒä¸­çš„ MDP æ˜¯(ğ“¢ï¼Œğ“ï¼Œğ“Ÿï¼Œğ“¡ï¼ŒÎ³)ã€‚

# å¥–åŠ±å…¬å¼

è€ƒè™‘åˆ°è´´ç°å› å­Î³ï¼Œåœ¨æ—¶é—´ *t* çš„å›æŠ¥å¯ä»¥å†™æˆ

![](img/320deb8dd3918fa2b4115998637bb0fd.png)

ç­‰å¼ 1ã€‚æ—¶é—´æ­¥é•¿ *t* çš„å¥–åŠ±ã€‚

æ€»å¥–åŠ±ï¼Œå³æ‰€æœ‰æ—¶é—´çš„ç´¯ç§¯å¥–åŠ±æ˜¯

![](img/ce051be995d22792a59c63dab77cf167.png)

ç­‰å¼ 2ã€‚ç´¯ç§¯å¥–åŠ±

æœ€å¤§åŒ–ç´¯ç§¯å›æŠ¥çš„Ï€ç­–ç•¥æ˜¯æˆ‘ä»¬çš„ MDP é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚

## æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä¾‹å­(è‡ªåŠ¨é©¾é©¶ä»£ç†):

åœ¨è‡ªåŠ¨é©¾é©¶çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹æ¥å¯¹è½¦è¾†çš„å†³ç­–è¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ï¼Œä»¥ä¾¿åœ¨é•¿æœŸå†…æœ€å°åŒ–ç‡ƒæ–™æ¶ˆè€—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç³»ç»Ÿçš„çŠ¶æ€å¯ä»¥ç”±è½¦è¾†çš„å½“å‰é€Ÿåº¦å’ŒåŠ é€Ÿåº¦æ¥è¡¨ç¤ºï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°å°†æœ€å°åŒ–ç‡ƒæ–™æ¶ˆè€—çš„æœ€ä½³åŠ¨ä½œåºåˆ—ã€‚

è½¦è¾†çš„ç¬æ—¶ç‡ƒæ–™æ¶ˆè€—å¯ä»¥å»ºæ¨¡ä¸ºå‡½æ•° *g(vï¼Œa)* ï¼Œå…¶ä¸­ *v* æ˜¯å½“å‰é€Ÿåº¦ï¼Œè€Œ *a* æ˜¯å½“å‰åŠ é€Ÿåº¦ã€‚è¯¥å‡½æ•°å¯ç”¨äºè¯„ä¼°ç»™å®šçŠ¶æ€ä¸‹æ¯ä¸ªå¯èƒ½è¡ŒåŠ¨çš„æˆæœ¬ï¼Œé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å¯ç”¨äºå¯»æ‰¾å°†æœ€å°åŒ–è½¦è¾†é•¿æœŸç‡ƒæ–™æ¶ˆè€—çš„æœ€ä½³è¡ŒåŠ¨åºåˆ—ã€‚

ä¾‹å¦‚ï¼Œåœ¨å½“å‰é€Ÿåº¦ä¸º *v* ä¸”å½“å‰åŠ é€Ÿåº¦ä¸º*a*çš„ç»™å®šçŠ¶æ€ä¸‹ï¼ŒMDP å¯ä»¥è€ƒè™‘ä¸€ç³»åˆ—å¯èƒ½çš„åŠ¨ä½œï¼Œä¾‹å¦‚åŠ é€Ÿã€å‡é€Ÿæˆ–ä¿æŒå½“å‰é€Ÿåº¦ã€‚å¯ä»¥ä½¿ç”¨å‡½æ•° *g(vï¼Œa)* æ¥è¯„ä¼°æ¯é¡¹æªæ–½çš„æˆæœ¬ï¼Œå¹¶æ ¹æ®å“ªé¡¹æªæ–½å°†å¯¼è‡´é•¿æœŸæœ€ä½çš„ç‡ƒæ²¹æ¶ˆè€—æ¥é€‰æ‹©æœ€ä½³æªæ–½ã€‚ç„¶åï¼Œå¯ä»¥åœ¨æ¯ä¸ªåç»­çŠ¶æ€ä¸‹é‡å¤è¯¥è¿‡ç¨‹ï¼Œä»¥æ‰¾åˆ°æœ€å¤§é™åº¦é™ä½ç‡ƒæ²¹æ¶ˆè€—çš„æœ€ä½³è¡ŒåŠ¨é¡ºåºã€‚

> **éœ€è¦å¼ºè°ƒçš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘æ²¡æœ‰è€ƒè™‘è½¬ç§»æ¦‚ç‡ğ“Ÿï¼Œè¿™æ˜¯ä¸ºäº†è®©æˆ‘ä»¬çš„ä¾‹å­æ›´å®¹æ˜“ç†è§£ï¼Œä¹Ÿæ›´ç¬¦åˆå®é™…ã€‚**

## ä¸€äº› python ä»£ç :

è€ƒè™‘ä¸€ä¸ª MDPï¼Œå…¶ä¸­çŠ¶æ€ä¸ºé€Ÿåº¦å’ŒåŠ é€Ÿåº¦ï¼Œé€Ÿåº¦çš„æœ€å°å€¼ä¸º 0 ç±³/ç§’ï¼Œæœ€å¤§å€¼ä¸º 50 ç±³/ç§’ï¼ŒåŠ é€Ÿåº¦çš„æœ€å°å€¼ä¸º-4.5 ç±³/ç§’ï¼Œæœ€å¤§å€¼ä¸º 3.0 ç±³/ç§’ï¼Œå®ƒä»¬ä¸­çš„æ¯ä¸€ä¸ªéƒ½ä»¥ 0.1 é‡åŒ–ã€‚æˆ‘ä»¬å¯ä»¥è€ƒè™‘ä»¥ä¸‹æ„é€ å‡½æ•°ä¸­çš„ MDP ç±»:

```
def __init__(self, velocity_min, velocity_max, acceleration_min, acceleration_max, velocity_step, acceleration_step, acceleration_min_accelerate, acceleration_max_accelerate):
        # Define minimum and maximum values for velocity and acceleration
        self.VELOCITY_MIN = velocity_min
        self.VELOCITY_MAX = velocity_max
        self.ACCELERATION_MIN = acceleration_min
        self.ACCELERATION_MAX = acceleration_max

        # Define quantization step for velocity and acceleration
        self.VELOCITY_STEP = velocity_step
        self.ACCELERATION_STEP = acceleration_step

        # Define minimum and maximum values for acceleration when accelerating or decelerating
        self.ACCELERATION_MIN_ACCELERATE = acceleration_min_accelerate
        self.ACCELERATION_MAX_ACCELERATE = acceleration_max_accelerate

        # Calculate number of possible values for velocity and acceleration
        self.num_velocity_values = int((self.VELOCITY_MAX - self.VELOCITY_MIN) / self.VELOCITY_STEP) + 1
        self.num_acceleration_values = int((self.ACCELERATION_MAX - self.ACCELERATION_MIN) / self.ACCELERATION_STEP) + 1

        # Create list of possible values for velocity and acceleration
        self.velocity_values = [self.VELOCITY_MIN + i * self.VELOCITY_STEP for i in range(self.num_velocity_values)]
        self.acceleration_values = [self.ACCELERATION_MIN + i * self.ACCELERATION_STEP for i in range(self.num_acceleration_values)]
```

æœŸæœ›çš„åŠ¨ä½œå¯ä»¥æ˜¯åŠ é€Ÿã€å‡é€Ÿæˆ–ä¿æŒè½¦è¾†çš„æ’å®šé€Ÿåº¦ã€‚

```
 # Function to calculate available actions in a given state
    def calculate_actions(self, v, a):
        # Initialize list of available actions
        actions = []

        # If current velocity is less than maximum, add option to accelerate
        if v < self.VELOCITY_MAX:
            for a_new in self.acceleration_values:
                if self.ACCELERATION_MIN_ACCELERATE <= a_new <= self.ACCELERATION_MAX_ACCELERATE:
                    actions.append((v, a_new))

        # If current velocity is greater than minimum, add option to decelerate
        if v > self.VELOCITY_MIN:
            for a_new in self.acceleration_values:
                if -self.ACCELERATION_MAX_ACCELERATE <= a_new <= -self.ACCELERATION_MIN_ACCELERATE:
                    actions.append((v, a_new))

        # Add option to maintain current velocity and acceleration
        actions.append((v, a))

         return actions
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—é¢„æœŸæ²¹è€—:

```
# Function to evaluate the expected fuel consumption for a given state and action
    def evaluate_fuel_consumption(self, v, a, v_new, a_new):
        # Calculate expected fuel consumption for current state and action
        fuel_current = self.fuel_consumption(v, a)
        fuel_new = self.fuel_consumption(v_new, a_new)
        return fuel_current + fuel_new
```

è®¡ç®—æœ€ä¼˜ç­–ç•¥çš„ä¸€ç§ç®€å•æ–¹æ³•æ˜¯æ‰«ææ•´ä¸ªçŠ¶æ€ç©ºé—´:

```
# Function to find the optimal action in a given state, based on minimizing expected fuel consumption
    def find_optimal_action(self, v, a):
        # Calculate available actions in current state
        actions = self.calculate_actions(v, a)

        # Initialize minimum expected fuel consumption
        min_fuel = float("inf")

        # Initialize optimal action
        optimal_action = None

        # Iterate over available actions and find action with minimum expected fuel consumption
        for v_new, a_new in actions:
            fuel = self.evaluate_fuel_consumption(v, a, v_new, a_new)
            if fuel < min_fuel:
                min_fuel = fuel
                optimal_action = (v_new, a_new)

        return optimal_action

    # Function to calculate the optimal policy for the MDP
    def calculate_optimal_policy(self):
        # Initialize dictionary to store optimal policy
        optimal_policy = {}

        # Iterate over all possible states and calculate optimal action for each state
        for v in self.velocity_values:
            for a in self.acceleration_values:
                optimal_policy[(v, a)] = self.find_optimal_action(v, a)

        return optimal_policy
```

ä»¥ä¸Šä»£ç ç‰‡æ®µçš„æµ‹è¯•å®ç°å¦‚ä¸‹:

```
# Create MDP instance
mdp = MDP(VELOCITY_MIN, VELOCITY_MAX, ACCELERATION_MIN, ACCELERATION_MAX, VELOCITY_STEP, ACCELERATION_STEP, ACCELERATION_MIN_ACCELERATE, ACCELERATION_MAX_ACCELERATE)

# Calculate optimal policy for the MDP
optimal_policy = mdp.calculate_optimal_policy()

# Print optimal policy for the first few states
for i in range(10):
    for j in range(10):
        print(optimal_policy[(mdp.velocity_values[i], mdp.acceleration_values[j])])
```

ä¸Šé¢ä¾‹å­çš„å®Œæ•´ä»£ç å¯ä»¥ä»[https://gist . github . com/rahulbhadani/92d 3 be 52529 a 64372 c 796 ca 5 e 7 CB 3770](https://gist.github.com/rahulbhadani/92d3be52529a64372c796ca5e7cb3770)ä¸‹è½½ã€‚

> ç°åœ¨ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé—®ä¸€ä¸ªé—®é¢˜:ä¸Šè¿°å®ç°æ˜¯å¦é«˜æ•ˆï¼Ÿ

æˆ‘ä»¬æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œä¸Šé¢çš„å®ç°æ‰«æäº†æ•´ä¸ªçŠ¶æ€ç©ºé—´ï¼Œæ•ˆç‡ä¸æ˜¯å¾ˆé«˜ã€‚ä¸ºäº†æé«˜è¿™ç§å®ç°çš„æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ¨æ€ç¼–ç¨‹æ¥å­˜å‚¨æ¯ä¸ªçŠ¶æ€çš„æœ€ä½³åŠ¨ä½œï¼Œç„¶åä½¿ç”¨å­˜å‚¨çš„å€¼æ¥è®¡ç®—æ•´ä¸ª MDP çš„æœ€ä½³ç­–ç•¥ï¼Œè€Œä¸éœ€è¦è¿­ä»£æ‰€æœ‰å¯èƒ½çš„çŠ¶æ€ã€‚é€šè¿‡åˆ©ç”¨ä»»ä½•ç»™å®šçŠ¶æ€çš„æœ€ä¼˜ç­–ç•¥ä»…å–å†³äºä»å½“å‰çŠ¶æ€å¯ä»¥åˆ°è¾¾çš„çŠ¶æ€çš„æœ€ä¼˜ç­–ç•¥çš„äº‹å®ï¼Œè¿™å°†å…è®¸æ›´æœ‰æ•ˆåœ°è®¡ç®—æœ€ä¼˜ç­–ç•¥ã€‚

å¦ä¸€ç§é€‰æ‹©æ˜¯ä½¿ç”¨å‡½æ•°é€¼è¿‘æ¥é€¼è¿‘æœ€ä¼˜ç­–ç•¥ï¼Œè¿™æ¯”æ˜¾å¼è®¡ç®—æ‰€æœ‰å¯èƒ½çŠ¶æ€çš„æœ€ä¼˜ç­–ç•¥æ›´æœ‰æ•ˆã€‚è¿™å¯ä»¥é€šè¿‡åœ¨çŠ¶æ€ç©ºé—´çš„ä»£è¡¨æ€§æ ·æœ¬ä¸Šè®­ç»ƒè¯¸å¦‚ç¥ç»ç½‘ç»œ(æ·±åº¦ RL)çš„æ¨¡å‹ï¼Œç„¶åä½¿ç”¨è®­ç»ƒçš„æ¨¡å‹æ¥é¢„æµ‹ä»»ä½•ç»™å®šçŠ¶æ€çš„æœ€ä½³åŠ¨ä½œæ¥å®Œæˆã€‚

åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬åº”è¯¥å¯ä»¥è½»æ¾åœ°è®¨è®ºè´å°”æ›¼æ–¹ç¨‹ã€åŠ¨æ€è§„åˆ’å’Œ Q å‡½æ•°ã€‚

> è´å°”æ›¼æ–¹ç¨‹åœ¨æ§åˆ¶ç†è®ºæˆ–æ§åˆ¶å·¥ç¨‹ä¸­ä¹Ÿç§°ä¸ºæ±‰å¯†å°”é¡¿-é›…å¯æ¯”æ–¹ç¨‹ã€‚

# è´å°”æ›¼æ–¹ç¨‹:ä»·å€¼å‡½æ•°å’Œ Q å‡½æ•°

åœ¨ä¸Šè¿°å®šä¹‰çš„ MDP ä¸­ï¼Œç›®æ ‡æ˜¯é•¿æœŸæœ€å°åŒ–ç‡ƒæ–™æ¶ˆè€—ï¼Œè´å°”æ›¼æ–¹ç¨‹åœ¨ç¡®å®šæœ€ä¼˜ç­–ç•¥ä¸­èµ·ç€é‡è¦ä½œç”¨ã€‚è´å°”æ›¼æ–¹ç¨‹æä¾›äº†çŠ¶æ€å€¼å’Œä»å½“å‰çŠ¶æ€å¯è¾¾åˆ°çš„çŠ¶æ€å€¼ä¹‹é—´çš„é€’å½’å…³ç³»ï¼Œå¯ç”¨äºé€šè¿‡æ‰¾åˆ°å¯¼è‡´å…·æœ‰æœ€é«˜å€¼çš„çŠ¶æ€çš„åŠ¨ä½œæ¥ç¡®å®šæœ€ä½³ç­–ç•¥ã€‚

è¿™ç§é€’å½’ä½¿ç”¨è¿­ä»£è®¡ç®—æœºç§‘å­¦ç®—æ³•æ¥è§£å†³ï¼Œå¦‚åŠ¨æ€è§„åˆ’å’Œçº¿æ€§è§„åˆ’ã€‚å®ƒä»¬çš„å˜åŒ–å¯¼è‡´äº†å¤šç§ RL è®­ç»ƒç®—æ³•ã€‚

çŠ¶æ€å€¼å’ŒçŠ¶æ€-åŠ¨ä½œå€¼çš„è´å°”æ›¼æ–¹ç¨‹åˆ†åˆ«ç§°ä¸ºå€¼å‡½æ•°å’Œ Q å‡½æ•°ã€‚

## ä»·å€¼å‡½æ•°

åœ¨ MDPï¼ŒçŠ¶æ€çš„å€¼è¢«å®šä¹‰ä¸ºä»å½“å‰çŠ¶æ€å¼€å§‹çš„é•¿æœŸçš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºä»·å€¼å‡½æ•°ã€‚

æ•°å­¦ä¸Šï¼Œä»·å€¼å‡½æ•°å¯ä»¥å†™æˆ

![](img/a8e3eebe43e4dbcaeac86816a7027385.png)

ç­‰å¼ 3ã€‚ä»·å€¼å‡½æ•°ã€‚

å…¶ä¸­ *P( s(t)ï¼Œa(t) )* åœ¨åŠ¨ä½œ *a(t)* çš„å½±å“ä¸‹ï¼Œä»çŠ¶æ€ *s(t)* åˆ° *s(t +1 )* çš„è½¬ç§»æ¦‚ç‡ã€‚ç­‰å¼ 3 çš„å®šä¹‰æ˜¯ä» [1](https://doi.org/10.1007/978-981-19-0638-1) å¾—åˆ°çš„å€¼å‡½æ•°çš„ä¿®æ”¹å½¢å¼ã€‚

ä»·å€¼å‡½æ•°å¯ç”¨äºé€šè¿‡å°†å½“å‰çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ä¸ä¸‹ä¸€çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ç›¸åŠ æ¥è®¡ç®—çŠ¶æ€çš„ä»·å€¼ï¼Œå…¶ä¸­ä¸‹ä¸€çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—é€šè¿‡åœ¨å½“å‰çŠ¶æ€ä¸‹å¯é‡‡å–çš„æ‰€æœ‰å¯èƒ½è¡ŒåŠ¨ä¸­å–æœ€å¤§å€¼æ¥è®¡ç®—ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥é€’å½’åœ°é‡å¤ï¼Œä»¥è®¡ç®—æ¯ä¸ªçŠ¶æ€çš„å€¼ï¼Œä»åˆå§‹çŠ¶æ€å¼€å§‹ï¼Œå‘åå·¥ä½œåˆ°æœ€ç»ˆçŠ¶æ€ã€‚

ä¸€æ—¦ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹è®¡ç®—äº†æ‰€æœ‰çŠ¶æ€çš„å€¼ï¼Œå°±å¯ä»¥é€šè¿‡æ‰¾åˆ°å¯¼è‡´æ¯ä¸ªçŠ¶æ€å…·æœ‰æœ€é«˜å€¼çš„çŠ¶æ€çš„åŠ¨ä½œæ¥ç¡®å®šæœ€ä¼˜ç­–ç•¥ã€‚ç„¶åï¼Œè¯¥æœ€ä½³ç­–ç•¥å¯ç”¨äºç¡®å®šåœ¨æ¯ä¸ªçŠ¶æ€ä¸‹é‡‡å–çš„æœ€ä½³è¡ŒåŠ¨ï¼Œä»¥ä¾¿åœ¨é•¿æœŸå†…å°†ç‡ƒæ–™æ¶ˆè€—é™è‡³æœ€ä½ã€‚

## q å‡½æ•°

åœ¨ä¸Šé¢å®šä¹‰çš„ MDP çš„æƒ…å†µä¸‹ï¼Œç›®æ ‡æ˜¯åœ¨é•¿æœŸå†…æœ€å°åŒ–ç‡ƒæ–™æ¶ˆè€—ï¼ŒQ å‡½æ•°æ˜¯å°†æ¯ä¸ªçŠ¶æ€å’ŒåŠ¨ä½œå¯¹æ˜ å°„åˆ°å®æ•°çš„å‡½æ•°ï¼Œè¡¨ç¤ºä»è¯¥çŠ¶æ€å¼€å§‹å¹¶é‡‡å–è¯¥åŠ¨ä½œçš„é•¿æœŸå†…çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ã€‚

æ•°å­¦ä¸Šï¼ŒQ å‡½æ•°å¯ä»¥å†™æˆ

![](img/98b8fb7cc54be928e9e36e4105f7bcc7.png)

ç­‰å¼ 4ã€‚q å‡½æ•°

è¿™æ˜¯åœ¨[ [1](https://doi.org/10.1007/978-981-19-0638-1) ä¸­ä½¿ç”¨çš„ Q å‡½æ•°çš„ä¿®æ”¹å½¢å¼ã€‚

å¯ä»¥ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹æ¥è®¡ç®— Q å‡½æ•°ï¼Œè¯¥æ–¹ç¨‹æä¾›äº†çŠ¶æ€å€¼å’Œä»å½“å‰çŠ¶æ€å¯ä»¥è¾¾åˆ°çš„çŠ¶æ€å€¼ä¹‹é—´çš„é€’å½’å…³ç³»ã€‚å¯ä»¥é€šè¿‡å°†å½“å‰çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ä¸ä¸‹ä¸€çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—ç›¸åŠ æ¥è®¡ç®— Q å‡½æ•°ï¼Œå…¶ä¸­ä¸‹ä¸€çŠ¶æ€ä¸‹çš„é¢„æœŸç‡ƒæ–™æ¶ˆè€—æ˜¯é€šè¿‡é‡‡å–å½“å‰çŠ¶æ€ä¸‹å¯ä»¥é‡‡å–çš„æœ€å¤§æ€»å¯èƒ½è¡ŒåŠ¨æ¥è®¡ç®—çš„ã€‚

ä¸€æ—¦ä½¿ç”¨è´å°”æ›¼æ–¹ç¨‹è®¡ç®—å‡ºæ‰€æœ‰çŠ¶æ€-åŠ¨ä½œå¯¹çš„å€¼ï¼Œå°±å¯ä»¥é€šè¿‡æ‰¾åˆ°ä½¿æ¯ä¸ªçŠ¶æ€çš„ Q å‡½æ•°æœ€å¤§åŒ–çš„åŠ¨ä½œæ¥ç¡®å®šæœ€ä½³ç­–ç•¥ã€‚ç„¶åï¼Œè¯¥æœ€ä½³ç­–ç•¥å¯ç”¨äºç¡®å®šåœ¨æ¯ä¸ªçŠ¶æ€ä¸‹é‡‡å–çš„æœ€ä½³è¡ŒåŠ¨ï¼Œä»¥ä¾¿åœ¨é•¿æœŸå†…å°†ç‡ƒæ–™æ¶ˆè€—é™è‡³æœ€ä½ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä»–ä»¬å¦‚ä½•å¯»æ‰¾æœ¬æ–‡ä¸­çš„ä¾‹å­ã€‚

```
 class MDP:
    # ...

    # Function to calculate the value function for the MDP
    def calculate_value_function(self):
        # Initialize dictionary to store values of each state
        values = {}

        # Iterate over all possible states and calculate value of each state
        for v in self.velocity_values:
            for a in self.acceleration_values:
                values[(v, a)] = self.evaluate_value(v, a, values)

        return values

    # Function to evaluate the value of a state using the Bellman equation
    def evaluate_value(self, v, a, values):
        # Check if value of current state has already been calculated
        if (v, a) in values:
            return values[(v, a)]

        # Calculate available actions in current state
        actions = self.calculate_actions(v, a)

        # Initialize maximum expected fuel consumption
        max_fuel = float("-inf")

        # Iterate over available actions and find action with maximum expected fuel consumption
        for v_new, a_new in actions:
            fuel = self.evaluate_fuel_consumption(v, a, v_new, a_new)
            if fuel > max_fuel:
                max_fuel = fuel

        # Return maximum expected fuel consumption
        return max_fuel
```

```
class MDP:
    # ...

    # Function to calculate the Q-function for the MDP
    def calculate_q_function(self):
        # Initialize dictionary to store values of each state-action pair
        q_values = {}

        # Iterate over all possible states and actions
        for v in self.velocity_values:
            for a in self.acceleration_values:
                for v_new, a_new in self.calculate_actions(v, a):
                    q_values[((v, a), (v_new, a_new))] = self.evaluate_q_value(v, a, v_new, a_new, q_values)

        return q_values

    # Function to evaluate the Q-value of a state-action pair using the Bellman equation
    def evaluate_q_value(self, v, a, v_new, a_new, q_values):
        # Check if Q-value of current state-action pair has already been calculated
        if ((v, a), (v_new, a_new)) in q_values:
            return q_values[((v, a), (v_new, a_new))]

        # Calculate expected fuel consumption in current state
        fuel = self.evaluate_fuel_consumption(v, a, v_new, a_new)

        # Calculate expected fuel consumption in next state by taking maximum over all possible actions
        max_fuel = float("-inf")
        for v_next, a_next in self.calculate_actions(v_new, a_new):
            fuel_next = self.evaluate_q_value(v_new, a_new, v_next, a_next, q_values)
            if fuel_next > max_fuel:
                max_fuel = fuel_next

        # Return expected fuel consumption in current state plus expected fuel consumption in next state
        return fuel + max_fuel
```

å½“ç„¶ï¼Œè¯¥ç¤ºä¾‹å¿½ç•¥äº†è½¬ç§»æ¦‚ç‡çš„æ¦‚å¿µï¼Œå› æ­¤ç”¨äºä¼˜åŒ–ç‡ƒæ–™æ¶ˆè€—çš„ç¤ºä¾‹çš„å€¼å‡½æ•°å’Œ Q å‡½æ•°æ¯”ç”¨äºä¸€äº›ç°å®ä¸–ç•Œçš„å®é™…é—®é¢˜è¦ç®€å•å¾—å¤šã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è®¨è®ºäº†é€šè¿‡æ±‚è§£ MDP æ¥è·å¾—æœ€ä¼˜ç­–ç•¥ã€å…³è”å€¼å‡½æ•°å’Œ Q å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å¯ç”¨äºä»¥æœ€ä¼˜æ–¹å¼æ±‚è§£ MDPã€‚

åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åœ¨å¼ºåŒ–å­¦ä¹ é—®é¢˜çš„èƒŒæ™¯ä¸‹è®¨è®ºåŠ¨æ€ç¼–ç¨‹ã€‚åœ¨ä»¥åçš„æ–‡ç« ä¸­ï¼Œæˆ‘å°†è®¨è®ºæ·±å±‚çš„ RL æ¦‚å¿µä»¥åŠåœ¨è¿™ç§åœºæ™¯ä¸­å¼•å…¥ç¥ç»ç½‘ç»œï¼Œå¹¶ç»™å‡ºä¸€äº›ä»¿çœŸç¤ºä¾‹ã€‚åŠ å…¥æˆ‘çš„[ç”µå­é‚®ä»¶åˆ—è¡¨](https://rahulbhadani.medium.com/subscribe)ï¼Œè®©æˆ‘æœªæ¥çš„æ–‡ç« ç›´æ¥å‘é€åˆ°ä½ çš„æ”¶ä»¶ç®±ã€‚

å¦‚æœä½ è¿˜æ²¡æœ‰çœ‹å®ŒåŸºé‡‘ä¼š RL ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« ï¼Œè¯·ä¸€å®šè¦å»çœ‹:[https://towards data science . com/fundamental-RL-Markov-States-Markov-chain-and-Markov-decision-process-be 8 CCC 341005](/foundational-rl-markov-states-markov-chain-and-markov-decision-process-be8ccc341005)ã€‚

> *ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿ* [*ç»™æˆ‘ä¹°æ¯å’–å•¡*](https://www.buymeacoffee.com/rahulbhadani) *ã€‚*
> 
> *çˆ±æˆ‘çš„æ–‡å­—ï¼ŸåŠ å…¥æˆ‘çš„* [*é‚®ç®±åˆ—è¡¨*](https://rahulbhadani.medium.com/subscribe) *ã€‚*
> 
> *æƒ³äº†è§£æ›´å¤š STEM ç›¸å…³è¯é¢˜ï¼ŸåŠ å…¥* [*ä¸­ç­‰*](https://rahulbhadani.medium.com/membership)

# å‚è€ƒ

1.  æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ŒAske Plaatï¼Œ[https://doi.org/10.1007/978-981-19-0638-1,](https://doi.org/10.1007/978-981-19-0638-1,)æ–½æ™®æ—æ ¼
2.  å¼ºåŒ–å­¦ä¹ å’Œéšæœºä¼˜åŒ–:è¿ç»­å†³ç­–çš„ç»Ÿä¸€æ¡†æ¶ã€‚)ï¼Œå¨åˆ©(2022)ã€‚ç²¾è£…æœ¬ã€‚ISBN 9781119815051ã€‚
3.  ç½—çº³å¾·Â·éœåå¾·(1960)ã€‚ [*åŠ¨æ€è§„åˆ’ä¸é©¬å°”å¯å¤«è¿‡ç¨‹*](http://web.mit.edu/dimitrib/www/dpchapter.pdf) (PDF)ã€‚éº»çœç†å·¥å­¦é™¢å‡ºç‰ˆç¤¾ã€‚