# å¦‚ä½•åœ¨ç”Ÿäº§ã€æœ¬åœ°å’Œ S3 ä¹‹é—´ä¼ è¾“æ–‡ä»¶

> åŸæ–‡ï¼š<https://towardsdatascience.com/how-to-transfer-files-among-prod-local-and-s3-ce073a7cbe6b>

## å¤‡ä»½ Postgresã€å¤åˆ¶ docker æ–‡ä»¶å’Œåœ¨ä¸åŒ AWS é…ç½®æ–‡ä»¶ä¹‹é—´åˆ‡æ¢çš„ä»£ç ç‰‡æ®µ

![](img/e6fd245d90910b75d94588d30e491dbb.png)

ç…§ç‰‡ç”±[ä»¥è‰²åˆ—æ€»ç»Ÿåºœ](https://unsplash.com/@othentikisra?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

æ•°æ®ç§‘å­¦å®¶å¾ˆå°‘ä¼šæ”¶åˆ°å¦‚ä¸‹è¯·æ±‚:

1.  æ‚¨èƒ½ä»ç”Ÿäº§æœºå™¨ä¸Šå¤‡ä»½ stage å’Œæœ¬åœ° Postgres æ•°æ®åº“å—ï¼Ÿ
2.  ä½ èƒ½ä»ç”Ÿäº§æœºå™¨ docker æœåŠ¡å™¨ä¸Šå¤åˆ¶ X æ–‡ä»¶å¹¶ä¿å­˜åˆ°æœ¬åœ°æœºå™¨ä¸Šå—ï¼Ÿ
3.  ä¸ºä½ çš„å®¢æˆ·ä¸Šä¼  X æ–‡ä»¶åˆ° AWS s3 æ€ä¹ˆæ ·ï¼Ÿ(æç¤º:æ‚¨å¯èƒ½æœ‰å¤šä¸ª AWS æ¦‚è¦æ–‡ä»¶)

å¦‚æœä½ ç»å†è¿‡ç±»ä¼¼çš„æƒ…å†µï¼Œä½†ä¸çŸ¥é“å¦‚ä½•å¤„ç†ï¼Œæˆ‘å¸Œæœ›æˆ‘ä¸‹é¢çš„ä»£ç ç‰‡æ®µå¯ä»¥å¸®åŠ©ä½ æ¢å¤å†·é™å’Œå†…å¿ƒçš„å¹³é™ã€‚

# å¦‚ä½•:ä»ç”Ÿäº§è®¡ç®—æœºå¤‡ä»½ stage å’Œæœ¬åœ° Postgres æ•°æ®åº“

åœ¨æˆ‘ä»¬å…¬å¸ï¼Œæˆ‘ä»¬åªèƒ½ ssh åˆ° prod æœºï¼Œè€Œä¸” Postgres æ•°æ®åº“éå¸¸å¤§ã€‚å› æ­¤ï¼Œä»¥ä¸‹æ˜¯é€‚åˆæˆ‘ä»¬å›¢é˜Ÿçš„è§£å†³æ–¹æ¡ˆ:

*   **ç¬¬ 0 æ­¥**:åœ¨æœ¬åœ°æœºå™¨ä¸Šå®‰è£…`zstd`ã€‚`zstd`æ˜¯ä¸€ç§å‹ç¼©ç®—æ³•ï¼Œå¯ä»¥å¸®åŠ©å‡å° Postgres `pg_dump`æ–‡ä»¶çš„å¤§å°ã€‚

```
# in your terminal
$ brew install zstd
```

*   **æ­¥éª¤ 1** : ssh åˆ°æ‚¨çš„ç”Ÿäº§æœºå™¨(å¦‚æœæ‚¨ä¸ç¡®å®šå¦‚ä½• ssh åˆ°æ‚¨çš„ç”Ÿäº§æœºå™¨ï¼Œè¯·å‘æ‚¨çš„ DevOps åŒäº‹å¯»æ±‚å¸®åŠ©ï¼)

```
$ ssh [alias for prod] 
$ pg_dump -T [table1] -c | zstd -T32 -19 -c > /tmp/prod.psql.zstd
```

ä¸Šé¢çš„å‘½ä»¤=â€œå¯¹é™¤è¡¨ 1 ä¹‹å¤–çš„æ‰€æœ‰è¡¨è¿è¡Œ pg_dumpâ€ã€‚è¯¥å‘½ä»¤å‹ç¼©`pg_dump`æ–‡ä»¶å¹¶å°†å…¶å­˜å‚¨åœ¨ç”Ÿäº§æœºå™¨çš„ä¸´æ—¶æ–‡ä»¶å¤¹ä¸­ã€‚

*   **æ­¥éª¤ 2** :å°† zstd è¾“å‡ºä¸‹è½½åˆ°æœ¬åœ°æœºå™¨

æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯ï¼Œå¹¶`cd`åˆ°ä½ æƒ³è¦ä¿å­˜æ–‡ä»¶çš„ç›®å½•ã€‚ä¾‹å¦‚`Downloads`:

```
$ cd Downloads/
$ scp discovery-prod:/tmp/prod.psql.zstd .
```

å‘½ä»¤ä»¥ä¸€ç§è¶…çº§å¹²å‡€çš„æ–¹å¼å°†æ–‡ä»¶ä» prod å¤åˆ¶åˆ°ä½ çš„æœ¬åœ°ï¼å°±åƒã€Šå“ˆåˆ©Â·æ³¢ç‰¹ã€‹ä¸­çš„*å¹½çµ*ğŸ’

*   ç¬¬ 3 æ­¥:ç”¨`zstd`æ–‡ä»¶
    å¤‡ä»½æ‚¨çš„æœ¬åœ°æˆ–ç™»å°æ•°æ®åº“ç¡®ä¿åœ¨æ‚¨çš„ç™»å°ç¯å¢ƒä¸­åˆ é™¤æ•°æ®åº“ä¹‹å‰å…ˆä¸æ‚¨çš„ DevOps å›¢é˜Ÿè®¨è®ºã€‚

```
# I feel pretty free to do so on my local machine$ dropdb discovery_db
$ createdb discovery_db
$ cat prod.psql.zstd | zstd -dc | psql discovery_db
```

# å¦‚ä½•:ä»ç”Ÿäº§æœºå™¨ docker æœåŠ¡å™¨å¤åˆ¶ X æ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¿å­˜åˆ°æœ¬åœ°æœºå™¨

å—¯ï¼Œç±»ä¼¼äºä¸Šé¢çš„è¿‡ç¨‹ï¼Œè¿™é‡Œå”¯ä¸€çš„æ–°ä¸œè¥¿æ˜¯ä»ä¸€ä¸ªç‰¹å®šçš„ docker å®¹å™¨ä¸­æŠ“å–ç‰¹å®šçš„æ–‡ä»¶ã€‚

```
# step 0: ssh to your production machine. 
$ ssh prod# step 1: show your docker container 
$ docker ps# step 2: copy a file under specific container ID
# Here I'm trying to copy a meltano.db file# step 3: copy file and store it in temp folder
$ docker cp [container_id]:/projects/.meltano/meltano.db /tmp/meltano.db
```

ç±»ä¼¼åœ°ï¼Œæ‚¨å¯ä»¥æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯å¹¶ä½¿ç”¨`scp`å°†`meltano.db`æ–‡ä»¶ä» production temp æ–‡ä»¶å¤¹ä¸‹è½½åˆ°æ‚¨çš„æœ¬åœ°æœºå™¨ã€‚ä»¥ä¸‹æ˜¯æˆªå›¾:

![](img/acbb119aad5f747d99c17a49fbbdff63.png)

é¢å¤–æç¤º:

*   ä½ å¯ä»¥äº¤æ›¿ä½¿ç”¨`docker container ls`å’Œ`docker ps`
*   Docker å®¹å™¨æ–‡ä»¶å¤¹å¯èƒ½ä¼šå˜å¾—éå¸¸å¤§ï¼Œæœ‰æ—¶æ‚¨å¯èƒ½å¸Œæœ›åˆ é™¤æ—§çš„æœªä½¿ç”¨çš„å®¹å™¨æ¥é‡Šæ”¾ç©ºé—´ã€‚æ‚¨å¯ä»¥è¿™æ ·åš:

```
# Run both to stop and remove the folder$ docker stop [container_id]$ docker rm [container_id]
```

æˆ‘æƒ³å¯¼å‡º`meltano.db`çš„åŸå› æ˜¯å› ä¸ºæˆ‘ä»¬æ³¨æ„åˆ°è¿™ä¸ªæ–‡ä»¶çš„å¤§å°ä»¥æ„æƒ³ä¸åˆ°çš„é€Ÿåº¦å¢é•¿ã€‚æ‰€ä»¥æˆ‘ä»¬æƒ³å¯¼å‡ºè¿™ä¸ªæ–‡ä»¶ä»¥ä¾›è¿›ä¸€æ­¥åˆ†æã€‚ä¸‹é¢æ˜¯æ˜¾ç¤ºæ–‡ä»¶å¤§å°çš„å¦ä¸€ä¸ªæŠ€å·§:

*   `du -h --max-depth=1`:æ˜¾ç¤ºè¯¥ç›®å½•ä¸‹çš„æ–‡ä»¶
*   `ls -alh`:è¿™å°†ä»¥äººç±»å¯è¯»çš„æ–¹å¼æ˜¾ç¤º`.`ä¸‹çš„æ–‡ä»¶åŠå…¶å¤§å°ã€‚

![](img/82ffcf683ac55ff6a1365369616bf171.png)

# å¦‚ä½•:è®¾ç½®å¤šä¸ª AWS æ¦‚è¦æ–‡ä»¶å¹¶å°†æ–‡ä»¶ä¸Šä¼ åˆ° s3

ä¾‹å¦‚ï¼Œæˆ‘æƒ³é…ç½®ä¸¤ä¸ªé…ç½®æ–‡ä»¶:ä¸€ä¸ªç”¨äºæˆ‘çš„å¤–éƒ¨å…¬å¸ï¼Œå¦ä¸€ä¸ªç”¨äºè®¿é—®å®¢æˆ·çš„å…¬å¸ã€‚æ‚¨éœ€è¦é¢„å…ˆè·å¾—ä¸¤ä¸ªæ¦‚è¦æ–‡ä»¶çš„ AWS è®¿é—®å¯†é’¥å’Œç§˜å¯†å¯†é’¥ã€‚

```
# step0: check your default profile list
$ aws configure list# Configure my profile 1: wen_outside
$ aws configure --profile wen_outside
# follow the steps to filling the blanks
AWS Access Key ID [None]: [fill your info]
AWS Secret Access Key [None]: [fill your info]
Default region name [None]: [fill your info] # example: us-east-1 
Default output format [None]: json# Configure my profile 2: wen_client
$ aws configure --profile wen_client
# follow the steps to filling the blanks
AWS Access Key ID [None]: [fill your info]
AWS Secret Access Key [None]: [fill your info]
Default region name [None]: [fill your info] 
Default output format [None]: json# Now check to see your profile list
$ aws configure list-profiles
```

ä¸‹ä¸€æ­¥æ˜¯å¦‚ä½•åœ¨é…ç½®æ–‡ä»¶ä¹‹é—´åˆ‡æ¢:

```
# Switch to my outside profile
$ export AWS_DEFAULT_PROFILE=wen_outside
```

æœ€åï¼Œå‡è®¾æˆ‘éœ€è¦å°†`meltano.db`ä¸Šä¼ åˆ°æˆ‘ä»¬å®¢æˆ·çš„ s3:

```
# switch to my profile wen_client
$ export AWS_PROFILE=wen_client# from local to S3: for single file
$ aws s3 cp meltano.db [client's s3 directory]# from S3 to current directory
$ aws s3 cp [s3 directory] .# from local to S3: sync the whole folder "forClient"
$ aws s3 sync forClient [client's s3 directory]
```

# æ‘˜è¦

*   å’Œå…¶ä»–ä¸€äº›æ•°æ®ç§‘å­¦å®¶ä¸€æ ·ï¼Œæˆ‘ä¹Ÿæœ‰ç±»ä¼¼çš„æ‹…å¿ƒï¼Œä¸ç”Ÿäº§æœºå™¨(é€šå¸¸æ˜¯ Linus å’Œ Ubuntu ç³»ç»Ÿ)äº¤äº’å¯èƒ½ä¼šä»¤äººç”Ÿç•ã€‚è¿™äº›ä»»åŠ¡æˆ‘åšå¾—ä¸å¤Ÿé¢‘ç¹ï¼Œä»¥è‡³äºæˆ‘å»ºç«‹äº†è‚Œè‚‰è®°å¿†ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œå¦‚æœæ‚¨å¯¹æ­¤ç±»ä»£ç ç‰‡æ®µä¿æŒè‰¯å¥½çš„æ–‡æ¡£è®°å½•ï¼Œè¿™ç§æ‹…å¿ƒæ˜¯å¯ä»¥å…‹æœçš„ã€‚