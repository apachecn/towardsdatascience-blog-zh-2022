# Python ä¸­çš„é¢„æµ‹åŒºé—´

> åŸæ–‡ï¼š<https://towardsdatascience.com/prediction-intervals-in-python-64b992317b1a>

![](img/0e05d9a378669285c1b549a7d6a9e5ea.png)

å›¾ä¸º[èˆ’å·´å§†Â·è¾¾å‰](https://unsplash.com/@theshubhamdhage?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## æ•°æ®ç§‘å­¦åŸºç¡€

## äº†è§£è·å¾—é¢„æµ‹åŒºé—´çš„ä¸‰ç§æ–¹æ³•

å¦‚æœè®©ä½ çŒœæˆ‘è¿‡å»ä¸€å‘¨çœ‹äº†å¤šå°‘éƒ¨ç”µå½±ï¼Œä½ ä¼šè§‰å¾—çŒœâ€œ2 åˆ° 6â€è¿˜æ˜¯â€œ3â€æ›´æœ‰æŠŠæ¡ï¼Ÿæˆ‘ä»¬å¯èƒ½ä¼šåŒæ„ï¼ŒçŒœæµ‹ä¸€ä¸ªèŒƒå›´æ¯”çŒœæµ‹ä¸€ä¸ªæ•°å­—æ›´æœ‰å¯èƒ½æ˜¯æ­£ç¡®çš„ã€‚åŒæ ·ï¼Œä¸å•å€¼é¢„æµ‹ç›¸æ¯”ï¼Œé¢„æµ‹åŒºé—´ä¸ºæˆ‘ä»¬æä¾›äº†æ›´å¯é ã€æ›´é€æ˜çš„ä¼°è®¡ã€‚åœ¨æœ¬å¸–ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åœ¨ Python ä¸­è·å¾—é¢„æµ‹åŒºé—´çš„ä¸‰ç§æ–¹æ³•ã€‚

![](img/48927058485663340650e7b27bdd1ab7.png)

ç…§ç‰‡ç”±[æ³•åº“é‡Œå®‰è®¾è®¡](https://unsplash.com/@fakurian?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

# ğŸ“¦ 0.è®¾ç½®

æˆ‘ä»¬å°†ä»åŠ è½½å¿…è¦çš„åº“å’Œæ ·æœ¬æ•°æ®å¼€å§‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Scikit-learn å…³äº[ç³–å°¿ç—…](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)çš„å†…ç½®æ•°æ®é›†(*è¯¥æ•°æ®åœ¨ BSD è®¸å¯ä¸‹å¯ç”¨*)ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºæ•°æ®é›†çš„ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨`print(diabetes[â€˜DESCRâ€™])`æŸ¥çœ‹å®ƒçš„æè¿°ã€‚

```
import numpy as np
np.set_printoptions(
    formatter={'float': lambda x: "{:.4f}".format(x)}
)
import pandas as pd
pd.options.display.float_format = "{:.4f}".format
from scipy.stats import t
import statsmodels.api as sm
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressorimport matplotlib.pyplot as plt
import seaborn as sns
sns.set(style='darkgrid', context='talk')diabetes = load_diabetes(as_frame=True)
df = diabetes['data']
df['target'] = diabetes['target']
df.info()
```

![](img/16e6fe25115ba6d9b2c5420668ce5ee2.png)

è®©æˆ‘ä»¬å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†:

```
train, test = train_test_split(df, test_size=0.1, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(
    df.drop(columns='target'), df['target'], test_size=0.1, 
    random_state=42
)
x_train = X_train['bmi']
x_test = X_test['bmi']print(f"X_train shape: {X_train.shape}")
print(f"x_train shape: {x_train.shape}")
print(f"y_train shape: {y_train.shape}")
print("\n========== Training data ==========")
display(train[['target']].describe().T)print(f"X_test shape: {X_test.shape}")
print(f"x_test shape: {x_test.shape}")
print(f"y_test shape: {y_test.shape}")print("\n========== Test data ==========")
test[['target']].describe().T
```

![](img/34c458ce7d4bb5cd2a0c7014071dd98d.png)

ç›®æ ‡èŒƒå›´ä» 25 åˆ° 350ï¼Œå¹³å‡å€¼çº¦ä¸º 150ï¼Œä¸­ä½æ•°çº¦ä¸º 130-140ã€‚

# ğŸ“ 1.é¢„æµ‹æ•°çš„å˜åŒ–èŒƒå›´

æˆ‘ä»¬ç°åœ¨æ¥çœ‹çœ‹è·å¾—é¢„æµ‹åŒºé—´çš„ä¸‰ç§æ–¹æ³•ã€‚

## ğŸ’¡ 1.1.ä½¿ç”¨æ ‡å‡†è¯¯å·®

è®©æˆ‘ä»¬ä½¿ç”¨`bmi`å»ºç«‹ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¥é¢„æµ‹`target`ã€‚

```
model = LinearRegression()
model.fit(x_train.values.reshape(-1, 1), y_train)
print(f"Intercept: {model.intercept_:.2f}")
print(f"Slope: {model.coef_[0]:.2f}")
print(model.predict(x_test.values.reshape(-1, 1))[:5])
```

![](img/4eaeecbe11a5068883ae0a2f80e78961.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°é¢„æµ‹ï¼Œæˆ‘ä»¬æœ€å¥½çš„çŒœæµ‹ã€‚ä½¿ç”¨ä¸‹é¢çš„å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æ ‡å‡†è¯¯å·®å¹¶è·å¾—é¢„æµ‹åŒºé—´:

![](img/2a35cf7c5a59facd1eeb587e985e1c38.png)

ç»¿æ¡†ä¸­çš„å˜é‡æ˜¯é’ˆå¯¹æˆ‘ä»¬æ­£åœ¨è¿›è¡Œé¢„æµ‹çš„ç‰¹å®šè§‚å¯Ÿçš„ï¼Œè€Œå…¶ä½™çš„æ˜¯æ ¹æ®è®­ç»ƒæ•°æ®è®¡ç®—çš„ã€‚

è¯¥å…¬å¼å¯ä»¥ç¿»è¯‘æˆå¦‚ä¸‹ä»£ç ã€‚æˆ‘ä»¬ä½¿ç”¨è‡ªå®šä¹‰å¯¹è±¡ï¼Œå› ä¸ºå®ƒæ¯”å‡½æ•°æ›´çµæ´»:

```
class CustomLinearRegression:
    def __init__(self):
        pass

    def fit(self, x, y):
        # Calculate stats
        self.n = len(x)
        self.x_mean = np.mean(x)
        self.y_mean = np.mean(y)
        self.x_gap = x-self.x_mean
        self.y_gap = y-self.y_mean
        self.ss = np.square(self.x_gap).sum()

        # Find coefficients
        self.slope = np.dot(self.x_gap, self.y_gap)/self.ss
        self.intercept = self.y_mean-self.slope*self.x_mean

        # Find training error
        y_pred = self.intercept+self.slope*x
        self.se_regression = np.sqrt(
            np.square(y-y_pred).sum()/(self.n-2)
        )

    def predict(self, x):
        y_pred = self.intercept+self.slope*x
        return y_pred

    def predict_interval(self, x, alpha=0.1):
        t_stat = t.ppf(1-alpha/2, df=self.n-2)

        # Calculate interval upper and lower boundaries
        df = pd.DataFrame({'x': x})
        for i, value in df['x'].iteritems():
            se = self.se_regression * np.sqrt(
                1+1/self.n+np.square(value-self.x_mean)/self.ss
            )
            df.loc[i, 'y_pred'] = self.intercept+self.slope*value
            df.loc[i, 'lower'] = df.loc[i, 'y_pred']-t_stat*se
            df.loc[i, 'upper'] = df.loc[i, 'y_pred']+t_stat*se
        return df

custom_model = CustomLinearRegression()     
custom_model.fit(x_train, y_train)
print(f"Intercept: {custom_model.intercept:.2f}")
print(f"Slope: {custom_model.slope:.2f}")
custom_pred = custom_model.predict_interval(x_test)
custom_pred.head()
```

![](img/febf74ba914527d63c4ad242aeeb019f.png)

è®©æˆ‘ä»¬æ¥ç†è§£è¿™ä¸ªè¾“å‡ºã€‚åœ¨çº¿æ€§å›å½’ä¸­ï¼Œé¢„æµ‹ä»£è¡¨æ¡ä»¶å¹³å‡ç›®æ ‡å€¼ã€‚å› æ­¤`y_pred`ï¼Œæˆ‘ä»¬çš„é¢„æµ‹æ ï¼Œå‘Šè¯‰æˆ‘ä»¬ç»™å®šç‰¹å¾çš„ä¼°è®¡å¹³å‡ç›®æ ‡ã€‚é¢„æµ‹åŒºé—´å‘Šè¯‰æˆ‘ä»¬*å¯¹äºä¸€ä¸ªç»™å®šçš„è®°å½•*ç›®æ ‡å¯ä»¥å–å€¼çš„èŒƒå›´ã€‚æˆ‘ä»¬å¯ä»¥ä»`lower`å’Œ`upper`åˆ—ä¸­çœ‹åˆ°é¢„æµ‹åŒºé—´çš„ä¸Šä¸‹è¾¹ç•Œã€‚è¿™æ˜¯ä¸€ä¸ª 90%çš„é¢„æµ‹åŒºé—´ï¼Œå› ä¸ºæˆ‘ä»¬é€‰æ‹©äº†`alpha=0.1`ã€‚æˆ‘ä»¬å°†åœ¨è¿™ç¯‡æ–‡ç« çš„å‰©ä½™éƒ¨åˆ†ä½¿ç”¨ç›¸åŒçš„ alpha å€¼ã€‚

å¦‚æœä½ å¾ˆå¥½å¥‡ï¼Œè¿™é‡Œæœ‰ä¸€äº›è§£é‡Šé¢„æµ‹åŒºé—´çš„æ–¹æ³•:

*   è®°å½• 287 çš„å®é™…ç›®æ ‡å€¼æœ‰ 90%çš„å¯èƒ½æ€§åœ¨ 42.8550 å’Œ 249.4799 ä¹‹é—´ã€‚
*   æ ¹æ®è®°å½• 287 çš„`bmi`å€¼ï¼Œæˆ‘ä»¬æœ‰ 90%çš„æŠŠæ¡è®¤ä¸ºå…¶å®é™…ç›®æ ‡å€¼å°†ä»‹äº 42.8550 å’Œ 249.4799 ä¹‹é—´ã€‚
*   å¤§çº¦ 90%çš„é¢„æµ‹åŒºé—´å°†åŒ…å«å®é™…å€¼ã€‚

è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹æµ‹è¯•æ•°æ®ä¸­çš„ç›®æ ‡å€¼åœ¨é¢„æµ‹åŒºé—´å†…çš„ç™¾åˆ†æ¯”:

```
custom_correct = np.mean(
    (custom_pred['lower']<y_test) & (y_test<custom_pred['upper'])
)
print(f"{custom_correct:.2%} of the prediction intervals contain true target.")
```

![](img/c01e853802ca426ad35208eb5af60845.png)

è¿™å¤§æ¦‚æ˜¯ 90%ã€‚è™½ç„¶æ‰‹åŠ¨è®¡ç®—æœ‰åŠ©äºæˆ‘ä»¬ç†è§£å¹•åå‘ç”Ÿçš„äº‹æƒ…ï¼Œä½†æ›´å®é™…çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åº“å¹¶ç®€åŒ–æˆ‘ä»¬çš„å·¥ä½œã€‚ä¸‹é¢æ˜¯æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨`statsmodels`åŒ…æ¥è·å¾—ç›¸åŒçš„é¢„æµ‹é—´éš”:

```
sm_model = sm.OLS(y_train, sm.add_constant(x_train)).fit()
print(f"Intercept: {sm_model.params[0]:.2f}")
print(f"Slope: {sm_model.params[1]:.2f}")sm_pred = sm_model.get_prediction(sm.add_constant(x_test))\
                  .summary_frame(alpha=0.1)
sm_pred.head()
```

![](img/7b4865924b23a50686de2dd3f5d5e15c.png)

è¿™ä¸ªè¾“å‡ºæä¾›äº†ä¸€äº›é¢å¤–çš„è¾“å‡ºï¼Œè®©æˆ‘ä»¬æ¥ç†è§£å…¶ä¸­çš„å…³é”®:
â—¼ï¸ `mean`:é¢„æµ‹ï¼Œä¸å‰é¢çš„`y_pred`ç›¸åŒã€‚
â—¼ï¸ `mean_ci_lower` & `mean_ci_upper`:ç½®ä¿¡åŒºé—´è¾¹ç•Œ
â—¼ï¸ `obs_ci_lower` & `obs_ci_upper`:é¢„æµ‹åŒºé—´è¾¹ç•Œï¼ŒåŒå‰é¢çš„`lower`å’Œ`upper`ã€‚

æˆ‘ä»¬å¯ä»¥æ£€æŸ¥é¢„æµ‹å’Œé¢„æµ‹é—´éš”æ˜¯å¦ä¸æ‰‹åŠ¨è®¡ç®—çš„ç›¸åŒ¹é…:

```
np.mean(np.isclose(
    custom_pred.drop(columns='x').values, 
    sm_pred[['mean', 'obs_ci_lower', 'obs_ci_upper']]), 
        axis=0)
```

![](img/298c680923d221239a7bd33b465686d6.png)

å¯çˆ±ï¼Œå¾ˆé…ï¼

ç°åœ¨ï¼Œä½ å¯èƒ½æƒ³çŸ¥é“ç½®ä¿¡åŒºé—´å’Œé¢„æµ‹åŒºé—´çš„åŒºåˆ«ã€‚è™½ç„¶è¿™äº›æœ¯è¯­ç›¸äº’å…³è”ï¼Œå¬èµ·æ¥æœ‰äº›ç›¸ä¼¼ï¼Œä½†å®ƒä»¬æŒ‡çš„æ˜¯ä¸¤ä¸ªä¸åŒçš„åŒºé—´ï¼Œä¸åº”äº’æ¢ä½¿ç”¨:
â—¼ï¸ç½®ä¿¡åŒºé—´ç”¨äºå‡å€¼é¢„æµ‹ã€‚ä¸é¢„æµ‹åŒºé—´ä¸åŒï¼Œç½®ä¿¡åŒºé—´å¹¶æ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬*ä¸€ä¸ªè§‚å¯Ÿå¯ä»¥é‡‡ç”¨çš„ç›®æ ‡å€¼çš„èŒƒå›´*ã€‚ç›¸åï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬ç›®æ ‡å¹³å‡å€¼çš„èŒƒå›´ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªè§£é‡Šç¤ºä¾‹:æœ‰ 90%çš„å¯èƒ½æ€§ï¼Œç‰¹å¾å€¼ä¸è®°å½• 287 ç›¸åŒçš„è®°å½•çš„å¹³å‡ç›®æ ‡å€¼å°†è½åœ¨ 140.9452 å’Œ 151.3897 ä¹‹é—´ã€‚
â—¼ï¸è™½ç„¶ä¸¤ä¸ªåŒºé—´éƒ½ä»¥é¢„æµ‹ä¸ºä¸­å¿ƒï¼Œä½†é¢„æµ‹åŒºé—´çš„æ ‡å‡†è¯¯å·®å¤§äºç½®ä¿¡åŒºé—´çš„æ ‡å‡†è¯¯å·®ã€‚å› æ­¤ï¼Œé¢„æµ‹åŒºé—´æ¯”ç½®ä¿¡åŒºé—´å®½ã€‚

æˆ‘ä»¬é€šè¿‡ç®€å•çš„çº¿æ€§å›å½’æ¥äº†è§£è¿™ä¸ªæ¦‚å¿µï¼Œä½†æ˜¯åœ¨å®è·µä¸­æ›´å¸¸è§çš„æ˜¯æœ‰å¤šä¸ªç‰¹å¾ã€‚æ˜¯æ—¶å€™æ‰©å±•æˆ‘ä»¬çš„ç¤ºä¾‹ä»¥ä½¿ç”¨å…¨éƒ¨åŠŸèƒ½äº†:

```
ols = sm.OLS(y_train, sm.add_constant(X_train)).fit()
test[['ols_lower', 'ols_upper']] = (ols
    .get_prediction(sm.add_constant(X_test))
    .summary_frame(alpha=0.1)[['obs_ci_lower', 'obs_ci_upper']])
columns = ['target', 'ols_lower', 'ols_upper']
test[columns].head()
```

![](img/8a8a9a108db59e033899acdfb9c2950d.png)

æµç¨‹ä¸ä½¿ç”¨å•ä¸ªç‰¹å¾å®Œå…¨ç›¸åŒã€‚å¦‚æœä½ å¾ˆæƒ³çŸ¥é“åœ¨å¤šé‡ç‰¹å¾å­˜åœ¨çš„æƒ…å†µä¸‹å…¬å¼æ˜¯å¦‚ä½•å˜åŒ–çš„ï¼Œè¯·æŸ¥çœ‹æœ¬æŒ‡å—ã€‚è®©æˆ‘ä»¬è¯„ä¼°ä¸€ä¸‹æˆ‘ä»¬çš„æ—¶é—´é—´éš”:

```
ols_correct = np.mean(
    test['target'].between(test['ols_lower'], test['ols_upper'])
)
print(f"{ols_correct:.2%} of the prediction intervals contain true target.")
```

![](img/83bf758d7052de704fad75a5f5110857.png)

## 1.2.æ¥è‡ªåˆ†ä½æ•°å›å½’

ä½¿ç”¨åˆ†ä½æ•°å›å½’ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æµ‹ç›®æ ‡çš„*æ¡ä»¶åˆ†ä½æ•°ï¼Œè€Œä¸æ˜¯æ¡ä»¶å‡å€¼ç›®æ ‡ã€‚ä¸ºäº†è·å¾— 90%çš„é¢„æµ‹åŒºé—´ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸¤ä¸ªåˆ†ä½æ•°å›å½’ï¼Œä¸€ä¸ªé¢„æµ‹ç¬¬ 5 ä¸ªç™¾åˆ†ä½æ•°ï¼Œå¦ä¸€ä¸ªé¢„æµ‹ç¬¬ 95 ä¸ªç™¾åˆ†ä½æ•°ã€‚*

```
alpha = 0.1
quant_lower = sm.QuantReg(
    y_train, sm.add_constant(X_train)
).fit(q=alpha/2)
test['quant_lower'] = quant_lower.predict(
    sm.add_constant(X_test)
)quant_upper = sm.QuantReg(
    y_train, sm.add_constant(X_train)
).fit(q=1-alpha/2)
test['quant_upper'] = quant_upper.predict(
    sm.add_constant(X_test)
)
columns.extend(['quant_lower', 'quant_upper'])
test[columns].head()
```

![](img/44aa289def441991d092e05c64121d51.png)

è¿™é‡Œï¼Œ`quant_lower`æ¨¡å‹é¢„æµ‹ä¸è¶³ï¼Œè€Œ`quant_upper`æ¨¡å‹é¢„æµ‹è¿‡åº¦ã€‚ç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥åœ¨æ–°é—´éš”å†…çš„é¢„æµ‹çš„ç™¾åˆ†æ¯”:

```
quant_correct = np.mean(
    test['target'].between(test['quant_lower'], test['quant_upper'])
)
print(f"{quant_correct:.2%} of the prediction intervals contain true target.")
```

![](img/dba617a258302bf8f5e3035717b91307.png)

ç•¥ä½äº 90%ï¼Œè¦†ç›–ç‡ç•¥ä½äºä»¥å‰ã€‚

## 1.3.ä»æœ‰åˆ†ä½æ•°æŸå¤±çš„ GBM

æœ€åä¸€ç§æ–¹æ³•ä¸å‰ä¸€ç§æ–¹æ³•éå¸¸ç›¸ä¼¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨åˆ†ä½æ•°æŸå¤±çš„`GradientBoostingRegressor`,é€šè¿‡ä¸¤ä¸ªæ¨¡å‹è·å¾— 90%çš„é¢„æµ‹åŒºé—´:

```
gbm_lower = GradientBoostingRegressor(
    loss="quantile", alpha=alpha/2, random_state=0
)
gbm_upper = GradientBoostingRegressor(
    loss="quantile", alpha=1-alpha/2, random_state=0
)gbm_lower.fit(X_train, y_train)
gbm_upper.fit(X_train, y_train)test['gbm_lower'] = gbm_lower.predict(X_test)
test['gbm_upper'] = gbm_upper.predict(X_test)
columns.extend(['gbm_lower', 'gbm_upper'])
test[columns].head()
```

![](img/127919da5d6f79158c97a52dde1aa62a.png)

è¯„ä¼°æ—¶é—´é—´éš”è¦†ç›–èŒƒå›´çš„æ—¶é—´:

```
gbm_correct = np.mean(
    test['target'].between(test['gbm_lower'], test['gbm_upper'])
)
print(f"{gbm_correct:.2%} of the prediction intervals contain true target.")
```

![](img/ee47d0b2e451cecfd0feeee97c45abf7.png)

ä¸ä»¥å‰çš„åŒºé—´ç›¸æ¯”ï¼Œè¿™ä¸€æ•°å€¼è¾ƒä½ã€‚æŸ¥çœ‹ä¸Šé¢çš„ç¤ºä¾‹è®°å½•ï¼Œä¸å‰ä¸¤ç§æ–¹æ³•ç›¸æ¯”ï¼Œé—´éš”çœ‹èµ·æ¥ç¨å¾®çª„ä¸€äº›ã€‚å¯¹äºæˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡ç« ä¸­å­¦åˆ°çš„ä»»ä½•æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‡å°‘ alpha æ¥å¢åŠ è¦†ç›–ç‡ã€‚ç„¶è€Œï¼Œè¿™æ„å‘³ç€é—´éš”å¯èƒ½å˜å¾—å¤ªå®½ï¼Œä»¥è‡³äºå®ƒä»¬å¯èƒ½ä¸å¤ªèƒ½æä¾›ä¿¡æ¯æˆ–å¯¹å†³ç­–æ²¡æœ‰å¸®åŠ©ã€‚å› æ­¤ï¼Œåœ¨ä½¿ç”¨é¢„æµ‹åŒºé—´æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»æ‰¾åˆ°æ­£ç¡®çš„å¹³è¡¡ç‚¹ã€‚

ç°åœ¨è®©æˆ‘ä»¬ç›´è§‚åœ°æ¯”è¾ƒæ‰€æœ‰ä¸‰ä¸ªåŒºé—´:

```
test = test.sort_values('target').reset_index()plt.figure(figsize=(10,6))
sns.scatterplot(data=test, x=test.index, y='target',
                color='grey')
sns.lineplot(data=test, x=test.index, y='ols_lower', 
             color='hotpink')
sns.lineplot(data=test, x=test.index, y='ols_upper', 
             color='hotpink', label='Linear Regression')sns.lineplot(data=test, x=test.index, y='quant_lower', 
             color='blue')
sns.lineplot(data=test, x=test.index, y='quant_upper', 
             color='blue', label='Quantile Regression')sns.lineplot(data=test, x=test.index, y='gbm_lower', 
             color='green')
sns.lineplot(data=test, x=test.index, y='gbm_upper', 
             color='green', label='Gradient Boosting Machine')
plt.xticks([]);
```

![](img/cd0371a213395442dd947df7b8da899b.png)

è¶Šæ¥è¿‘æœ€å°å€¼å’Œæœ€å¤§å€¼çš„å€¼è¶Šæœ‰å¯èƒ½è¶…å‡ºé¢„æµ‹åŒºé—´ã€‚è®©æˆ‘ä»¬è¿›ä¸€æ­¥ç ”ç©¶è¿™äº›é”™è¯¯ã€‚æˆ‘ä»¬å°†æŸ¥çœ‹å…·æœ‰æœ€é«˜ç›®æ ‡çš„ 5 é¡¹è®°å½•:

```
test[columns].nlargest(5, 'target')
```

![](img/ee423087d78d6a91e244b34dd929cc70.png)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦ä¸€ç«¯:

```
test[columns].nsmallest(5, 'target')
```

![](img/ed2b87e21fab1d2477c7cdaf59da9e96.png)

çº¿æ€§å›å½’é¢„æµ‹åŒºé—´çš„ä¸‹é™æœ‰æ—¶æ˜¯è´Ÿå€¼ã€‚è¿™æ˜¯éœ€è¦æ³¨æ„çš„äº‹æƒ…ã€‚å¦‚æœæˆ‘ä»¬çŸ¥é“ç›®æ ‡æ€»æ˜¯æ­£çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŒ…è£…å‡½æ•°ç”¨æœ€ä½å¯èƒ½çš„å€¼è¦†ç›–è¿™äº›è´Ÿè¾¹ç•Œã€‚

ç§ï¼Œè¿™å°±æ˜¯è®¡ç®—é¢„æµ‹åŒºé—´çš„ä¸‰ç§æ–¹æ³•ï¼å¸Œæœ›æ‚¨èƒ½åœ¨ä¸‹ä¸€ä¸ªå›å½’ç”¨ä¾‹ä¸­ä½¿ç”¨è¿™äº›æ–¹æ³•ã€‚

![](img/c2a299a427c63a87baafa6a1c214d624.png)

å¡å·´æ–¯è’‚å®‰Â·æ–¯æ–‡æ£®åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

*æ‚¨æƒ³è®¿é—®æ›´å¤šè¿™æ ·çš„å†…å®¹å—ï¼Ÿåª’ä½“ä¼šå‘˜å¯ä»¥æ— é™åˆ¶åœ°è®¿é—®åª’ä½“ä¸Šçš„ä»»ä½•æ–‡ç« ã€‚å¦‚æœä½ ä½¿ç”¨* [*æˆ‘çš„æ¨èé“¾æ¥*](https://zluvsand.medium.com/membership)*æˆä¸ºä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šè´¹ä¼šç›´æ¥å»æ”¯æŒæˆ‘ã€‚*

è°¢è°¢ä½ çœ‹æˆ‘çš„å¸–å­ã€‚å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¿™é‡Œæœ‰æˆ‘çš„ä¸€äº›å¸–å­çš„é“¾æ¥:

â—¼ï¸ï¸ [ç®¡é“ã€ColumnTransformer å’Œ FeatureUnion è§£é‡Š](/pipeline-columntransformer-and-featureunion-explained-f5491f815f?source=your_stories_page-------------------------------------)
â—¼ï¸ï¸ [FeatureUnionã€ColumnTransformer &ç®¡é“ç”¨äºé¢„å¤„ç†æ–‡æœ¬æ•°æ®](/featureunion-columntransformer-pipeline-for-preprocessing-text-data-9dcb233dbcb6)
â—¼ï¸ [ç”¨è¿™äº›æç¤ºä¸°å¯Œæ‚¨çš„ Jupyter ç¬”è®°æœ¬](/enrich-your-jupyter-notebook-with-these-tips-55c8ead25255)
â—¼ï¸ [ç”¨è¿™äº›æç¤ºç»„ç»‡æ‚¨çš„ Jupyter ç¬”è®°æœ¬](/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f)
â—¼ï¸ [è§£é‡Š Scikit-ç”¨ SHAP å­¦ä¹ æ¨¡å‹](/explaining-scikit-learn-models-with-shap-61daff21b12a)
â—¼ï¸ï¸ [åœ¨ scikit ä¸­é€‰æ‹©ç‰¹æ€§](/feature-selection-in-scikit-learn-dc005dcf38b7)

å†è§ğŸƒğŸ’¨