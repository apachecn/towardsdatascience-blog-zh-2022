# 31 ä¸ªç‹¬ç‰¹çš„ Python åŒ…æ¥æ”¹è¿›æ‚¨çš„æ•°æ®å·¥ä½œæµ

> åŸæ–‡ï¼š<https://towardsdatascience.com/31-uniques-python-packages-to-improve-your-data-workflow-4f9762fc8f8b>

## é¢å‘æ•°æ®äººå‘˜çš„å„ç§ Python åŒ…

![](img/00a233fcc0190b96a4a3c62f2b256e2a.png)

äºšå†å±±å¤§Â·å¸­é»˜å…‹åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

æ•°æ®æ˜¯ä¸€ä¸ªå¹¿é˜”çš„é¢†åŸŸï¼Œæœ‰å¤§é‡çš„ç¤¾åŒºæ”¯æŒæŠ€æœ¯å‘å±•ã€‚æ­¤å¤–ï¼ŒPython æ‹¥æœ‰çƒ­å¿ƒçš„æ”¯æŒè€…ï¼Œå¸®åŠ©æ•°æ®ä¸–ç•Œå˜å¾—æ›´å®¹æ˜“è®¿é—®ï¼Œå¹¶ä¸ºæ•°æ®å·¥ä½œæµå¸¦æ¥ä»·å€¼ã€‚

å·²ç»å¼€å‘äº†å„ç§ Python åŒ…æ¥å¸®åŠ©æ•°æ®äººå‘˜çš„å·¥ä½œã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œè®¸å¤šæœ‰ç”¨çš„æ•°æ® Python åŒ…ç¼ºä¹è®¤çŸ¥åº¦ï¼Œæˆ–è€…ä»åœ¨æµè¡Œã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘æƒ³å‘æ‚¨ä»‹ç»å‡ ä¸ªç‹¬ç‰¹çš„ Python åŒ…ï¼Œå®ƒä»¬å°†åœ¨è®¸å¤šæ–¹é¢å¸®åŠ©æ‚¨çš„æ•°æ®å·¥ä½œæµã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼

## 1.æ•²é—¨

[Knockknock](https://github.com/huggingface/knockknock/blob/master/README.md/) æ˜¯ä¸€ä¸ªç®€å•çš„ Python åŒ…ï¼Œç”¨äºåœ¨æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå®Œæˆæˆ–å´©æºƒæ—¶é€šçŸ¥ä½ ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç”µå­é‚®ä»¶ã€Slackã€å¾®è½¯å›¢é˜Ÿç­‰å¤šç§æ¸ é“è·å¾—é€šçŸ¥ã€‚

ä¸ºäº†å®‰è£…è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‹é¢çš„ä»£ç ã€‚

```
pip install knockknock
```

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å‘æ‚¨çš„ Gmail ç”µå­é‚®ä»¶åœ°å€é€šçŸ¥æ‚¨çš„æœºå™¨å­¦ä¹ å»ºæ¨¡åŸ¹è®­çŠ¶æ€ã€‚

```
from knockknock import email_sender
from sklearn.linear_model import LinearRegression
import numpy as np@email_sender(recipient_emails=["<your_email@address.com>", "<your_second_email@address.com>"], sender_email="<sender_email@gmail.com>")def train_linear_model(your_nicest_parameters): x = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
    y = np.dot(x, np.array([1, 2])) + 3 
    regression = LinearRegression().fit(x, y) 

    return regression.score(x, y)
```

æ— è®ºä½ è¿”å›å“ªä¸ªå‡½æ•°ï¼Œä½ éƒ½ä¼šå¾—åˆ°é€šçŸ¥ã€‚

## 2.tqdm

å½“ä½ åšä¸€ä¸ªè¿­ä»£æˆ–è€…å¾ªç¯è¿‡ç¨‹æ—¶ï¼Œä½ éœ€è¦ä¸€ä¸ªè¿›åº¦æ¡å—ï¼Ÿé‚£ä¹ˆ [tqdm](https://github.com/tqdm/tqdm) å°±æ˜¯ä½ çš„ç­”æ¡ˆã€‚è¿™ä¸ªåŒ…ä¼šåœ¨ä½ çš„ç¬”è®°æœ¬æˆ–å‘½ä»¤æç¤ºç¬¦ä¸­æä¾›ä¸€ä¸ªç®€å•çš„è¿›åº¦æ¡ã€‚

è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install tqdm
```

ç„¶åæˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥æ˜¾ç¤ºå¾ªç¯è¿‡ç¨‹ä¸­çš„è¿›åº¦æ¡ã€‚

```
from tqdm import tqdm
q = 0
for i in tqdm(range(10000000)):
    q = i +1
```

![](img/a16c7877c480bd45bc9af1e586402ca1.png)

ä½œè€… GIF

æ­£å¦‚ä½ åœ¨ä¸Šé¢çš„ GIF ä¸­çœ‹åˆ°çš„ï¼Œä½ çš„ç¬”è®°æœ¬ä¸­æ˜¾ç¤ºäº†ä¸€ä¸ªæ¼‚äº®çš„è¿›åº¦æ¡ã€‚å½“æ‚¨æœ‰ä¸€ä¸ªå¤æ‚çš„è¿­ä»£å¹¶ä¸”æƒ³è¦è·Ÿè¸ªè¿›åº¦æ—¶ï¼Œå®ƒä¼šæœ‰ç”¨å¾—å¤šã€‚

## 3.ç†ŠçŒ«-æ—¥å¿—

[Pandas-log](https://github.com/eyaltrabelsi/pandas-log) æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œæä¾›å¯¹ç†ŠçŒ«åŸºæœ¬æ“ä½œçš„åé¦ˆï¼Œæ¯”å¦‚`.query`ã€`.drop`ã€`.merge`ç­‰ç­‰ã€‚å®ƒåŸºäº R Tidyverseï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥ç†è§£æ‰€æœ‰çš„æ•°æ®åˆ†ææ­¥éª¤ã€‚

è®©æˆ‘ä»¬å°è¯•å®‰è£…è½¯ä»¶åŒ…ã€‚

```
pip install pandas-log
```

å®‰è£…è½¯ä»¶åŒ…åï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ•°æ®æ¡†ã€‚

```
import pandas as pd
import numpy as np
import pandas_logdf = pd.DataFrame({"name": ['Alfred', 'Batman', 'Catwoman'],
                   "toy": [np.nan, 'Batmobile', 'Bullwhip'],
                   "born": [pd.NaT, pd.Timestamp("1940-04-25"),   pd.NaT]})
```

ç„¶åï¼Œè®©æˆ‘ä»¬ç”¨ä¸‹é¢çš„ä»£ç å°è¯•åšä¸€ä¸ªç®€å•çš„ç†ŠçŒ«æ‰§è¡Œã€‚

```
with pandas_log.enable():
    res = (df.drop("born", axis = 1)
             .groupby('name')
          )
```

![](img/40c28fb7179814966d1c49ee290aa7cc.png)

ä½œè€…å›¾ç‰‡

æœ‰äº† Pandas-logï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ‰€æœ‰çš„æ‰§è¡Œä¿¡æ¯ã€‚

## 4.è¡¨æƒ…ç¬¦å·

é¡¾åæ€ä¹‰ï¼Œ[è¡¨æƒ…ç¬¦å·](https://github.com/carpedm20/emoji/)æ˜¯ä¸€ä¸ªæ”¯æŒè¡¨æƒ…ç¬¦å·æ–‡æœ¬æ•°æ®åˆ†æçš„ Python åŒ…ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬åœ¨é˜…è¯» Python çš„è¡¨æƒ…ç¬¦å·æ—¶ä¼šæœ‰å›°éš¾ï¼Œä½†æ˜¯è¡¨æƒ…ç¬¦å·åŒ…å¯ä»¥å¸®åŠ©æˆ‘ä»¬ã€‚

ä½¿ç”¨ä»¥ä¸‹ä»£ç å®‰è£…è¡¨æƒ…åŒ…ã€‚

```
pip install emoji
```

è®©æˆ‘ä»¬å°è¯•ä¸€ä¸ªç®€å•çš„åŒ…è£…è¡¨æƒ…ç¬¦å·ã€‚

```
import emoji
print(emoji.emojize('Python is :thumbs_up:'))
```

![](img/936316691c1fca44aa4ed923925809e7.png)

ä½œè€…å›¾ç‰‡

æœ‰äº†è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬å¯ä»¥è¾“å‡ºè¡¨æƒ…ç¬¦å·ï¼Œå› ä¸ºè¡¨æƒ…ç¬¦å·å·²ç»è¢«è§£ç æˆ Python ä¸­å¯æ¥å—çš„ã€‚

## 5.TheFuzz

[TheFuzz](https://github.com/seatgeek/thefuzz) æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œå®ƒä½¿ç”¨ [Levenshtein è·ç¦»](https://en.wikipedia.org/wiki/Levenshtein_distance)è®¡ç®—ç›¸ä¼¼åº¦æ¥åŒ¹é…æ–‡æœ¬ã€‚

è¦ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®‰è£…å®ƒã€‚

```
pip install thefuzz
```

è®©æˆ‘ä»¬è¯•è¯•è¿™ä¸ªåŒ…ï¼Œçœ‹çœ‹æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ TheFuzz åŒ…æ¥è¿›è¡Œç›¸ä¼¼æ€§æ–‡æœ¬åŒ¹é…ã€‚

```
from thefuzz import fuzz, process#Testing the score between two sentences
fuzz.ratio("Test the word", "test the Word!")
```

![](img/6efe8667c0dc96e87dba3cb0f55b858a.png)

ä½œè€…å›¾ç‰‡

Fuzz è¿˜å¯ä»¥åŒæ—¶ä»è®¸å¤šå•è¯ä¸­æå–ç›¸ä¼¼æ€§åˆ†æ•°ã€‚

```
choices = ["Atlanta Falcons", "New York Jets", "New York Giants", "Dallas Cowboys"]
process.extract("new york jets", choices, limit=2)
```

![](img/24e854a6681332837938e945771547f6.png)

ä½œè€…å›¾ç‰‡

Fuzz é€‚ç”¨äºä»»ä½•æ–‡æœ¬æ•°æ®ç›¸ä¼¼æ€§æ´»åŠ¨ã€‚å®ƒåº”è¯¥æ˜¯ä½ çš„æ­¦å™¨åº“ä¸­çš„ä¸€ä¸ªåŒ…ã€‚

## 6.æ•°å­—è®¡ç®—å™¨

[Numerizer](https://github.com/jaidevd/numerizer) æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œå®ƒå°†ä¹¦å†™çš„æ•°å­—æ–‡æœ¬è½¬æ¢æˆæ•´æ•°æˆ–æµ®ç‚¹æ•°ã€‚è®©æˆ‘ä»¬è¯•è¯•è¿™ä¸ªåŒ…æ¥äº†è§£æ›´å¤šã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‹é¢çš„ä»£ç å®‰è£…è¿™ä¸ªåŒ…ã€‚

```
pip install numerizer
```

ç„¶åæˆ‘ä»¬å¯ä»¥æµ‹è¯•è¿™ä¸ªåŒ…ã€‚æˆ‘ä»¬æ¥è¯•è¯•å‡ ä¸ªè¯æ¥è½¬åŒ–ã€‚

```
from numerizer import numerize
numerize('forty two')
```

![](img/7d3badf2c2a505195a7a6435b9ef3b88.png)

ä½œè€…å›¾ç‰‡

å¦‚æ‚¨æ‰€è§ï¼Œå•è¯è¢«è½¬æ¢æˆäº†å®ƒä»¬çš„æ•´æ•°å¯¹åº”ç‰©ã€‚å¦‚æœä½ ä½¿ç”¨å¦ä¸€ç§ä¹¦å†™é£æ ¼ï¼Œæ¯”å¦‚ä¸‹é¢çš„ï¼Œå®ƒä¹Ÿæ˜¯æœ‰æ•ˆçš„ã€‚

```
numerize('forty-two')
```

![](img/250c3a28b9c36e3c99b0cf14a9c71680.png)

ä½œè€…å›¾ç‰‡

å®ƒä¹Ÿé€‚ç”¨äºè¡¨ç¤ºæµ®ç‚¹æ•°å­—æ–‡æœ¬çš„å•è¯ã€‚

```
numerize('nine and three quarters')
```

![](img/cb1ad0810469df762a8c4abc0c21b51d.png)

ä½œè€…å›¾ç‰‡

å¦‚æœå•è¯ä¸æ˜¯ä¸€ä¸ªæ•°å­—è¡¨è¾¾å¼ï¼Œå®ƒä»¬ä¼šä¿æŒåŸæ ·ã€‚

```
numerize('maybe around nine and three quarters')
```

![](img/cb152e3c654c0d0e31f7e24d654b9424.png)

ä½œè€…å›¾ç‰‡

è¿™ä¸ªåŒ…å¾ˆç®€å•ï¼Œä½†æ˜¯åœ¨å¾ˆå¤šåœºåˆéƒ½å¾ˆæœ‰ç”¨ã€‚

## 7.PyAutoGUI

PyAutoGUI æ˜¯ä¸€ä¸ªç®€å•çš„ Python åŒ…ï¼Œå¯ä»¥è‡ªåŠ¨æ§åˆ¶é¼ æ ‡å’Œé”®ç›˜ã€‚å®ƒçš„å·¥ä½œåŸç†æ˜¯åœ¨ä½ çš„ IDE ä¸­ä¼ é€’ä»£ç å¹¶è®©å®ƒä»¬ä¸ºä½ å·¥ä½œã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install pyautogui
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥æµ‹è¯•è¿™ä¸ªåŠ¨ä½œã€‚

```
import pyautogui
pyautogui.moveTo(10, 15)
pyautogui.click()
pyautogui.doubleClick()
pyautogui.press('enter')
```

ä¸Šé¢çš„ä»£ç ä¼šå°†é¼ æ ‡ç§»åŠ¨åˆ°æŸä¸ªä½ç½®å¹¶ç‚¹å‡»ä½ çš„é¼ æ ‡ã€‚é€šè¿‡æŒ‰ä¸‹åŠŸèƒ½ï¼Œä½ ä¹Ÿå¯ä»¥æŒ‰ä¸‹æŸä¸ªé”®ç›˜æŒ‰é’®ã€‚

å½“ä½ éœ€è¦åƒä¸‹è½½æ–‡ä»¶æˆ–æ”¶é›†æ•°æ®è¿™æ ·çš„é‡å¤æ€§åŠ¨ä½œæ—¶ï¼Œè¿™ä¸ªåŒ…éå¸¸æœ‰ç”¨ã€‚

## 8.åŠ æƒè®¡ç®—

[Weightedcalcs](https://github.com/jsvine/weightedcalcs) æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œç”¨äºç®€åŒ–åŸºäºæˆ‘ä»¬çš„æ•°æ®æ¡†æ¶çš„åŠ æƒç»Ÿè®¡è®¡ç®—ã€‚ä»ç®€å•çš„ç»Ÿè®¡ï¼Œå¦‚åŠ æƒå¹³å‡å€¼ã€ä¸­å€¼å’Œæ ‡å‡†åå·®ï¼Œåˆ°åŠ æƒè®¡æ•°å’Œåˆ†å¸ƒï¼Œç”¨æ³•å„ä¸ç›¸åŒã€‚

ä¸ºäº†ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥å®‰è£…å®ƒã€‚

```
pip install weightedcalcs
```

è®©æˆ‘ä»¬è¯•ç€ç”¨ç°æœ‰çš„æ•°æ®æ¥è®¡ç®—ä¸€ä¸ªåŠ æƒåˆ†å¸ƒã€‚

```
import seaborn as sns
df = sns.load_dataset('mpg')
```

æˆ‘ä¼šä½¿ç”¨ seaborn åŒ…ä¸­çš„ MPG æ•°æ®é›†ã€‚ä¸ºäº†è®¡ç®—åŠ æƒç»Ÿè®¡é‡ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆç”¨åŠ æƒå˜é‡å£°æ˜ç±»ã€‚

```
import weightedcalcs as wc
calc = wc.Calculator("mpg")
```

ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¯¥ç±»é€šè¿‡ä¼ é€’æ•°æ®é›†å’Œè®¡ç®—é¢„æœŸå˜é‡æ¥è¿›è¡ŒåŠ æƒè®¡ç®—ã€‚

```
calc.distribution(df, "origin")
```

![](img/e73ca4bbc4d0a7d0374478f8ef08cbc7.png)

ä½œè€…å›¾ç‰‡

## 9.scikit-posthocs

[scikit-posthocs](https://github.com/maximtrp/scikit-posthocs) æ˜¯ä¸€ä¸ªç”¨äºäº‹åæµ‹è¯•åˆ†æçš„ python åŒ…ï¼Œé€šå¸¸ç”¨äºç»Ÿè®¡åˆ†æä¸­çš„æˆå¯¹æ¯”è¾ƒã€‚è¿™ä¸ªåŒ…æä¾›äº†ç®€å•çš„ scikit-learn API æ¥è¿›è¡Œåˆ†æã€‚è®©æˆ‘ä»¬ä»å®‰è£…è½¯ä»¶åŒ…åˆ°è¯•ç”¨å®ƒå¼€å§‹ã€‚

```
pip install scikit-posthocs
```

é‚£ä¹ˆè®©æˆ‘ä»¬ä»ç®€å•çš„æ•°æ®é›†å¼€å§‹ï¼Œåœ¨è¯•ç”¨è¿™ä¸ªåŒ…ä¹‹å‰åšä¸€ä¸ª ANOVA æµ‹è¯•ã€‚

```
import statsmodels.api as sa
import statsmodels.formula.api as sfa
import scikit_posthocs as sp
df = sa.datasets.get_rdataset('iris').data
df.columns = df.columns.str.replace('.', '')lm = sfa.ols('SepalWidth ~ C(Species)', data=df).fit()
anova = sa.stats.anova_lm(lm)
print(anova)
```

![](img/d53ef7f60c3b80eff2628999ee2158bd.png)

ä½œè€…å›¾ç‰‡

æˆ‘ä»¬è·å¾—äº† ANOVA æµ‹è¯•ç»“æœï¼Œä½†ä¸ç¡®å®šå“ªä¸ªå˜é‡ç±»åˆ«å¯¹ç»“æœçš„å½±å“æœ€å¤§ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦ä½¿ç”¨ä¸‹é¢çš„ä»£ç è¿›è¡Œäº‹åæµ‹è¯•ã€‚

```
sp.posthoc_ttest(df, val_col='SepalWidth', group_col='Species', p_adjust='holm')
```

![](img/1c0534bbabcfd115cc51d4257fd7de3a.png)

ä½œè€…å›¾ç‰‡

ä½¿ç”¨ scikit-posthocï¼Œæˆ‘ä»¬ç®€åŒ–äº†äº‹åæ£€éªŒçš„æˆå¯¹åˆ†æè¿‡ç¨‹ï¼Œå¹¶è·å¾—äº† P å€¼ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šçš„äº‹åæµ‹è¯•ï¼Œä½ å¯ä»¥åœ¨æˆ‘ä¸‹é¢çš„å¦ä¸€ç¯‡æ–‡ç« ä¸­è¯»åˆ°æ›´å¤šã€‚

</multiple-hypothesis-testing-correction-for-data-scientist-46d3a3d1611d>  

## 10.youtube_dl

[youtube_dl](https://github.com/ytdl-org/youtube-dl) æ˜¯ä¸€ä¸ªç®€å•çš„ python åŒ…ï¼Œé€šè¿‡æä¾›ä»£ç é“¾æ¥æ¥ä¸‹è½½ youtube è§†é¢‘ã€‚è®©æˆ‘ä»¬å…ˆå®‰è£…åŒ…æ¥è¯•è¯•è¿™ä¸ªåŒ…ã€‚

```
pip install youtube_dl
```

ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç å°†è§†é¢‘ä¸‹è½½åˆ°æ‚¨çš„ç¯å¢ƒä¸­ã€‚

```
# Youtube Dl Example
import youtube_dl
ydl_opt = {}with youtube_dl.YoutubeDL(ydl_opt) as ydl:
    ydl.download(['[https://www.youtube.com/watch?v=ukzFI9rgwfU'](https://www.youtube.com/watch?v=ukzFI9rgwfU')])
```

![](img/10e5c4ae647f5b08ddc0cf1267d042d5.png)

ä½œè€…å›¾ç‰‡

ä¸‹è½½è¿‡ç¨‹å°†å¼€å§‹ï¼Œmp4 æ ¼å¼çš„è§†é¢‘å°†å¯ç”¨ã€‚

## 11.åœ°ç‹±çŠ¬åº§

Cerberus æ˜¯ä¸€ä¸ªè½»é‡çº§ python åŒ…ï¼Œç”¨äºæ•°æ®éªŒè¯æ´»åŠ¨ã€‚å®ƒæ—¨åœ¨éªŒè¯æˆ‘ä»¬å‘èµ·çš„ä»»ä½•æ¨¡å¼æ•°æ®ä»¥åŠåŸºäºå®ƒçš„æ•°æ®ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install cerberus
```

Cerberus çš„åŸºæœ¬ç”¨æ³•æ˜¯å¯åŠ¨éªŒè¯å™¨ç±»æ¥æ‹¥æœ‰æ•°æ®æ¨¡å¼ã€‚

```
from cerberus import Validator
schema = {'name': {'type': 'string'}, 'gender':{'type': 'string'}, 'age':{'type':'integer'}}
v = Validator(schema)
```

ç„¶åï¼Œä½¿ç”¨æˆ‘ä»¬ä¼ é€’ç»™éªŒè¯å™¨ç±»çš„æ¨¡å¼ï¼Œæˆ‘ä»¬å¯ä»¥éªŒè¯ä¼ é€’ç»™ä»£ç çš„æ•°æ®ã€‚

```
document = {'name': 'john doe', 'gender':'male', 'age': 15}
v.validate(document)
```

![](img/a3f50c19d382e83fc47393c0e678f9bd.png)

ä½œè€…å›¾ç‰‡

å¦‚æœä¼ é€’çš„æ•°æ®ä¸æ¨¡å¼ç›¸ä¼¼ï¼Œé‚£ä¹ˆéªŒè¯å™¨ç±»å°†å¾—åˆ°çœŸå®çš„è¾“å‡ºã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æ•°æ®è¾“å…¥å¯¹äºæ¨¡å¼æ€»æ˜¯å¯é çš„ã€‚

## 12.ppscore

[ppscore](https://github.com/8080labs/ppscore) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨æ¥è®¡ç®—å…³äºç›®æ ‡å˜é‡çš„å˜é‡é¢„æµ‹èƒ½åŠ›ã€‚è¯¥è½¯ä»¶åŒ…è®¡ç®—å¯ä»¥æ£€æµ‹ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„çº¿æ€§æˆ–éçº¿æ€§å…³ç³»çš„åˆ†æ•°ã€‚å¾—åˆ†èŒƒå›´ä» 0(æ— é¢„æµ‹èƒ½åŠ›)åˆ° 1(å®Œç¾é¢„æµ‹èƒ½åŠ›)ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®‰è£…è½¯ä»¶åŒ…è¿›è¡Œæµ‹è¯•ã€‚

```
pip install ppscore
```

ç„¶åä½¿ç”¨å¯ç”¨çš„æ•°æ®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ppscore åŒ…æ¥è®¡ç®—åŸºäºç›®æ ‡çš„åˆ†æ•°ã€‚

```
import seaborn as sns
import ppscore as ppsdf = sns.load_dataset('mpg')
pps.predictors(df, 'mpg')
```

![](img/20572f2eb0c3672a1009cc62c7e5bf66.png)

ä½œè€…å›¾ç‰‡

ç»“æœæ˜¯æ ¹æ®ç›®æ ‡åŠå…¶ ppscore å¯¹å˜é‡è¿›è¡Œæ’åºã€‚æ’åè¶Šä½ï¼Œå˜é‡å¯¹ç›®æ ‡çš„é¢„æµ‹èƒ½åŠ›è¶Šä½ã€‚

## 13.ç›é›…äºº

Maya æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨äºå°½å¯èƒ½è½»æ¾åœ°è§£ææ—¥æœŸæ—¶é—´æ•°æ®ã€‚å®ƒä½¿ç”¨ä¸€ç§ç®€å•çš„äººç±»å¯è¯»çš„äº¤äº’æ¥è·å–æˆ‘ä»¬æƒ³è¦çš„æ—¥æœŸæ—¶é—´æ•°æ®ã€‚è®©æˆ‘ä»¬é€šè¿‡é¦–å…ˆå®‰è£…å®ƒæ¥å¼€å§‹ä½¿ç”¨è¿™ä¸ªåŒ…ã€‚

```
 pip install maya
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç è½»æ¾è®¿é—®å½“å‰æ—¥æœŸã€‚

```
import maya
now = maya.now()
print(now)
```

![](img/2a19c17c95a72b889b866c132856a377.png)

ä½œè€…å›¾ç‰‡

æˆ‘ä»¬è¿˜å¯ä»¥ä¸ºæ˜å¤©çš„æ—¥æœŸåˆå§‹åŒ–ä¸€ä¸ªå¯¹è±¡ç±»ã€‚

```
tomorrow = maya.when('tomorrow')
tomorrow.datetime()
```

![](img/ff266961a638e0d9b3d1f1fa556e2efb.png)

ä½œè€…å›¾ç‰‡

è¿™ä¸ªåŒ…å¯¹äºä»»ä½•ä¸æ—¶é—´åºåˆ—ç›¸å…³çš„æ´»åŠ¨éƒ½å¾ˆæœ‰ç”¨ï¼Œæ‰€ä»¥è¯•è¯•å§ã€‚

## 14.é’Ÿæ‘†

[Pendulum](https://pendulum.eustace.io/) æ˜¯å¦ä¸€ä¸ªå…³æ³¨æ—¥æœŸæ—¶é—´æ•°æ®çš„ python åŒ…ã€‚å®ƒç”¨äºç®€åŒ–ä»»ä½•æ—¥æœŸæ—¶é—´åˆ†æè¿‡ç¨‹ã€‚è®©æˆ‘ä»¬ä»å¯¼å…¥åŒ…å¼€å§‹ã€‚

```
pip install pendulum 
```

ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°è®¿é—®æ—¶é—´ï¼Œå¹¶ç”¨ä¸‹é¢çš„ä»£ç æ›´æ”¹å®ƒã€‚

```
import pendulumnow = pendulum.now("Europe/Berlin")# Changing timezone
now.in_timezone("Asia/Tokyo")# Default support for common datetime formats
now.to_iso8601_string()# Day Shifting
now.add(days=2)
```

![](img/0d938b2da83a80b51bec8fbe0f1099a2.png)

ä½œè€…å›¾ç‰‡

## 15.ç±»åˆ« _ ç¼–ç å™¨

[category_encoders](https://github.com/scikit-learn-contrib/category_encoders) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨äºç±»åˆ«æ•°æ®ç¼–ç (è½¬æ¢æˆæ•°å€¼æ•°æ®)ã€‚è¿™ä¸ªåŒ…æ˜¯å„ç§ç¼–ç æ–¹æ³•çš„é›†åˆï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®éœ€è¦å°†è¿™äº›æ–¹æ³•åº”ç”¨äºå„ç§åˆ†ç±»æ•°æ®ã€‚

ä¸ºäº†è¯•ç”¨è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…è¿™ä¸ªåŒ…ã€‚

```
pip install category_encoders
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä¾‹å­æ¥åº”ç”¨è½¬æ¢ã€‚

```
from category_encoders import BinaryEncoder
import pandas as pd# use binary encoding to encode two categorical features
enc = BinaryEncoder(cols=['origin']).fit(df)# transform the dataset
numeric_dataset = enc.transform(df)
numeric_dataset.head()
```

![](img/9ce7c1ccf76b8becda44a868698fc627.png)

ä½œè€…å›¾ç‰‡

## 16.sci kit-å¤šé‡å­¦ä¹ 

[scikit-multilearn](http://scikit.ml/index.html) æ˜¯ä¸“é—¨é’ˆå¯¹å¤šç±»åˆ†ç±»æ¨¡å‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„ python åŒ…ã€‚è¯¥è½¯ä»¶åŒ…æä¾›äº†ç”¨äºè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„ APIï¼Œä»¥é¢„æµ‹å…·æœ‰ä¸¤ä¸ªä»¥ä¸Šç±»ç›®æ ‡çš„æ•°æ®é›†ã€‚

è®©æˆ‘ä»¬é€šè¿‡é¦–å…ˆå®‰è£…å®ƒæ¥å¼€å§‹ä½¿ç”¨è¿™ä¸ªåŒ…ã€‚

```
pip install scikit-multilearn
```

ä½¿ç”¨æ ·æœ¬æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¤šæ ‡ç­¾ KNN æ¥è®­ç»ƒåˆ†ç±»å™¨å¹¶æµ‹é‡æ€§èƒ½æŒ‡æ ‡ã€‚

```
from skmultilearn.dataset import load_dataset
from skmultilearn.adapt import MLkNN
import sklearn.metrics as metricsX_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')
X_test, y_test, _, _ = load_dataset('emotions', 'test')classifier = MLkNN(k=3)
prediction = classifier.fit(X_train, y_train).predict(X_test)metrics.hamming_loss(y_test, prediction)
```

![](img/572aa19720c26d2c583dec873596b919.png)

ä½œè€…å›¾ç‰‡

## 17.å¤šé‡é›†

Multiset æ˜¯ä¸€ä¸ªç®€å•çš„ Python åŒ…ï¼Œç±»ä¼¼äºå†…ç½®çš„ set å‡½æ•°ï¼Œä½†æ˜¯è¿™ä¸ªåŒ…å…è®¸å¤šæ¬¡å‡ºç°ã€‚

```
pip install multiset
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥ä½¿ç”¨ Multiset å‡½æ•°ã€‚

```
from multiset import Multiset
set1 = Multiset('aab')
set1
```

![](img/e8d1dd799b8203a21329d612d9fe4a64.png)

ä½œè€…å›¾ç‰‡

æ‚¨è¿˜å¯ä»¥æµ‹è¯•ç”¨äºæ¯”è¾ƒå’Œæ•°æ®å¯å˜æ€§çš„å„ç§å‡½æ•°ã€‚

## 18.çˆµå£«éŸ³ä¹

[Jazzit](https://github.com/sangarshanan/jazzit) æ˜¯ä¸€ä¸ªå¯çˆ±è€Œæœ‰è¶£çš„ python åŒ…ï¼Œå¯ä»¥åœ¨ä»£ç å‡ºé”™æˆ–ç­‰å¾…ä»£ç è¿è¡Œæ—¶æ’­æ”¾éŸ³ä¹ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install jazzit
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç åœ¨å‡ºé”™çš„æƒ…å†µä¸‹å°è¯•æ ·æœ¬éŸ³ä¹ã€‚

```
from jazzit import error_track[@error_track](http://twitter.com/error_track)("curb_your_enthusiasm.mp3", wait=5)
def run():
    for num in reversed(range(10)):
        print(10/num)
```

å‡ºé”™æ—¶ä¼šæ’­æ”¾éŸ³ä¹ï¼Œæ‰€ä»¥ä¸è¦æƒŠè®¶ã€‚

## 19.æ‰‹æ‘‡è®¡ç®—å™¨

[handcalcs](https://github.com/connorferster/handcalcs) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨æ¥ç®€åŒ–ç¬”è®°æœ¬æ¸²æŸ“çš„æ•°å­¦ latex è¿‡ç¨‹ã€‚å®ƒå°†ä»»ä½•æ•°å­¦å‡½æ•°è½¬åŒ–ä¸ºæ–¹ç¨‹å½¢å¼ã€‚

è¦å®‰è£…è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç ã€‚

```
pip install handcalcs
```

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥å¿…è¦çš„åŒ…ã€‚

```
import handcalcs.render
from math import sqrt
```

ç„¶åæˆ‘ä»¬å°†å°è¯•ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥æµ‹è¯• handcalcs åŒ…ã€‚ä½¿ç”¨`%%render` magic å‘½ä»¤æ¸²æŸ“ Latex è®¡ç®—ã€‚

```
%%rendera = 4
b = 6
c = sqrt(3*a + b/7)
```

![](img/a96df7c2d08fdb2259ebd124db740a19.png)

ä½œè€…å›¾ç‰‡

## 20.æ•´æ´æ–‡æœ¬

NeatText æ˜¯ä¸€ä¸ªç®€å•çš„ python åŒ…ï¼Œå®ƒç®€åŒ–äº†æ–‡æœ¬æ¸…ç†å’Œæ–‡æœ¬æ•°æ®çš„é¢„å¤„ç†ã€‚å®ƒå¯¹ä»»ä½• NLP é¡¹ç›®å’Œæ–‡æœ¬æœºå™¨å­¦ä¹ é¡¹ç›®æ•°æ®éƒ½å¾ˆæœ‰ç”¨ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install neattext
```

ä½¿ç”¨ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥è¯•ç”¨è¿™ä¸ªåŒ…ã€‚

```
import neattext as nt 
mytext = "This is the word sample but ,our WEBSITE is [https://exaempleeele.com](https://exaempleeele.com) ğŸ˜Šâœ¨."
docx = nt.TextFrame(text=mytext)
```

`TextFrame`ç”¨äºå¯åŠ¨ NeatText ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å„ç§å‡½æ•°æ¥æè¿°æ•°æ®å’Œæ¸…ç†æ•°æ®ã€‚

```
docx.describe()
```

![](img/3e1a8b36c0ef5cdadaf02ad29e4d7405.png)

ä½œè€…å›¾ç‰‡

ä½¿ç”¨ describe å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£æˆ‘ä»¬éœ€è¦çŸ¥é“çš„æ¯ä¸ªæ–‡æœ¬ç»Ÿè®¡ã€‚

ä¸ºäº†è¿›ä¸€æ­¥æ¸…ç†æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç ã€‚

```
docx.normalize()
```

![](img/dc384ccb88ea36fa469b32223974e2c8.png)

ä½œè€…å›¾ç‰‡

æ¸…ç†æ•°æ®è¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œä½†æ˜¯æœ‰å¾ˆå¤šåŠŸèƒ½æ”¹è¿›äº†é¢„å¤„ç†ã€‚

## 21.å°å‹çˆµå£«ä¹é˜Ÿ

[Combo](https://github.com/yzhao062/combo) æ˜¯ä¸€ä¸ªç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹å’Œåˆ†æ•°ç»„åˆçš„ python åŒ…ã€‚è¯¥è½¯ä»¶åŒ…æä¾›äº†ä¸€ä¸ªå·¥å…·ç®±ï¼Œå…è®¸å°†å„ç§æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒåˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ã€‚å®ƒè¢«è§†ä¸ºé›†æˆå­¦ä¹ æ¨¡å‹ä¸­çš„ä¸€ä¸ªå­ä»»åŠ¡ã€‚

è¦è¯•ç”¨è¿™ä¸ªåŒ…ï¼Œè®©æˆ‘ä»¬å…ˆå®‰è£…å®ƒã€‚

```
pip install combo
```

æˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨ä» scikit-learn è·å¾—çš„ä¹³è…ºç™Œæ•°æ®é›†å’Œä» scikit-learn è·å¾—çš„å„ç§åˆ†ç±»æ¨¡å‹æ¥åˆ›å»ºæœºå™¨å­¦ä¹ ç»„åˆã€‚

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥æ‰€æœ‰é‡è¦çš„åŒ…ã€‚

```
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancerfrom combo.models.classifier_stacking import Stacking
from combo.utils.data import evaluate_print
```

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ç”¨äºé¢„æµ‹ç›®æ ‡çš„å•ä¸ªåˆ†ç±»å™¨ã€‚

```
# Define data file and read X and y
random_state = 42
X, y = load_breast_cancer(return_X_y=True)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,
                                                        random_state=random_state)# initialize a group of clfs
classifiers = [DecisionTreeClassifier(random_state=random_state),
                   LogisticRegression(random_state=random_state),
                   KNeighborsClassifier(),
                   RandomForestClassifier(random_state=random_state),
                   GradientBoostingClassifier(random_state=random_state)]
clf_names = ['DT', 'LR', 'KNN', 'RF', 'GBDT']# evaluate individual classifiers
for i, clf in enumerate(classifiers):
    clf.fit(X_train, y_train)
    y_test_predict = clf.predict(X_test)
    evaluate_print(clf_names[i] + '   |   ', y_test, y_test_predict)
    print()
```

![](img/806e36ccd313ca72f2e73f4cde1da04f.png)

ä½œè€…å›¾ç‰‡

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨ç»„åˆåŒ…çš„å †å æ¨¡å‹ã€‚

```
# build a Stacking model and evaluate
clf = Stacking(classifiers, n_folds=4, shuffle_data=False,
                   keep_original=True, use_proba=False,
                   random_state=random_state)clf.fit(X_train, y_train)
y_test_predict = clf.predict(X_test)evaluate_print('Stacking | ', y_test, y_test_predict)
```

![](img/814ad180d21cd2dcf0057098db0d881c.png)

ä½œè€…å›¾ç‰‡

æœ‰æ‰€æ”¹å–„ï¼Œä½†è‚¯å®šè¿˜æœ‰è¿›è¡Œå¦ä¸€é¡¹å®éªŒçš„ç©ºé—´ã€‚æ‚¨å¯ä»¥ä½¿ç”¨è¯¥è½¯ä»¶åŒ…å°è¯•ä»»ä½•æ‚¨è®¤ä¸ºå¿…è¦çš„ç»„åˆã€‚

## 22.çš®é˜¿å…¹ç‰¹ç½—

ä½ éœ€è¦æ˜Ÿåº§æ•°æ®è¿˜æ˜¯åªæ˜¯å¥½å¥‡ä½ ä»Šå¤©çš„è¿æ°”ï¼Ÿç„¶åä½ å¯ä»¥ç”¨ [PyAztro](https://github.com/sameerkumar18/pyaztro) æ¥å®ç°ï¼è¯¥è½¯ä»¶åŒ…æ¶µç›–äº†ç‹¬ç‰¹çš„ä¿¡æ¯ï¼Œå¦‚å¹¸è¿æ•°å­—ï¼Œå¹¸è¿æ ‡å¿—ï¼Œå¿ƒæƒ…ï¼Œç­‰ç­‰ã€‚è®©æˆ‘ä»¬è¯•ç€é€šè¿‡å®‰è£…æ¥ä½¿ç”¨è¿™ä¸ªåŒ…ã€‚

```
pip install pyaztro
```

ç„¶åæˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç å°è¯•è®¿é—®ä»Šå¤©çš„æ˜Ÿåº§ã€‚

```
import pyaztro
pyaztro.Aztro(sign='gemini').description
```

![](img/9da80caad6cc8b874cebd9d54a8934da.png)

ä½œè€…å›¾ç‰‡

## 23.éª—å­

[Faker](https://github.com/joke2k/faker) æ˜¯ä¸€ä¸ª Python åŒ…ï¼Œç”¨æ¥ç®€åŒ–ç”Ÿæˆåˆæˆæ•°æ®ã€‚è®¸å¤šå¼€å‘äººå‘˜ä½¿ç”¨è¿™ä¸ªåŒ…æ¥åˆ›å»ºå¦ä¸€ä¸ªåˆæˆæ•°æ®ç”Ÿæˆå™¨åŒ…ã€‚è¦ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œè®©æˆ‘ä»¬å®‰è£…å®ƒã€‚

```
pip install Faker
```

ä¸ºäº†ä½¿ç”¨ Faker åŒ…ç”Ÿæˆåˆæˆæ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦åˆå§‹åŒ–`Faker`ç±»ã€‚

```
from faker import Faker
fake = Faker()
```

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åˆå§‹åŒ–çš„ç±»åˆ›å»ºä¸€ä¸ªåˆæˆæ•°æ®åã€‚

```
fake.name()
```

![](img/e272f0fa1f49e7a445a6b7b307d9114e.png)

ä½œè€…å›¾ç‰‡

æ¯å½“æˆ‘ä»¬è¿è¡Œ Faker ç±»ä¸­çš„å±æ€§`.name`æ—¶ï¼ŒFaker ä¼šéšæœºç”Ÿæˆåˆæˆæ•°æ®ã€‚æ‚¨ä»ç„¶å¯ä»¥å°è¯•ä½¿ç”¨è®¸å¤šå±æ€§æ¥ç”Ÿæˆæ•°æ®ã€‚

## 24.è´¹å°”å‹’æ©

[Fairlearn](https://fairlearn.org/) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨äºè¯„ä¼°å’Œå‡è½»æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„ä¸å…¬å¹³æ€§ã€‚è¿™ä¸ªåŒ…æä¾›äº†è®¸å¤šå¿…è¦çš„ API æ¥æŸ¥çœ‹åå·®ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥é¿å…å®ƒã€‚è¦è¯•ç”¨è¿™ä¸ªåŒ…ï¼Œè®©æˆ‘ä»¬å…ˆå¼€å§‹å®‰è£…å®ƒã€‚

```
pip install fairlearn
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Fairlearn çš„æ•°æ®é›†æ¥æŸ¥çœ‹æ¨¡å‹ä¸­æœ‰å¤šå°‘åå·®ã€‚å‡ºäºæ•™å­¦ç›®çš„ï¼Œæˆ‘ä»¬å°†ç®€åŒ–æ¨¡å‹é¢„æµ‹ã€‚

```
from fairlearn.metrics import MetricFrame, selection_rate
from fairlearn.datasets import fetch_adultdata = fetch_adult(as_frame=True)
X = data.data
y_true = (data.target == '>50K') * 1
sex = X['sex']selection_rates = MetricFrame(metrics=selection_rate,
                              y_true=y_true,
                              y_pred=y_true,
                              sensitive_features=sex)fig = selection_rates.by_group.plot.bar(
    legend=False, rot=0,
    title='Fraction earning over $50,000')
```

![](img/cb687b044c5d4e02df5453530965c5c0.png)

ä½œè€…å›¾ç‰‡

Fairlearn API æœ‰ä¸€ä¸ª`selection_rate`å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥æ£€æµ‹ç¾¤ä½“æ¨¡å‹é¢„æµ‹ä¹‹é—´çš„åˆ†æ•°å·®å¼‚ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°ç»“æœçš„åå·®ã€‚

## 25.tiobeindexpy

tiobeindexpy æ˜¯ä¸€ä¸ªç®€å•çš„ python åŒ…ï¼Œç”¨äºè·å– TIOBE ç´¢å¼•æ•°æ®ã€‚TIOBE index æ˜¯ä¸€ä¸ªç¼–ç¨‹æ’åæ•°æ®ï¼Œéµå¾ªå®ƒå¯èƒ½å¾ˆé‡è¦ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æƒ³é”™è¿‡ç¼–ç¨‹ä¸–ç•Œä¸­çš„ä¸‹ä¸€ä»¶äº‹ã€‚

è¦ä½¿ç”¨ tiobeindexpyï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®‰è£…å®ƒã€‚

```
pip install tiobeindexpy
```

ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä»£ç è·å¾—å½“æœˆæ’åå‰ 20 çš„ç¼–ç¨‹è¯­è¨€ã€‚

```
from tiobeindexpy import tiobeindexpy as tb
df = tb.top_20()
```

![](img/3dd5a4e3fd7aa0f4ccf6f70eda754b59.png)

ä½œè€…å›¾ç‰‡

## 26.pytrends

pytrends æ˜¯ä¸€ä¸ª python åŒ…ï¼Œä½¿ç”¨ä»–ä»¬çš„ API è·å– Google ä¸Šçš„è¶‹åŠ¿å…³é”®è¯ã€‚å½“æˆ‘ä»¬æƒ³è¦è·Ÿä¸Šå½“å‰çš„ç½‘ç»œè¶‹åŠ¿æˆ–ä¸æˆ‘ä»¬çš„å…³é”®è¯ç›¸å…³çš„è¶‹åŠ¿æ—¶ï¼Œè¿™ä¸ªåŒ…æ˜¯æœ‰ç”¨çš„ã€‚è¦ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®‰è£…å®ƒã€‚

```
pip install pytrends
```

å‡è®¾æˆ‘æƒ³çŸ¥é“ä¸å…³é”®å­—â€œç¤¼ç‰©â€ç›¸å…³çš„å½“å‰è¶‹åŠ¿ï¼Œé‚£ä¹ˆæˆ‘å°†ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥äº†è§£å½“å‰è¶‹åŠ¿ã€‚

```
from pytrends.request import TrendReq
import pandas as pd
pytrend = TrendReq()keywords = pytrend.suggestions(keyword='Present Gift')
df = pd.DataFrame(keywords)
df
```

![](img/f6827a46f2febfb3ecb8876a523a2742.png)

ä½œè€…å›¾ç‰‡

è¯¥åŒ…å°†è¿”å›ä¸å…³é”®å­—ç›¸å…³çš„å‰ 5 ä¸ªè¶‹åŠ¿ã€‚

## 27.è§†åŠ›

[visions](https://github.com/dylan-profiler/visions) æ˜¯ä¸€ä¸ªç”¨äºè¯­ä¹‰æ•°æ®åˆ†æçš„ python åŒ…ã€‚è¯¥åŒ…å¯ä»¥æ£€æµ‹æ•°æ®å¸§ç±»å‹ï¼Œå¹¶æ¨æ–­è¯¥åˆ—çš„æ•°æ®åº”è¯¥æ˜¯ä»€ä¹ˆã€‚å®ƒæ—¨åœ¨è‡ªåŠ¨åŒ–æ•°æ®æ¨æ–­å¹¶é™ä½å·¥ä½œå¤æ‚æ€§ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install visions
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç é€šè¿‡ visions æ¥æ£€æµ‹ dataframe ä¸­çš„åˆ—æ•°æ®ç±»å‹ã€‚æˆ‘ä¼šä½¿ç”¨æ¥è‡ª seaborn çš„æ³°å¦å°¼å…‹å·æ•°æ®é›†ã€‚

```
import seaborn as sns
from visions.functional import detect_type, infer_type
from visions.typesets import CompleteSet
df = sns.load_dataset('titanic')
typeset = CompleteSet()# Inference works well even if we monkey with the data, say by converting everything to strings
print(detect_type(df, typeset))
```

![](img/12c7186511bfdb1b09649c9c5412a199.png)

ä½œè€…å›¾ç‰‡

## 28.æ—¥ç¨‹å®‰æ’

[Schedule](https://github.com/dbader/schedule) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œä¸ºä»»ä½•ä»£ç åˆ›å»ºä½œä¸šè°ƒåº¦åŠŸèƒ½ã€‚å®ƒçš„è®¾è®¡æ˜¯ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·åœ¨ä½ å¯ä»¥è®¾ç½®çš„é‡å¤æ—¶é—´é‡Œå®‰æ’ä»–ä»¬æƒ³è¦çš„ä»»ä½•äº‹æƒ…ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install schedule
```

ä¾‹å¦‚ï¼Œæˆ‘æƒ³æ‰“å°å‡ºæˆ‘æ¯ 10 ç§’é’Ÿå·¥ä½œä¸€æ¬¡ã€‚ç„¶åæˆ‘ä¼šç”¨ä¸‹é¢çš„ä»£ç æ¥åšè¿™ä»¶äº‹ã€‚

```
import schedule
import timedef job():
    print("I'm working...")schedule.every(10).seconds.do(job)while True:
    schedule.run_pending()
    time.sleep(1)
```

![](img/98b5d670f3f74732946b82e049318475.png)

ä½œè€…å›¾ç‰‡

## 29.è‡ªåŠ¨æ›´æ­£

[è‡ªåŠ¨æ›´æ­£](https://github.com/filyp/autocorrect)æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨äºè®¸å¤šè¯­è¨€ä¸­çš„æ–‡æœ¬æ‹¼å†™æ›´æ­£ã€‚è¿™ç§ç”¨æ³•å¾ˆç®€å•ï¼Œä½†å¯¹æ•°æ®æ¸…ç†è¿‡ç¨‹éå¸¸æœ‰ç”¨ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚

```
pip install autocorrect
```

ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç±»ä¼¼äºä¸‹é¢ä»£ç çš„è‡ªåŠ¨æ›´æ­£åŒ…ã€‚

```
from autocorrect import Speller
spell = Speller()
spell("I'm not sleaspy and tehre is no place I'm giong to.")
```

![](img/32fba3e0f7ddfc0e8caf882f6555287f.png)

ä½œè€…å›¾ç‰‡

## 30.funcy

funcy æ˜¯ä¸€ä¸ª python åŒ…ï¼Œå…¶ä¸­å……æ»¡äº†æ—¥å¸¸æ•°æ®åˆ†æä½¿ç”¨çš„å¥‡ç‰¹å®ç”¨å‡½æ•°ã€‚è½¯ä»¶åŒ…ä¸­çš„å‡½æ•°å¤ªå¤šäº†ï¼Œæˆ‘æ— æ³•ä¸€ä¸€å±•ç¤ºï¼Œè¿˜æœ‰ä¸€ä¸ªå¤‡å¿˜å•[å¯ä»¥è®©å®ƒå˜å¾—æ›´ç®€å•ã€‚è®©æˆ‘ä»¬ä»å®‰è£…åŒ…å¼€å§‹ã€‚](https://funcy.readthedocs.io/en/stable/cheatsheet.html)

```
pip install funcy
```

æˆ‘å°†åªå±•ç¤ºä¸€ä¸ªä» iterable å˜é‡ä¸­é€‰æ‹©å¶æ•°çš„ç¤ºä¾‹å‡½æ•°ï¼Œå¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºã€‚

```
from funcy import select, even
select(even, {i for i in range (20)})
```

![](img/cae34793348164bd7b3167c07cfa36db.png)

ä½œè€…å›¾ç‰‡

## 31.å†°æ·‡æ·‹

[IceCream](https://github.com/gruns/icecream) æ˜¯ä¸€ä¸ª python åŒ…ï¼Œç”¨äºæ‰“å°ç›®çš„ï¼Œä½†ä½¿è°ƒè¯•è¿‡ç¨‹æ›´å®¹æ˜“ã€‚åŸºæœ¬ä¸Šï¼Œè¿™ä¸ªåŒ…åœ¨æ‰“å°/è®°å½•è¿‡ç¨‹ä¸­æä¾›äº†ç¨å¾®è¯¦ç»†ä¸€ç‚¹çš„è¾“å‡ºã€‚

ä¸ºäº†ä½¿ç”¨è¿™ä¸ªåŒ…ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥å®‰è£…å®ƒã€‚

```
pip install icecream
```

ç„¶åæˆ‘ä»¬å¯ä»¥ç”¨ä¸‹é¢çš„ä»£ç æ¥ä½¿ç”¨è¿™ä¸ªåŒ…ã€‚

```
from icecream import icdef some_function(i):
    i = 4 + (1 * 2)/ 10 
    return i + 35ic(some_function(121))
```

![](img/1becedd18a779b2e18682b88d0bc735b.png)

ä½œè€…å›¾ç‰‡

è¯¥å‡½æ•°ä¹Ÿå¯ä»¥ç”¨ä½œå‡½æ•°æ£€æŸ¥å™¨ã€‚

```
def foo():
    ic()

    if some_function(12):
        ic()
    else:
        ic()foo()
```

![](img/b90d6cbdf153d5a733a358d67a077e1d.png)

ä½œè€…å›¾ç‰‡

å¯¹äºæˆ‘ä»¬æ‰€åšçš„ä»»ä½•æ•°æ®åˆ†ææ¥è¯´ï¼Œè¯¦ç»†ç¨‹åº¦éƒ½æ˜¯éå¸¸å¥½çš„ã€‚

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº† 31 ä¸ªç‹¬ç‰¹çš„ python åŒ…ï¼Œå®ƒä»¬åœ¨æ•°æ®å·¥ä½œæµä¸­å¾ˆæœ‰ç”¨ã€‚å¤§å¤šæ•°è½¯ä»¶åŒ…æ˜“äºä½¿ç”¨ä¸”ç®€å•æ˜äº†ï¼Œä½†æœ‰äº›å¯èƒ½éœ€è¦è¿›ä¸€æ­¥é˜…è¯»ã€‚

å¸Œæœ›æœ‰å¸®åŠ©ï¼

> *è®¿é—®æˆ‘çš„* [***ç¤¾äº¤åª’ä½“***](https://bio.link/cornelli)**è¿›è¡Œæ›´æ·±å…¥çš„äº¤è°ˆæˆ–æœ‰ä»»ä½•é—®é¢˜ã€‚**

> **å¦‚æœæ‚¨ä¸æ˜¯ä½œä¸ºä¸­ç­‰ä¼šå‘˜è®¢é˜…ï¼Œè¯·è€ƒè™‘é€šè¿‡* [*æˆ‘çš„æ¨è*](https://cornelliusyudhawijaya.medium.com/membership) *è®¢é˜…ã€‚**