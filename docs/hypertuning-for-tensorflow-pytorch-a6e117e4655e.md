# TensorFlow å’Œ PyTorch çš„è¶…è°ƒ

> åŸæ–‡ï¼š<https://towardsdatascience.com/hypertuning-for-tensorflow-pytorch-a6e117e4655e>

![](img/d89ff40f4abd6b03e497ece9509c1db7.png)

è¶…å‚æ•°è°ƒæ•´å°±åƒç”¨æ•°æ®æ‰“ç¢Ÿä¸€æ ·â€”â€”ç…§ç‰‡æ¥æº([unsplash.com/photos/ZfCVTJ30yoc](https://unsplash.com/photos/ZfCVTJ30yoc))

> *æ·±åº¦å­¦ä¹ åº“çš„æ ¹æœ¬é—®é¢˜æ˜¯ï¼Œå®ƒä»¬æ˜¯ä¸ºå•æ¬¡å†…å­˜è¿è¡Œè€Œè®¾è®¡çš„ï¼Œå…¶å”¯ä¸€ç›®çš„æ˜¯æœ€å°åŒ–æŸå¤±â€”â€”è€Œåœ¨ç°å®ä¸­ï¼Œè°ƒæ•´ä¸€ä¸ªæ¶æ„éœ€è¦å¤šæ¬¡è¿è¡Œï¼Œå·¥ä½œæµéœ€è¦æŒç»­ï¼Œè®­ç»ƒæŸå¤±åªæ˜¯æ¨¡å‹è¯„ä¼°çš„å¼€å§‹ã€‚*

![](img/49505c35ad8b5500724148007160421f.png)

çº¢è‰²éå¸¸å—æ¬¢è¿ï¼Œå°½ç®¡è¾ƒå°‘çš„å›¾å±‚ç±»å‹åŠŸèƒ½è¾ƒå°‘-å›¾ç‰‡ç”±ä½œè€…æä¾›

# ç‰©ä»¥ç±»èšã€‚

ä¸€å¹´å‰ï¼Œæˆ‘å¼€å§‹æ„å»ºä¸€ä¸ªåº“ï¼Œè®© **TensorFlow** å’Œ **PyTorch** çš„å®éªŒè·Ÿè¸ªå’Œå‚æ•°è°ƒæ•´æ›´åŠ å®¹æ˜“ã€‚è¿™äº›åº“å…±äº«ç›¸åŒçš„åº•å±‚æ¦‚å¿µï¼Œå› æ­¤åŒ…è£…å®ƒä»¬å¾ˆå®¹æ˜“:

*   *fn_build â€”* ä¸ºæ¶æ„ã€‚
*   *fn_train â€”* å®šä¹‰å›è·¯ã€‚
*   *fn_lose* â€”è®¡ç®—æŸè€—ã€‚
*   *fn_optimize â€”* ç”¨äºå­¦ä¹ è®¾ç½®ã€‚
*   *fn_predict â€”* ç”¨äºè¿è¡Œå®ƒã€‚

å¾ˆæœ‰è¶£ï¼æˆ‘ç”¨ç®€å•çš„ *if* è¯­å¥(ä¾‹å¦‚ *concave_convex:[Trueï¼ŒFalse]* )æµ‹è¯•äº†å®Œå…¨ä¸åŒçš„æ¶æ„ï¼Œç”šè‡³å°† Torch æŸå¤±å‡½æ•°ä¸ Keras æ¨¡å‹æ··åˆåœ¨ä¸€èµ·ã€‚

æ ¹æ®æˆ‘æ­£åœ¨è¿›è¡Œçš„åˆ†æç±»å‹(ä¾‹å¦‚å›å½’ã€äºŒå…ƒåˆ†ç±»å’Œå¤šæ ‡ç­¾åˆ†ç±»)ï¼Œæˆ‘å¼€å§‹æ³¨æ„åˆ°æˆ‘æ­£åœ¨ä½¿ç”¨ç›¸åŒçš„*ä¸¢å¤±-ä¼˜åŒ–-é¢„æµ‹*ç»„åˆã€‚æ‰€ä»¥æˆ‘èƒ½å¤Ÿä¸ºå¤§å¤šæ•°ç»„ä»¶è®¾ç½®å¯è¦†ç›–çš„é»˜è®¤å€¼ã€‚

> â™»ï¸ç±»ä¼¼äº Keras å¦‚ä½•æŠ½è±¡ä¸€ä¸ªè®­ç»ƒå¾ªç¯ï¼Œæˆ‘æŠ½è±¡äº†ä¸€ä¸ªè®­ç»ƒå¾ªç¯çš„å¾ªç¯ï¼ŒåŒæ—¶ä¿æŒäº†å·¥ä½œæµçš„å¯å®šåˆ¶æ€§ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªåŸºæœ¬çš„å¤šæ ‡ç­¾åˆ†ç±»ç¤ºä¾‹:

```
# Unique param combos will get passed into functions as `hp**`.
**hyperparameters** = {
      "neuron_count":  [9, 12]
    , "batch_size":    [3, 5]
    , "epoch_count":   [30, 60]
} **def fn_build***(features_shape, label_shape, **hp):*
    model = Sequential()
    model.add(Input(shape=features_shape))
    model.add(Dense(units=hp['neuron_count'], activation='relu'))
    model.add(Dense(units=label_shape[0], activation='softmax'))
    return model **def fn_train***(
    model, loser, optimizer, 
    samples_train, samples_evaluate, **hp
):*
    model.compile(
          loss      = loser
        , optimizer = optimizer
        , metrics   = ['accuracy']
    )
    model.fit(
          samples_train["features"]
        , samples_train["labels"]
        , validation_data = (
            samples_evaluate["features"]
            , samples_evaluate["labels"]
        )
        , verbose    = 0
        , batch_size = hp['batch_size']
        , epochs     = hp['epoch_count']
        , callbacks  = [History()]
    )
    return model
```

è¿™äº›ç»„ä»¶ç”¨äºç»„è£…åŸ¹è®­å·¥ä½œçš„*é˜Ÿåˆ—*:

```
**queue = aiqc.Experiment.make**(
      **# --- Analysis type ---**
      *library*         = "keras"
    , *analysis_type*   = "classification_multi"

      **# --- Model functions ---**
    , *fn_build*        = fn_build
    , *fn_train*        = fn_train
    , *fn_lose*         = None *#auto CatCrossEnt.*
    , *fn_optimize*     = None *#auto Adamax <3.*
    , *fn_predict*      = None *#returns `preds, probs`.*

      **# --- Training options ---**
    , *repeat_count*    = 2
    , *hyperparameters* = hyperparameters

      **# --- Data source ---**
    , *splitset_id*     = splitset.id #scroll down.
    , *hide_test*       = False
)**queue.run_jobs()**
#ğŸ”® Training Models ğŸ”®: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16
```

ç„¶è€Œï¼Œå½“åˆ°äº†ç”¨æŒ‡æ ‡å’Œå›¾è¡¨è¯„ä¼°æ¯ä¸ªæ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘æ„è¯†åˆ°ä¸€äº›å…³é”®é—®é¢˜è¢«æ©ç›–äº†ã€‚

![](img/5ca597b78d583f5df218d7617fb385e7.png)

AIQC çš„å†…ç½®å¯è§†åŒ–â€”â€”ä½œè€…å›¾ç‰‡

![](img/940e61c7caed31ce8fde2e32f4224be8.png)

æ¢ç´¢è¶…ç»´åº¦ç‰¹å¾ç©ºé—´ä»¥æœ€å°åŒ–æŸå¤±â€”â€”ä½œè€…å›¾ç‰‡

# æ·±åº¦å­¦ä¹ ï¼Œæµ…èŒƒå›´ã€‚

> æ·±åº¦å­¦ä¹ åº“åšå¥½ä¸€ä»¶äº‹ï¼›é«˜æ•ˆåœ°å°†æŸå¤±é™è‡³æœ€ä½ã€‚éå¸¸å¿«â€”ä½¿ç”¨ 20ï¼Œ000 åˆ— 650 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ—¶æœŸ 1 ç§’â€”éå¸¸å¿«ã€‚

ç¦»è®¡ç®—æœºç§‘å­¦ç¹é‡çš„ä»»åŠ¡è¶Šè¿œï¼Œè¿™äº›åº“çš„å¸®åŠ©å°±è¶Šå°‘ã€‚å…¶ä»–çš„äº‹æƒ…â€”â€”ä¸Šæ¸¸çš„*æ•°æ®å‡†å¤‡*å’Œä¸‹æ¸¸çš„*æ¨¡å‹è¯„ä¼°*éƒ½è½¬ç§»åˆ°äº†ç”¨æˆ·çš„è‚©ä¸Šã€‚æ ¸å¿ƒæ·±åº¦å­¦ä¹ åº“ä¸æ˜¯:

ğŸ¤” ***åˆ†ææ„ŸçŸ¥*** â€”ç®—æ³•ä¸çŸ¥é“æ‚¨æ­£åœ¨è¿›è¡Œä»€ä¹ˆç±»å‹çš„åˆ†æï¼Œå› æ­¤å®ƒä¸çŸ¥é“è¯„ä¼°ç»™å®šæ¨¡å‹éœ€è¦ä»€ä¹ˆæŒ‡æ ‡&å›¾è¡¨ã€‚

[ğŸ’¾](https://emojipedia.org/floppy-disk/) ***æ•°æ®æ„ŸçŸ¥*** â€”ç¨‹åºä¸çŸ¥é“ä½ çš„æ•°æ®é›†æ˜¯å¦‚ä½•æ„é€ çš„ã€‚è¿™ä¸ä»…é€‚ç”¨äº(a)éœ€è¦è¯„ä¼°çš„åˆ†å‰²/æŠ˜å ä¸­çš„ç‰¹å¾/æ ‡ç­¾ç­‰å­é›†ï¼Œè¿˜é€‚ç”¨äº(b)ç”¨äºé¢„å¤„ç†/åå¤„ç†çš„å½¢çŠ¶ã€‚

ğŸ“‚*â€”æ¨¡å‹ã€æŒ‡æ ‡å’Œä»»ä½•é¢„å¤„ç†æ­¥éª¤åªå­˜åœ¨äºå†…å­˜ä¸­ã€‚ä¿å­˜å’Œç»„ç»‡å®ƒä»¬å–å†³äºä»ä¸šè€…ã€‚*

# *é¢å‘å¯¹è±¡çš„æ–¹æ³•ã€‚*

*![](img/78cad7239deaac4026ee35e4f5a0ff41.png)*

*AIQC é«˜çº§å’Œä½çº§åŸæ–™è¯çš„è¦ç‚¹-å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚*

> *ç®—æ³•åªæ˜¯å¸Œæœ›ä½ ä»¥æ­£ç¡®çš„æ ¼å¼æ˜¾ç¤ºæ­£ç¡®çš„æ•°æ®ã€‚æˆ‘åŒå€¦äº†äº’è”ç½‘ä¸Šä»»æ„é£Ÿè°±ä¸­çš„è¿™ç§â€œX_trainï¼Œy_testâ€æ•°å­¦æœ¯è¯­ã€‚å°±å«å®ƒä»¬**ç‰¹æ€§**å’Œæ ‡ç­¾å§ï¼ç­‰ç­‰â€¦å°±æ˜¯è¿™æ ·ï¼*

*åŸºäºæ‰€æ¶‰åŠçš„æ•°æ®å’Œåˆ†æçš„ç±»å‹ï¼Œæœ‰ä¸€äº›è§„åˆ™æ¥ç®¡ç†è¿™äº›å¯¹è±¡åº”è¯¥å¦‚ä½•ç›¸äº’äº¤äº’ã€‚æ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½éœ€è¦æŒä¹…åŒ–ã€‚è¿™ä¸ªæ ‡å‡†ä½¿å¾—æœºå™¨å­¦ä¹ æˆä¸ºå¯¹è±¡å…³ç³»æ¨¡å‹(ORM)æŠ½è±¡çš„å®Œç¾å€™é€‰ï¼Œä¹Ÿå°±æ˜¯å…³ç³»æ•°æ®åº“çš„ APIã€‚*

*åœ¨æ„å»º**ä½çº§** *ç‰¹å¾æ—¶ï¼Œæ ‡ç­¾ã€ç¼–ç å™¨ã€åˆ†å‰²ã€æŠ˜å *ç­‰ã€‚â€”æˆ‘æ„è¯†åˆ°æˆ‘æ¯æ¬¡éƒ½åœ¨ç”¨ä¸åŒè®¾ç½®çš„ç›¸åŒå¯¹è±¡ã€‚æ‰€ä»¥æˆ‘å°†æ‰€æœ‰çš„æ‘„å–&é¢„å¤„ç†æ­¥éª¤ç»„åˆæˆä¸€ä¸ª**é«˜çº§** *æµæ°´çº¿*ï¼Œå¹¶å°†æ‰€æœ‰çš„è®­ç»ƒ&è¯„ä¼°å¯¹è±¡ç»„åˆæˆä¸€ä¸ª*å®éªŒ*ã€‚*

*Iris æ•°æ®é›†çš„å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜çš„æ•°æ®å‡†å¤‡å¦‚ä¸‹:*

```
*import aiqc
# Creates or finds SQLite db for persisting workflow.
aiqc.setup()# Built-in example datasets.
from aiqc import datum
df = datum.to_pandas('iris.tsv') **splitset = aiqc.Pipeline.Tabular.make**(
      **# --- Data source ---**
      *df_or_path* = df

      **# --- Label preprocessing ---**
    , *label_column*  = 'species'
    , *label_encoder* = dict(
          sklearn_preprocess=OneHotEncoder()
    )

      **# --- Feature preprocessing ---**
    , *feature_cols_excluded* = 'species'
    , *feature_encoders*      = [
          dict(
              sklearn_preprocess   = StandardScaler()
              # Encode a list of `dtypes` or `columns`              
              , dtypes = ['float64'] 
          )
    ] **# --- Stratification ---**
    , *size_test*       = 0.22
    , *size_validation* = 0.12
    , *fold_count*      = None
    , *bin_count*       = None)*
```

## *AIQC æ˜¯é¢å‘å¯¹è±¡ MLOps çš„å¼€æºæ¡†æ¶ã€‚*

**é«˜çº§ API* å…è®¸ä»ä¸šè€…ä¸“æ³¨äºä»–ä»¬çš„æ•°æ®ç§‘å­¦å·¥ä½œæµç¨‹ï¼Œè€Œä¸æ˜¯å°†è„šæœ¬å’Œæ‹¼å‡‘çš„å·¥å…·é›†ç²˜åœ¨ä¸€èµ·ã€‚å®ƒæŠ½è±¡å‡ºäº†ä½¿æœºå™¨å­¦ä¹ å˜å¾—å¦‚æ­¤ä¸å¯æ¥è¿‘çš„æ•°æ®äº‰è®ºã€‚*

> *<https://github.com/aiqc/aiqc>**(åˆ«å¿˜äº†â­ )***