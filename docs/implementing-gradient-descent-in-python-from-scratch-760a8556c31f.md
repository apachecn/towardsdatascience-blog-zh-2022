# ä»å¤´å¼€å§‹åœ¨ Python ä¸­å®ç°æ¢¯åº¦ä¸‹é™

> åŸæ–‡ï¼š<https://towardsdatascience.com/implementing-gradient-descent-in-python-from-scratch-760a8556c31f>

## ä»å¤´å¼€å§‹ç”¨ä»£ç å®ç°æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œäº†è§£å®ƒçš„å·¥ä½œåŸç†ã€‚

![](img/58c9e8aaac3d4e402ea9bb79f3bdba7d.png)

**ä½œè€…å›¾ç‰‡(ä½¿ç”¨ python ä¸­çš„ matplotlib åˆ›å»º)**

æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½æœ‰å‡ ä¸ªç‰¹å¾ï¼Œä½†æ˜¯ä¸€äº›ç‰¹å¾å¯èƒ½æ¯”å…¶ä»–ç‰¹å¾å¯¹è¾“å‡ºæœ‰æ›´é«˜çš„å½±å“ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹é¢„æµ‹å…¬å¯“ä»·æ ¼ï¼Œå…¬å¯“çš„ä½ç½®å¯¹è¾“å‡ºçš„å½±å“å¯èƒ½æ¯”å…¬å¯“å»ºç­‘çš„å±‚æ•°æ›´å¤§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†æƒé‡çš„æ¦‚å¿µã€‚æ¯ä¸ªç‰¹å¾éƒ½ä¸ä¸€ä¸ªæƒé‡(ä¸€ä¸ªæ•°å­—)ç›¸å…³è”ï¼Œå³ç‰¹å¾å¯¹è¾“å‡ºçš„å½±å“è¶Šå¤§ï¼Œä¸ä¹‹ç›¸å…³è”çš„æƒé‡å°±è¶Šå¤§ã€‚ä½†æ˜¯ï¼Œå¦‚ä½•å†³å®šåº”è¯¥ç»™æ¯ä¸ªç‰¹å¾åˆ†é…å¤šå¤§çš„æƒé‡å‘¢ï¼Ÿè¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™çš„ç”¨æ­¦ä¹‹åœ°ã€‚

æ¢¯åº¦ä¸‹é™æ˜¯ä¸€ç§ä¼˜åŒ–ç®—æ³•ï¼Œå¯ä»¥å¸®åŠ©æ‚¨æ‰¾åˆ°æ¨¡å‹çš„æœ€ä½³æƒé‡ã€‚å®ƒé€šè¿‡å°è¯•å„ç§æƒé‡å¹¶æ‰¾åˆ°æœ€é€‚åˆæ¨¡å‹çš„æƒé‡æ¥å®ç°ï¼Œå³æœ€å°åŒ–æˆæœ¬å‡½æ•°ã€‚æˆæœ¬å‡½æ•°å¯ä»¥å®šä¹‰ä¸ºå®é™…äº§é‡å’Œé¢„æµ‹äº§é‡ä¹‹é—´çš„å·®å¼‚ã€‚å› æ­¤ï¼Œæˆæœ¬å‡½æ•°è¶Šå°ï¼Œæ¨¡å‹çš„é¢„æµ‹è¾“å‡ºå°±è¶Šæ¥è¿‘å®é™…è¾“å‡ºã€‚æˆæœ¬å‡½æ•°åœ¨æ•°å­¦ä¸Šå¯ä»¥å®šä¹‰ä¸º:

```
**ğ‘¦=ğ›½+Î¸nXn,** 
where x is the parameters(can go from 1 to n), ğ›½ is the             bias and Î¸ is the weight
```

è€Œå¦ä¸€æ–¹é¢ï¼Œæ¢¯åº¦ä¸‹é™çš„å­¦ä¹ ç‡è¢«è¡¨ç¤ºä¸º **Î±ã€‚**å­¦ä¹ ç‡æ˜¯æ¯ä¸ªæ¢¯åº¦æ‰€èµ°çš„æ­¥çš„å¤§å°ã€‚è™½ç„¶è¾ƒå¤§çš„å­¦ä¹ ç‡å¯èƒ½ä¼šç»™æˆ‘ä»¬çš„ **ğ›½** å’Œ **Î¸** çš„ä¼˜åŒ–å€¼è¾ƒå·®ï¼Œä½†å­¦ä¹ ç‡ä¹Ÿå¯èƒ½å¤ªå°ï¼Œè¿™éœ€è¦å¤§é‡å¢åŠ è·å¾—æ”¶æ•›ç‚¹(ğ›½å’ŒÎ¸çš„æœ€ä½³å€¼ç‚¹)æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ã€‚è¯¥ç®—æ³•ç»™å‡ºÎ± **ã€** ğ›½å’ŒÎ¸çš„å€¼ä½œä¸ºè¾“å‡ºã€‚

å¦‚æœä½ æƒ³æ›´è¯¦ç»†çš„äº†è§£æ¢¯åº¦ä¸‹é™å’Œä»£ä»·å‡½æ•°ï¼Œæˆ‘æ¨è[è¿™ç¯‡æ–‡ç« ](/machine-leaning-cost-function-and-gradient-descend-75821535b2ef)ã€‚

ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ä»¥åŠå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç”¨ python å®ç°å®ƒã€‚ä½†æ˜¯ï¼Œåœ¨æˆ‘ä»¬å¼€å§‹ç›¸åŒçš„ä»£ç é€»è¾‘ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ•°æ®å’Œä¸ºäº†æˆ‘ä»¬çš„ç›®çš„å°†è¦å¯¼å…¥çš„åº“ã€‚

å¯¹äºè¿™ä¸ªå®ç°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¹¿å‘Šæ•°æ®é›†ã€‚è¿™æ˜¯ä¸€ä¸ªæ•°æ®é›†ï¼Œå®ƒç»™å‡ºäº†ä¸åŒäº§å“åœ¨ç”µè§†ã€å¹¿æ’­å’ŒæŠ¥çº¸ä¸Šé”€å”®åçš„æ€»é”€å”®é¢ã€‚ä½¿ç”¨æˆ‘ä»¬çš„ç®—æ³•ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾å‡ºå“ªç§åª’ä½“å¯¹æˆ‘ä»¬çš„é”€å”®è¡¨ç°æœ€å¥½ï¼Œå¹¶ç›¸åº”åœ°ä¸ºæ‰€æœ‰åª’ä½“åˆ†é…æƒé‡ã€‚è¯¥æ•°æ®é›†å¯ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½:

> [https://www.kaggle.com/sazid28/advertising.csv](https://www.kaggle.com/sazid28/advertising.csv)

è½¬åˆ°å¯¼å…¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åº“ pandas å’Œ numpyï¼Œå®ƒä»¬å°†ç”¨äºè¯»å–æ•°æ®ä»¥åŠå¯¹æ•°æ®æ‰§è¡Œæ•°å­¦å‡½æ•°ã€‚æˆ‘ä»¬è¿˜å°†ä½¿ç”¨ matplotlib å’Œ seaborn æ¥ç»˜åˆ¶æˆ‘ä»¬çš„å‘ç°ï¼Œå¹¶ä»¥å›¾å½¢æ–¹å¼è§£é‡Šç»“æœã€‚ä¸€æ—¦æˆ‘ä»¬å¯¼å…¥äº†åº“ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ pandas æ¥è¯»å–æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œå¹¶æ‰“å°å‰ 5 åˆ—ä»¥ç¡®ä¿æ•°æ®è¢«æ­£ç¡®è¯»å–ã€‚ä¸€æ—¦æˆ‘ä»¬è¯»å–äº†æ•°æ®ï¼Œæˆ‘ä»¬å°†ä¸ºæˆ‘ä»¬çš„æ¢¯åº¦ä¸‹é™æ›²çº¿è®¾ç½® X & Y å˜é‡ã€‚

```
import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sndf=pd.read_csv('Advertising.csv')df.head()
```

è¾“å‡º:

![](img/955e36e643966b3604dcea7f11e9a9f4.png)

æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ(æ•°æ®é›†çš„å‰ 5 è¡Œ)

x ä»£è¡¨ç”µè§†ã€å¹¿æ’­å’ŒæŠ¥çº¸ï¼Œè€Œ Y ä»£è¡¨æˆ‘ä»¬çš„é”€å”®ã€‚ç”±äºæ‰€æœ‰è¿™äº›é”€å”®å¯èƒ½åœ¨ä¸åŒçš„è§„æ¨¡ï¼Œç„¶åæˆ‘ä»¬æ­£å¸¸åŒ–æˆ‘ä»¬çš„ X & Y å˜é‡ã€‚

```
X=df[[â€˜TVâ€™,â€™Radioâ€™,â€™Newspaperâ€™]]Y=df[â€˜Salesâ€™]Y=np.array((Y-Y.mean())/Y.std())X=X.apply(lambda rec:(rec-rec.mean())/rec.std(),axis=0)
```

ä¸€æ—¦æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„ç®—æ³•ã€‚è¦å®ç°æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œæˆ‘ä»¬éœ€è¦éµå¾ª 4 ä¸ªæ­¥éª¤:

1.  éšæœºåˆå§‹åŒ–åå·®å’Œæƒé‡Î¸
2.  ç»™å®šåå·®å’Œæƒé‡ï¼Œè®¡ç®— Y çš„é¢„æµ‹å€¼
3.  æ ¹æ® Y çš„é¢„æµ‹å€¼å’Œå®é™…å€¼è®¡ç®—æˆæœ¬å‡½æ•°
4.  è®¡ç®—æ¢¯åº¦å’Œæƒé‡

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä¸ºåå·®å’Œæƒé‡å–ä¸€ä¸ªéšæœºå€¼ï¼Œå®ƒå¯èƒ½å®é™…ä¸Šæ¥è¿‘æœ€ä½³åå·®å’Œæƒé‡ï¼Œä¹Ÿå¯èƒ½ç¦»å¾—å¾ˆè¿œã€‚

```
import randomdef initialize(dim):b=random.random()theta=np.random.rand(dim)return b,thetab,theta=initialize(3)print(â€œBias: â€œ,b,â€Weights: â€œ,theta)
```

è¾“å‡º:

```
Bias: 0.4439513186463464 Weights: [0.92396489 0.05155633 0.06354297]
```

è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåä¸º initialise çš„å‡½æ•°ï¼Œå®ƒä¸ºæˆ‘ä»¬æä¾›äº†ä¸€äº›åå·®å’Œæƒé‡çš„éšæœºå€¼ã€‚æˆ‘ä»¬ä½¿ç”¨éšæœºåº“æ¥ç»™å‡ºç¬¦åˆæˆ‘ä»¬éœ€è¦çš„éšæœºæ•°ã€‚ä¸‹ä¸€æ­¥æ˜¯ä½¿ç”¨è¿™äº›æƒé‡å’Œåå·®è®¡ç®—è¾“å‡º(Y)ã€‚

```
def predict_Y(b,theta,X):return b + np.dot(X,theta)Y_hat=predict_Y(b,theta,X)Y_hat[0:10]
```

è¾“å‡º:

```
array([ 3.53610908, 0.53826004, 1.4045012 , 2.27511933, 2.25046604, 1.6023777 , -0.36009639, -0.37804669, -2.20360351, 0.69993066])
```

Y_hat æ˜¯é¢„æµ‹çš„è¾“å‡ºå€¼ï¼Œè€Œ Y å°†æ˜¯å®é™…å€¼ã€‚è¿™ä¸¤è€…ä¹‹é—´çš„å·®å¼‚å°†ç»™å‡ºæˆ‘ä»¬çš„æˆæœ¬å‡½æ•°ã€‚è¿™å°†åœ¨æˆ‘ä»¬ä¸‹ä¸€ä¸ªå‡½æ•°ä¸­è®¡ç®—ã€‚

```
import mathdef get_cost(Y,Y_hat):Y_resd=Y-Y_hatreturn np.sum(np.dot(Y_resd.T,Y_resd))/len(Y-Y_resd)Y_hat=predict_Y(b,theta,X)get_cost(Y,Y_hat)
```

è¾“å‡º:

```
0.5253558445651124
```

è¿™æ˜¯æˆ‘ä»¬çš„æˆæœ¬å‡½æ•°ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯å°½å¯èƒ½åœ°å‡å°‘è¿™ä¸ªï¼Œä»¥è·å¾—æœ€å‡†ç¡®çš„é¢„æµ‹ã€‚ä¸ºäº†è·å¾—æ›´æ–°çš„åå·®å’Œæƒé‡ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™å…¬å¼:

![](img/ecfdc38ef0edeac651b8e753373052f7.png)

å›¾ç‰‡ä½œè€…(æ›´æ–°çš„ theta å…¬å¼)ï¼Œ

ä¼ é€’ç»™è¯¥å‡½æ•°çš„å‚æ•°æœ‰

1.  xï¼Œy:è¾“å…¥å’Œè¾“å‡ºå˜é‡
2.  y_hat:å¸¦æœ‰å½“å‰åå·®å’Œæƒé‡çš„é¢„æµ‹å€¼
3.  b_0ï¼ŒÎ¸_ 0:ç”µæµåç½®å’Œæƒé‡
4.  å­¦ä¹ ç‡:è°ƒæ•´æ›´æ–°æ­¥é•¿çš„å­¦ä¹ ç‡

```
def update_theta(x,y,y_hat,b_0,theta_o,learning_rate):db=(np.sum(y_hat-y)*2)/len(y)dw=(np.dot((y_hat-y),x)*2)/len(y)b_1=b_0-learning_rate*dbtheta_1=theta_o-learning_rate*dwreturn b_1,theta_1print("After initialization -Bias: ",b,"theta: ",theta)Y_hat=predict_Y(b,theta,X)b,theta=update_theta(X,Y,Y_hat,b,theta,0.01)print("After first update -Bias: ",b,"theta: ",theta)get_cost(Y,Y_hat)
```

è¾“å‡º:

```
After initialization -Bias:  0.4733071000028529 theta:  [0.56745402 0.43024717 0.0722811 ]
After first update -Bias:  0.46384095800279584 theta:  [0.57117721 0.43202382 0.07171437]0.37245638135702513
```

å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæ–°çš„åå·®å’Œæƒé‡é™ä½äº†æˆæœ¬å‡½æ•°ã€‚ç›®å‰æˆ‘ä»¬å°†å­¦ä¹ ç‡å®šä¸º 0.001ï¼Œæˆ‘ä»¬ä¹Ÿå°†å°è¯• 0.01ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦èƒ½æˆä¸ºæ›´å¥½ã€æ›´ä¼˜çš„å­¦ä¹ ç‡ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†æ‰€æœ‰éœ€è¦çš„å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªä¸»æ¢¯åº¦ä¸‹é™å‡½æ•°ï¼Œå®ƒè¿è¡Œå®ƒä»¬ä¸€ä¸ªç‰¹å®šçš„è¿­ä»£æ¬¡æ•°ï¼Œå¹¶ä¸ºæˆ‘ä»¬æ‰¾åˆ°æœ€ä½³çš„åå·®å’Œæƒé‡ã€‚å¯¹äºè¿™ä¸ªå®ç°ï¼Œæˆ‘ä»¬è¿è¡Œè¿™ä¸ªå‡½æ•° 200 æ¬¡è¿­ä»£ã€‚

```
def run_gradient_descent(X,Y,alpha,num_iterations):b,theta=initialize(X.shape[1])iter_num=0gd_iterations_df=pd.DataFrame(columns=[â€˜iterationâ€™,â€™costâ€™])result_idx=0for each_iter in range(num_iterations):Y_hat=predict_Y(b,theta,X)this_cost=get_cost(Y,Y_hat)prev_b=bprev_theta=thetab,theta=update_theta(X,Y,Y_hat,prev_b,prev_theta,alpha)if(iter_num%10==0):gd_iterations_df.loc[result_idx]=[iter_num,this_cost]result_idx=result_idx+1iter_num +=1print(â€œFinal Estimate of b and theta : â€œ,b,theta)return gd_iterations_df,b,thetagd_iterations_df,b,theta=run_gradient_descent(X,Y,alpha=0.001,num_iterations=200)
```

è¾“å‡º:

```
Final Estimate of b and theta : 0.31516040347417285 [0.39731522 0.31571747 0.61334115]
```

theta æ˜¯ 3 ä¸ªæ•°å­—çš„åˆ—è¡¨ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ 3 ä¸ªè¾“å…¥ï¼Œç”µè§†ï¼Œå¹¿æ’­å’ŒæŠ¥çº¸ã€‚å¦‚æœæˆ‘ä»¬æ‰“å°æ¯æ¬¡è¿­ä»£çš„æˆæœ¬å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆæœ¬å‡½æ•°çš„å‡å°‘ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ç»˜åˆ¶è¿­ä»£çš„æˆæœ¬å‡½æ•°æ¥æŸ¥çœ‹ç»“æœã€‚

```
gd_iterations_df[0:10]
```

è¾“å‡º:

![](img/ffa9b315f4c9256a59887873d619f380.png)

æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ(è¿­ä»£çš„è¾“å‡º)

```
%matplotlib inlineplt.plot(gd_iterations_df[â€˜iterationâ€™],gd_iterations_df[â€˜costâ€™])plt.xlabel(â€œNumber of iterationsâ€)plt.ylabel(â€œCost or MSEâ€)
```

è¾“å‡º:

![](img/b62cf3d74c1daa806046e7ef415628ad.png)

æŒ‰ä½œè€…åˆ†ç±»çš„å›¾åƒ(æˆæœ¬å‡½æ•°ä¸è¿­ä»£)

æ­£å¦‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°çš„ï¼Œæˆæœ¬å‡½æ•°éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ è€Œå‡å°‘ï¼Œä½†æˆ‘ä»¬ä»ç„¶æ²¡æœ‰è¾¾åˆ°æ”¶æ•›ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•ä½¿ç”¨Î±=0.01 è¿›è¡Œ 2000 æ¬¡è¿­ä»£ï¼Œå¹¶å°†å…¶ä¸Î±=0.001 è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºå“ªä¸ªå­¦ä¹ ç‡å¯¹äºè¯¥æ•°æ®é›†æ›´å¥½ã€‚

```
alpha_df_1,b,theta=run_gradient_descent(X,Y,alpha=0.01,num_iterations=2000)alpha_df_2,b,theta=run_gradient_descent(X,Y,alpha=0.001,num_iterations=2000)plt.plot(alpha_df_1[â€˜iterationâ€™],alpha_df_1[â€˜costâ€™],label=â€alpha=0.01")plt.plot(alpha_df_2[â€˜iterationâ€™],alpha_df_2[â€˜costâ€™],label=â€alpha=0.001")plt.legend()plt.ylabel(â€˜costâ€™)plt.xlabel(â€˜Number of iterationsâ€™)plt.title(â€˜Cost Vs. Iterations for different alpha valuesâ€™)
```

è¾“å‡º:

![](img/9fa15589b088b4ad7a9594269a74b091.png)

ä½œè€…å›¾ç‰‡

å¯ä»¥çœ‹å‡ºï¼Œ0.01 æ˜¯æ›´ä¼˜çš„å­¦ä¹ é€Ÿç‡ï¼Œå› ä¸ºå®ƒæ¯” 0.001 æ”¶æ•›å¾—æ›´å¿«ã€‚0.01 åœ¨ 100 å¤§å…³é™„è¿‘æ”¶æ•›ï¼Œè€Œ 0.001 éœ€è¦ 1000 æ¬¡è¿­ä»£æ‰èƒ½è¾¾åˆ°æ”¶æ•›ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬æˆåŠŸåœ°åœ¨ python ä¸Šæ„å»ºäº†æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚è®°ä½ï¼Œå­¦ä¹ ç‡çš„æœ€ä½³å€¼å¯¹äºæ¯ä¸ªæ•°æ®é›†éƒ½æ˜¯ä¸åŒçš„ã€‚

å¸Œæœ›ä½ ä»Šå¤©å­¦åˆ°äº†æ–°çš„æœ‰æ„ä¹‰çš„ä¸œè¥¿ã€‚

è°¢è°¢ä½ ã€‚