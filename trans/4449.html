<html>
<head>
<title>Introduction to Image Classification with TensorFlow â€” Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¼ é‡æµå›¾åƒåˆ†ç±»ç®€ä»‹(äºŒ)</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef#2022-10-03">https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef#2022-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d5c8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Pythonè®¡ç®—æœºè§†è§‰åˆå­¦è€…å®ç”¨æŒ‡å—</h2></div><p id="940d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" rel="noopener" target="_blank" href="/introduction-to-image-classification-with-tensorflow-part-1-381d0a373b8f">åœ¨</a>ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬åœ¨åŒ…å«æ‰‹å†™æ•°å­—é»‘ç™½å›¾åƒçš„MNISTæ•°æ®é›†ä¸Šæ„å»ºäº†åŸºæœ¬çš„å›¾åƒåˆ†ç±»æ¨¡å‹ã€‚è¿™äº›æ•°æ®å¾ˆå®¹æ˜“é€šè¿‡TensorFlowè·å¾—ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œç°å®ç”Ÿæ´»ä¸­çš„å›¾åƒæ˜¯ä¸°å¯Œå¤šå½©çš„ï¼Œæ•°æ®é€šå¸¸ä¸å®¹æ˜“è·å¾—ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»ƒä¹ è‡ªå·±åŠ è½½å›¾åƒæ•°æ®ï¼Œå¹¶åœ¨å½©è‰²å›¾åƒä¸Šå»ºç«‹æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†å­¦ä¹ ä¸€ç‚¹å…³äºè¿ç§»å­¦ä¹ çš„çŸ¥è¯†ã€‚</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/a53ab1189ff9618dc9710a08e4c593ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xI150zWls0ow5L2O"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">ç…§ç‰‡ç”±<a class="ae le" href="https://unsplash.com/@picoftasty?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Mae Mu </a>åœ¨<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šæ‹æ‘„</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f4ac" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">ğŸ“¦æ•°æ®</h1><p id="c5e2" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">æˆ‘ä»¬å°†ä½¿ç”¨ä»è”¬èœå†œåœºå’Œå¸‚åœºæ”¶é›†çš„15ç§è”¬èœçš„å›¾åƒã€‚å…³äºè¯¥æ•°æ®é›†çš„å®˜æ–¹è®ºæ–‡å¯åœ¨<a class="ae le" href="https://www.researchgate.net/publication/352846889_DCNN-Based_Vegetable_Image_Classification_Using_Transfer_Learning_A_Comparative_Study" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>è·å¾—ã€‚æ•°æ®é›†å¯é€šè¿‡<a class="ae le" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0è®¸å¯è¯</a>è·å¾—ã€‚</p><p id="58e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¦‚æœæ‚¨æƒ³è·Ÿéšæ•™ç¨‹ï¼Œè¯·ä»<a class="ae le" href="https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset" rel="noopener ugc nofollow" target="_blank">è”¬èœå›¾åƒæ•°æ®é›†| Kaggle </a>ä¸‹è½½æ•°æ®é›†ï¼Œå¹¶å°†æ•°æ®ä¿å­˜åœ¨ä¸æ‚¨çš„ç¬”è®°æœ¬ä½äºåŒä¸€ç›®å½•çš„åä¸º<code class="fe mz na nb nc b">data</code>çš„æ–‡ä»¶å¤¹ä¸­ï¼Œå¹¶å°†<code class="fe mz na nb nc b">validation</code>å­ç›®å½•é‡å‘½åä¸º<code class="fe mz na nb nc b">valid</code>ã€‚å®Œæˆåï¼Œæ‚¨çš„å·¥ä½œç›®å½•å°†å¦‚ä¸‹æ‰€ç¤º:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="1b6c" class="nh md it nc b gy ni nj l nk nl">image_classification<br/>â”œâ”€â”€ *.ipynb<br/>â”œâ”€â”€ data<br/>â”‚   â”œâ”€â”€ train<br/>â”‚   â”‚   â”œâ”€â”€ class 1<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg<br/>â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”œâ”€â”€ class n<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg<br/>â”‚   â”œâ”€â”€ valid<br/>â”‚   â”‚   â”œâ”€â”€ class 1<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg<br/>â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”œâ”€â”€ class n<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg<br/>â”‚   â”œâ”€â”€ test<br/>â”‚   â”‚   â”œâ”€â”€ class 1<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg<br/>â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”œâ”€â”€ class n<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ ...<br/>â”‚   â”‚   â”‚   â”œâ”€â”€ imagen.jpg</span></pre><p id="9a59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è¿™æ˜¯ç»„ç»‡å›¾åƒçš„å®Œç¾æ ¼å¼ã€‚æ¯ä¸ªåˆ†åŒºæ•°æ®é›†å°†ä¸åŒç±»åˆ«çš„å›¾åƒä¿å­˜åœ¨ä»¥ç±»åˆ«å‘½åçš„å•ç‹¬å­ç›®å½•ä¸­ã€‚</p><p id="b171" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬ç°åœ¨å°†åŠ è½½å›¾åƒåº“å¹¶æ£€æŸ¥å›¾åƒæ€»æ•°:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="9231" class="nh md it nc b gy ni nj l nk nl">import pathlib<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>import seaborn as sns<br/>sns.set(style='darkgrid', context='talk')</span><span id="fb0f" class="nh md it nc b gy nm nj l nk nl">import tensorflow as tf<br/>from tensorflow.keras.preprocessing import image_dataset_from_directory<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import (Input, Rescaling, Conv2D, <br/>                                     MaxPooling2D, Flatten, Dense)<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.applications.resnet import ResNet50</span><span id="3920" class="nh md it nc b gy nm nj l nk nl">images = [*pathlib.Path('data').glob('**/*.jpg')]<br/>print(f"There are {len(images)} images.")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/aca20f14fa4f41f3d27e965d1129f026.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*HluWC7tI9FAICuZY7jhQJg.png"/></div></figure><p id="1561" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬æ€»å…±æœ‰21Kå¼ å›¾ç‰‡ã€‚è®©æˆ‘ä»¬ç¡®è®¤åœ¨åˆ†åŒºçš„æ•°æ®é›†ä¸­ç±»åæ˜¯ç›¸åŒçš„:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="59ed" class="nh md it nc b gy ni nj l nk nl">train_classes = [item.name for item in <br/>                 pathlib.Path('data/train').glob('*')]<br/>valid_classes = [item.name for item in <br/>                 pathlib.Path('data/valid').glob('*')]<br/>test_classes = [item.name for item in <br/>                pathlib.Path('data/test').glob('*')]</span><span id="cf45" class="nh md it nc b gy nm nj l nk nl">if train_classes==valid_classes==test_classes:<br/>    print("All datasets have the same classes.")<br/>print(f"There are total of {len(train_classes)} classes.")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ab717ad5876c3a29929b55fd1ec8f353.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*LVkImW6051iwSLuw92UK4Q.png"/></div></figure><p id="9894" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¤ªæ£’äº†ï¼Œæ•°æ®é›†ä¸Šçš„ç±»åéƒ½åŒ¹é…ã€‚æˆ‘ä»¬ç°åœ¨å°†åˆ›å»º<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> TensorFlowæ•°æ®é›†</a>ï¼Œå®ƒå°†åœ¨éœ€è¦æ—¶æ‰¹é‡åŠ è½½æ•°æ®ã€‚æˆ‘ä»¬å°†æ··æ´—è®­ç»ƒå›¾åƒï¼Œä»¥ä¾¿åœ¨æ¯ä¸€æ‰¹ä¸­æˆ‘ä»¬éƒ½æœ‰æ··åˆçš„è”¬èœã€‚</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="428d" class="nh md it nc b gy ni nj l nk nl">image_size = (224, 224)<br/>shape = image_size + (3,)<br/>batch_size = 32</span><span id="a129" class="nh md it nc b gy nm nj l nk nl">print("========== Training data ==========")<br/>train_data = image_dataset_from_directory(<br/>    directory='data/train', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    seed=42<br/>)<br/>print("\n========== Validation data ==========")<br/>valid_data = image_dataset_from_directory(<br/>    directory='data/valid', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    shuffle=False<br/>)</span><span id="612d" class="nh md it nc b gy nm nj l nk nl">print("\n========== Test data ==========")<br/>test_data = image_dataset_from_directory(<br/>    directory='data/test', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    shuffle=False<br/>)</span><span id="ac9e" class="nh md it nc b gy nm nj l nk nl">len(train_data.class_names)==len(valid_data.class_names)==len(test_data.class_names)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ca3b6d75e261b98108bfa7fd488f663e.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*kB3kU1Rnz1NJ3-cp_hQ2EA.png"/></div></figure><p id="40fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ä»å›¾åƒçš„çˆ¶ç›®å½•æ¨æ–­å›¾åƒçš„ç±»åã€‚æˆ‘ä»¬çœ‹åˆ°è¿™äº›æ¨æ–­çš„ç±»åå¯ä»¥é€šè¿‡<code class="fe mz na nb nc b">.class_names</code>å±æ€§è®¿é—®ã€‚è®©æˆ‘ä»¬æŒ‰ç±»æ£€æŸ¥æ¯ä¸ªæ•°æ®é›†çš„å›¾åƒæ•°é‡:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="956d" class="nh md it nc b gy ni nj l nk nl">summary = pd.DataFrame()<br/>for d in ['train', 'valid', 'test']:<br/>    for c in train_classes:<br/>        n = len([i for i in <br/>                 pathlib.Path(f'data/{d}/{c}').glob('*.jpg')])<br/>        summary.loc[c, d] = n<br/>summary.style.format("{:.0f}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/17522318910ec1b61e897e8f527e2996.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*-2FASMLIGMWZLJki2jjDxg.png"/></div></figure><p id="4f1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æ¯å ‚è¯¾æœ‰1000ä¸ªè®­ç»ƒã€200ä¸ªéªŒè¯å’Œ200ä¸ªæµ‹è¯•å›¾åƒã€‚</p><p id="b3bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨å¼€å§‹å»ºæ¨¡ä¹‹å‰çœ‹çœ‹ç¤ºä¾‹å›¾åƒ:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="8983" class="nh md it nc b gy ni nj l nk nl">n_rows = 2<br/>n_cols = 3</span><span id="0e03" class="nh md it nc b gy nm nj l nk nl">train_path = pathlib.Path('data/train')<br/>train_images = [item for item in train_path.glob('*/*.jpg')]<br/>np.random.seed(42)<br/>sample_images = np.random.choice(train_images, n_rows*n_cols, <br/>                                 replace=False)</span><span id="665e" class="nh md it nc b gy nm nj l nk nl">plt.figure(figsize=(12,8))<br/>for i, image in enumerate(sample_images):<br/>    ax = plt.subplot(n_rows, n_cols, i+1)<br/>    plt.imshow(mpimg.imread(image))<br/>    plt.axis('off')<br/>    plt.title(image.parts[2])<br/>plt.suptitle('Sample training images', fontsize=20);</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7668605b6f5ea8f8fce813bc12039cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*wbo_4Jsm2UY3rxIRN-0q_g.png"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="0084" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">ğŸ”¨ç³»ç»Ÿæ¨¡å‹åŒ–</h1><h2 id="dc11" class="nh md it bd me ns nt dn mi nu nv dp mm kr nw nx mo kv ny nz mq kz oa ob ms oc bi translated">ğŸ”§å‹å·0</h2><p id="991f" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">åœ¨ç¬¬1éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬æ„å»ºçš„CNNæ¶æ„è¢«è¯æ˜æ˜¯MNISTæ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä»å¯¹è”¬èœæ•°æ®åº”ç”¨ä¸åŸºçº¿æ¨¡å‹ç›¸åŒçš„ä½“ç³»ç»“æ„å¼€å§‹:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="5cf1" class="nh md it nc b gy ni nj l nk nl">n_classes = len(train_data.class_names)</span><span id="092e" class="nh md it nc b gy nm nj l nk nl">model_0 = Sequential([<br/>    Rescaling(1./255, input_shape=shape),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Flatten(),<br/>    Dense(128, activation='relu'),<br/>    Dense(n_classes, activation='softmax')<br/>])</span><span id="f150" class="nh md it nc b gy nm nj l nk nl">model_0.compile(loss='categorical_crossentropy', optimizer='Adam', <br/>                metrics=['accuracy'])<br/>model_0.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d2e4993529e57abee27a55e02b29e2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*VDF4qS92jO0D-v0T8KGNVw.png"/></div></figure><p id="433e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è®©æˆ‘ä»¬è®­ç»ƒç½‘ç»œã€‚æˆ‘ä»¬å°†åªè¿è¡Œä¸¤ä¸ªé˜¶æ®µï¼Œå› ä¸ºç°åœ¨åŸ¹è®­æ›´åŠ è€—æ—¶:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="fcbf" class="nh md it nc b gy ni nj l nk nl">hist_0 = model_0.fit(train_data, epochs=2, <br/>                     validation_data=valid_data)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/f3f80c8d3e07c52e17b46d16646eeffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*cXcgtS6ZaV9nvTY4etQ-Sg.png"/></div></figure><p id="41ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¯¹äº15ä¸ªç±»åˆ«ï¼Œå¤§çº¦87%çš„å‡†ç¡®ç‡ç›¸å½“ä¸é”™ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸åŒæ—¶æœŸçš„å‡†ç¡®æ€§:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d72a" class="nh md it nc b gy ni nj l nk nl">def clean_history(hist):<br/>    epochs = len(hist.history['accuracy'])<br/>    df = pd.DataFrame(<br/>        {'epochs': np.tile(np.arange(epochs), 2),<br/>         'accuracy': hist.history['accuracy'] + <br/>                     hist.history['val_accuracy'], <br/>         'loss': hist.history['loss'] + <br/>                 hist.history['val_loss'], <br/>         'dataset': np.repeat(['train', 'valid'], epochs)}<br/>    )<br/>    return df</span><span id="0a3a" class="nh md it nc b gy nm nj l nk nl">sns.lineplot(data=clean_history(hist_0), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/032d55954056cdc11786d54341c29e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*JEB-_49qIn7aJy0cQD91xA.png"/></div></figure><p id="3e8b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬å°†ä¸ºæ¯ä¸ªæµ‹è¯•å›¾åƒå‡†å¤‡æ ‡ç­¾ã€‚è¿™å°†æœ‰åŠ©äºè¿›ä¸€æ­¥è¯„ä¼°æ¨¡å‹:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="3d7b" class="nh md it nc b gy ni nj l nk nl">test_path = pathlib.Path('data/test')<br/>test_images = [item for item in test_path.glob('*/*.jpg')]</span><span id="22e3" class="nh md it nc b gy nm nj l nk nl">test_labels = []<br/>for _, labels in test_data.unbatch():<br/>    test_labels.append(labels.numpy().argmax())<br/>test_labels[:10]</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/4b5af0b8ac8eab79b55e8cd6f8193303.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*cDybMhiCKSSOhwJW3tzWxA.png"/></div></figure><p id="ffb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ ¹æ®æµ‹è¯•æ•°æ®æ£€æŸ¥æ¨¡å‹çš„æ€§èƒ½:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="13c5" class="nh md it nc b gy ni nj l nk nl">test_preds_0 = model_0.predict(test_data)<br/>test_classes_0 = test_preds_0.argmax(axis=1)<br/>test_metrics = pd.DataFrame(columns=['Test accuracy'])<br/>test_metrics.loc['model_0'] = np.mean(test_labels==test_classes_0)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5047b6dc1408395afde1fe73ed12b29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*7jp6rVTxM2is5dKu-f0I8A.png"/></div></figure><p id="42d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ç¬¬ä¸€ä¸ªæ¨¡å‹çº¦87%çš„å‡†ç¡®ç‡æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼€å§‹ã€‚è®©æˆ‘ä»¬é€šè¿‡è¯¾å ‚æ¥ç†è§£è¡¨æ¼”:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="275d" class="nh md it nc b gy ni nj l nk nl">def show_confusion_matrix(labels, classes):<br/>    cm = (pd.crosstab(pd.Series(labels, name='actual'), <br/>                      pd.Series(classes, name='predicted'))<br/>            .style.background_gradient('binary'))<br/>    return cm</span><span id="e3b3" class="nh md it nc b gy nm nj l nk nl">show_confusion_matrix(test_labels, test_classes_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/7c6e793e27823740729bdcd4d5141d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*RWtuPpQck-Zvcp0PXJInAA.jpeg"/></div></figure><p id="af9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¾ˆé«˜å…´çœ‹åˆ°å¤§éƒ¨åˆ†å›¾åƒéƒ½é›†ä¸­åœ¨å¯¹è§’çº¿ä¸Šã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©ä¸å‘½åç±»ï¼Œå› ä¸ºæœ‰ç©ºæ ¼(ç”¨ç±»åä»£æ›¿æ•°å­—ä¼šæ‰©å¤§è¡¨æ ¼çš„å°ºå¯¸)ã€‚å¯¹è§’çº¿ä¸Šæœ‰ä¸€äº›è¾ƒæ·±çš„ç°è‰²å•å…ƒæ ¼ã€‚ä¾‹å¦‚ï¼Œ3ç­æœ‰æ—¶ä¼šä¸10ç­æ··æ·†ã€‚æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥æ‰¾åˆ°3çº§å’Œ10çº§çš„æ ‡ç­¾:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="7b41" class="nh md it nc b gy ni nj l nk nl">print(f"Class 3 is {train_data.class_names[3]}")<br/>print(f"Class 10 is {train_data.class_names[10]}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oj"><img src="../Images/32ed4000ba40a4f58034639d8c4fb271.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*eq-Ck9sOt4JgPpsW_zhtmQ.png"/></div></div></figure><p id="0476" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æ‰€ä»¥å¸ƒæ—å“ˆå°”å¶å°”ä¼šè¢«è¯¯è®¤ä¸ºæ˜¯æœ¨ç“œã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ç¤ºä¾‹å›¾åƒåŠå…¶é¢„æµ‹:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="0993" class="nh md it nc b gy ni nj l nk nl">def inspect_sample_predictions(images, preds, dataset='test', <br/>                               seed=42, n_rows=2, n_cols=3):<br/>    np.random.seed(seed)<br/>    indices = np.random.choice(range(len(images)), n_rows*n_cols, <br/>                               replace=False)<br/>    plt.figure(figsize=(12,8))<br/>    for i, index in enumerate(indices):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        image = images[index]<br/>        plt.imshow(mpimg.imread(image))<br/>        plt.axis('off')<br/>        <br/>        proba = preds[index].max()<br/>        pred = preds[index].argmax()<br/>        pred_class = test_data.class_names[pred]<br/>        if pred_class == image.parts[2]:<br/>            colour = 'green'<br/>        else:<br/>            colour = 'red'<br/>        plt.title(f"Actual: {image.parts[2]} \nPredicted: {pred_class} ({proba:.1%})", color=colour, fontsize=14)<br/>    plt.suptitle(f'Sample {dataset} images with prediction', fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>inspect_sample_predictions(test_images, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ok"><img src="../Images/6ca58ab79ff564b3a432dbf291a0aa4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsUXOjMTfAy6rRnhtMetJg.png"/></div></div></figure><p id="23e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¾ˆé«˜å…´çœ‹åˆ°æ‰€æœ‰è¿™äº›æ ·æœ¬å›¾åƒéƒ½è¢«æ­£ç¡®é¢„æµ‹ã€‚æˆ‘ä»¬çœ‹åˆ°å„ç§é¢„æµ‹çš„ç½®ä¿¡åº¦ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹æœ€ä¸æ­£ç¡®çš„é¢„æµ‹:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="5d2f" class="nh md it nc b gy ni nj l nk nl">def see_most_incorrect(data, images, preds, dataset='test', seed=42, <br/>                       n_rows=2, n_cols=3):<br/>    df = pd.DataFrame()    <br/>    df['true_class'] = [image.parts[2] for image in images]<br/>    df['pred_class'] = [data.class_names[pred] for <br/>                        pred in preds.argmax(axis=1)]<br/>    df['proba'] = preds.max(axis=1)<br/>    incorrect_df = df.query("true_class!=pred_class")\<br/>                     .nlargest(n_rows*n_cols, 'proba')<br/>    <br/>    plt.figure(figsize=(8,5))<br/>    for i, (ind, row) in enumerate(incorrect_df.iterrows()):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        plt.imshow(plt.imread(images[ind]), cmap='binary')<br/>        plt.axis('off')<br/>        true = row['true_class']<br/>        proba = row['proba']<br/>        pred = row['pred_class']<br/>    <br/>        plt.title(f"Actual: {true}\nPred: {pred} ({proba:.1%})", fontsize=14, color='red')<br/>    plt.suptitle(f'Most incorrect {dataset} predictions', fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>see_most_incorrect(test_data, test_images, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8fa7ef8aea065363feaad6aa6c83e98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*qVIwx0uHtTADQAE4hEXbdw.png"/></div></figure><p id="cc4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">åœ¨ä¸Šé¢çš„ä¸­é—´å›¾åƒä¸­ï¼Œæ‚¨èƒ½é©¬ä¸Šåˆ†è¾¨å‡ºæ˜¯è¥¿çº¢æŸ¿å—ï¼Ÿè¥¿çº¢æŸ¿çš„é¢œè‰²ä¸æ˜¯ä½ æ‰€æœŸæœ›çš„ã€‚</p><p id="f31f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­æ‰€äº†è§£åˆ°çš„ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•é€šè¿‡æ·»åŠ å±‚ã€æ›´å¤šå•å…ƒã€è¿è¡Œæ›´å¤šæ—¶ä»£æ¥å¢åŠ æ¨¡å‹çš„å¤æ‚æ€§ã€‚å¦‚æœæ¨¡å‹å¯¹è®­ç»ƒæ•°æ®è¿‡æ‹Ÿåˆï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­åŠ å…¥<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" rel="noopener ugc nofollow" target="_blank">è„±è½å±‚</a>æœ‰åŠ©äºå‡å°‘è¿‡æ‹Ÿåˆã€‚æˆ–è€…ï¼Œé€šè¿‡æ•°æ®å¢å¼ºç­‰æŠ€æœ¯è·å–æ›´å¤šæ•°æ®æˆ–å¢åŠ æ•°æ®çš„å¤šæ ·æ€§ä¹Ÿæœ‰åŠ©äºæœ€å°åŒ–è¿‡åº¦æ‹Ÿåˆã€‚<a class="ae le" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank">æ•°æ®å¢å¼º</a>æ˜¯ä¸€ç§é€šè¿‡å˜æ¢å›¾åƒä½¿è®­ç»ƒæ•°æ®å¤šæ ·åŒ–çš„æŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œä½œä¸ºæ•°æ®å¢å¼ºçš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥éšæœºæ—‹è½¬ã€è£å‰ªã€å¹³ç§»ã€ç¼©æ”¾å’Œç¿»è½¬å›¾åƒã€‚å½“æ²¡æœ‰æ›´å¤šæ•°æ®å¯ç”¨æ—¶ï¼Œé€šè¿‡æ•°æ®å¢å¼ºä½¿æ•°æ®å¤šæ ·åŒ–å¯ä»¥å¸®åŠ©åœ¨æ›´å…·æ™®éæ€§çš„å›¾åƒä¸Šè®­ç»ƒæ¨¡å‹ã€‚</p><p id="f9d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è®©æˆ‘ä»¬çœ‹çœ‹æ˜¯å¦èƒ½æ”¹è¿›è¿™ä¸ªæ¨¡å‹ã€‚</p><h2 id="e517" class="nh md it bd me ns nt dn mi nu nv dp mm kr nw nx mo kv ny nz mq kz oa ob ms oc bi translated">ğŸ”§å‹å·1</h2><p id="d66f" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨è‡ªå·±æ„å»ºæ¨¡å‹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å¦ä¸€ç§é€‰æ‹©:è¿ç§»å­¦ä¹ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é‡ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚å¯¹äºè¿™ä¸ªè¿­ä»£ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è¿ç§»å­¦ä¹ ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç§ç§°ä¸ºç‰¹å¾æå–çš„è¿ç§»å­¦ä¹ ã€‚åœ¨ç‰¹å¾æå–ä¸­ï¼Œæˆ‘ä»¬å°†ä¿æŒé¢„è®­ç»ƒæ¨¡å‹ä¸å˜ï¼Œåªæ”¹å˜è¾“å‡ºå±‚ä»¥é€‚åº”æˆ‘ä»¬çš„ç”¨ä¾‹ã€‚</p><p id="ab2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬å°†ä½¿ç”¨<a class="ae le" href="https://paperswithcode.com/method/resnet" rel="noopener ugc nofollow" target="_blank"> ResNet-50å‹å·</a>ã€‚è¯¥æ¨¡å‹åœ¨é€šè¿‡<a class="ae le" href="https://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>æ•°æ®åº“è·å¾—çš„æ•°åƒå¼ å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒã€‚åœ¨TensorFlowä¸­ï¼Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•æ¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸‹é¢çš„ç®€å•æ–¹æ³•æ¥åŠ è½½ä¸€ä¸ªæ¨¡å‹ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®šResNetæ¨¡å‹ä¸åŒ…æ‹¬é¡¶å±‚ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è¦æ„å»ºè‡ªå·±çš„è¾“å‡ºå±‚ï¼Œå®ƒé€‚ç”¨äº15ä¸ªè”¬èœç±»ã€‚æˆ‘ä»¬å°†åœ¨ResNetæ¨¡å‹ä¸Šæ·»åŠ å±•å¹³å±‚å’Œè¾“å‡ºå±‚ã€‚</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="f948" class="nh md it nc b gy ni nj l nk nl">model_1 = Sequential([<br/>    ResNet50(include_top=False, weights='imagenet', <br/>             input_shape=shape),<br/>    Flatten(),<br/>    Dense(n_classes, activation='softmax')<br/>])</span><span id="fa5a" class="nh md it nc b gy nm nj l nk nl">model_1.compile(optimizer=Adam(learning_rate=0.0001), <br/>                loss='categorical_crossentropy', <br/>                metrics=['accuracy'])<br/>model_1.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/768dad68f0b71ac52d420252ddada58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*bQP2yN_tdnZgQWuNHqYyLA.png"/></div></figure><p id="911d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ç°åœ¨ï¼Œæˆ‘ä»¬å°†ç¡®ä¿æ‰€æœ‰å±‚éƒ½è¢«è®¾ç½®ä¸ºä¸å¯è®­ç»ƒï¼Œä»¥ä¾¿ä»ImageNetå­¦ä¹ çš„æ¨¡å‹çš„æƒé‡å’Œåå·®ä¿æŒä¸å˜ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®­ç»ƒæ¨¡å‹:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d0bf" class="nh md it nc b gy ni nj l nk nl">for layer in model_1.layers[0].layers:<br/>    layer.trainable=False<br/>hist_1 = model_1.fit(train_data, validation_data=valid_data, <br/>                     epochs=2)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/0560da49ba6aea5192fa890b670ecfba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*mN4gxQNx9BG2dETdiwcOJA.png"/></div></figure><p id="c9be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å“‡ï¼Œæ¨¡å‹ç²¾åº¦æ˜æ˜¾æé«˜äº†ï¼å³ä½¿æœ‰1 epochï¼Œæ€§èƒ½çœ‹èµ·æ¥ä¹Ÿå¾ˆæ£’ã€‚</p><p id="7c20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è®©æˆ‘ä»¬æŒ‰æ—¶ä»£æ¥çœ‹æ€§èƒ½:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="0dfc" class="nh md it nc b gy ni nj l nk nl">sns.lineplot(data=clean_history(hist_1), x='epochs', y='accuracy', <br/>                                hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b57653886964d5f7dd5f87085fc77834.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*zeAy3dYVAm6PYNxgbMd3Uw.png"/></div></figure><p id="3387" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">éšç€ç¬¬äºŒä¸ªçºªå…ƒï¼Œæˆ‘ä»¬å¼€å§‹ç¨å¾®è¿‡åº¦æ‹Ÿåˆã€‚</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d91e" class="nh md it nc b gy ni nj l nk nl">test_preds_1 = model_1.predict(test_data)<br/>test_classes_1 = test_preds_1.argmax(axis=1)<br/>test_metrics.loc['model_1'] = np.mean(test_labels==test_classes_1)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b45e6ff17c2cf23fa924c15c11fd748e.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*kTykr7CTHPPfoz1QLuVK8w.png"/></div></figure><p id="a5e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">15ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡è¾¾åˆ°98%å·¦å³ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ€§èƒ½ã€‚è®©æˆ‘ä»¬æŒ‰ç±»è¿›ä¸€æ­¥æŒ–æ˜:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="483b" class="nh md it nc b gy ni nj l nk nl">show_confusion_matrix(test_labels, test_classes_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/65a47a214e9ae798fe6230e4afccd306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*uYyDWYh0B8sij7SZownRog.jpeg"/></div></figure><p id="d67d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¾ˆé«˜å…´çœ‹åˆ°å¤§å¤šæ•°å€¼éƒ½é›†ä¸­åœ¨å¯¹è§’çº¿ä¸Šã€‚é€šè¿‡é‡ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è¾¾åˆ°äº‹åŠåŠŸå€çš„æ•ˆæœã€‚</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="915b" class="nh md it nc b gy ni nj l nk nl">inspect_sample_predictions(test_images, test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi or"><img src="../Images/f7608ccfc583e940e422260695d8501f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NbUJU0sXUdkNX-jKQE4dg.png"/></div></div></figure><p id="f1e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ä¸ä¸Šä¸€æ¬¡è¿­ä»£ä¸€æ ·ï¼Œæ ·æœ¬å›¾åƒè¢«æ­£ç¡®é¢„æµ‹ã€‚é¢„æµ‹æ¦‚ç‡æ¯”ä»¥å‰æ›´é«˜ã€‚</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="80bc" class="nh md it nc b gy ni nj l nk nl">see_most_incorrect(test_data, test_images, test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/7a2e22a6cec31ff335bccc48b341d0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*25PJYkv_X8w7NCUm1NG-UQ.png"/></div></figure><p id="6832" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æœ‰è¶£çš„æ˜¯ï¼Œçº¢åº•èåœå’Œèƒ¡èåœè¢«æ··æ·†äº†ã€‚è¿™æœ‰åŠ©äºäº†è§£æ¨¡å‹çš„é”™è¯¯ä¹‹å¤„ã€‚</p><p id="34c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è¿ç§»å­¦ä¹ ä¹Ÿé€‚ç”¨äºè¾ƒå°çš„æ•°æ®é›†(å³è¾ƒå°‘çš„å›¾åƒ)ï¼Œåªè¦æ‚¨ä½¿ç”¨çš„æ¨¡å‹æ˜¯åœ¨ç›¸ä¼¼çš„æ•°æ®é›†ä¸Šé¢„å…ˆè®­ç»ƒçš„ã€‚å·²ç»å¯¹è¿ç§»å­¦ä¹ æœ‰äº†ä¸€ä¸ªå¿«é€Ÿçš„ä»‹ç»ï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿ç§»å­¦ä¹ çš„çŸ¥è¯†ï¼Œ<a class="ae le" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">è¿™ä¸ªèµ„æº</a>å¯èƒ½ä¼šæœ‰å¸®åŠ©ã€‚å¦‚æœæ‚¨æƒ³å°è¯•å…¶ä»–é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·ä»<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>æŸ¥çœ‹å…¶ä»–å¯ç”¨æ¨¡å‹ã€‚</p><p id="7e67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å…¨éƒ¨å†…å®¹ï¼å¸Œæœ›ä½ å·²ç»å­¦åˆ°äº†ä¸€äº›å®ç”¨çš„æŠ€èƒ½ï¼Œå¯ä»¥å¼€å§‹ä½ çš„è®¡ç®—æœºè§†è§‰ä¹‹æ—…ã€‚å¦‚æœä½ æƒ³é€šè¿‡åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šåº”ç”¨æˆ‘ä»¬ä½œä¸ºç³»åˆ—çš„ä¸€éƒ¨åˆ†æ‰€å­¦çš„çŸ¥è¯†æ¥è·å¾—æ›´å¤šçš„å›¾åƒåˆ†ç±»ç»éªŒï¼ŒKaggle ä¸­çš„è¿™ä¸ª<a class="ae le" href="https://www.kaggle.com/datasets?tags=13207-Computer+Vision" rel="noopener ugc nofollow" target="_blank">å¼€æ”¾æ•°æ®é›†å¯èƒ½å¯¹ä½ æœ‰ç”¨ã€‚</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ot"><img src="../Images/7516c6e0134b6b2778f564be0d6bd06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LZT7z7uWRpfZjnwg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">å®‰å¨œÂ·ä½©å°”æ³½åœ¨<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>ä¸Šçš„ç…§ç‰‡</p></figure><p id="a5a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ou">æ‚¨æƒ³è®¿é—®æ›´å¤šè¿™æ ·çš„å†…å®¹å—ï¼Ÿåª’ä½“ä¼šå‘˜å¯ä»¥æ— é™åˆ¶åœ°è®¿é—®åª’ä½“ä¸Šçš„ä»»ä½•æ–‡ç« ã€‚å¦‚æœä½ ä½¿ç”¨</em> <a class="ae le" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="ou">æˆ‘çš„æ¨èé“¾æ¥</em> </a>ï¼Œ<em class="ou">æˆä¸ºä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šè´¹ä¼šç›´æ¥å»æ”¯æŒæˆ‘ã€‚</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6e0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è°¢è°¢ä½ çœ‹æˆ‘çš„å¸–å­ã€‚å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¿™é‡Œæœ‰æˆ‘çš„ä¸€äº›å¸–å­çš„é“¾æ¥:</p><p id="92d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">â—¼ï¸ï¸ <a class="ae le" rel="noopener" target="_blank" href="/pipeline-columntransformer-and-featureunion-explained-f5491f815f?source=your_stories_page-------------------------------------">ç®¡é“ã€ColumnTransformerå’ŒFeatureUnionè®²è§£</a> <br/> â—¼ï¸ï¸ <a class="ae le" rel="noopener" target="_blank" href="/featureunion-columntransformer-pipeline-for-preprocessing-text-data-9dcb233dbcb6"> FeatureUnionã€ColumnTransformer &amp;ç®¡é“ç”¨äºé¢„å¤„ç†æ–‡æœ¬æ•°æ®</a> <br/> â—¼ï¸ <a class="ae le" rel="noopener" target="_blank" href="/enrich-your-jupyter-notebook-with-these-tips-55c8ead25255">ç”¨è¿™äº›æç¤ºä¸°å¯Œæ‚¨çš„Jupyterç¬”è®°æœ¬</a> <br/> â—¼ï¸ <a class="ae le" rel="noopener" target="_blank" href="/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f">ç”¨è¿™äº›æç¤ºæ•´ç†æ‚¨çš„Jupyterç¬”è®°æœ¬</a> <br/> â—¼ï¸ <a class="ae le" rel="noopener" target="_blank" href="/explaining-scikit-learn-models-with-shap-61daff21b12a">è®²è§£Scikit-ç”¨SHAPå­¦ä¹ æ¨¡å‹</a> <br/> â—¼ï¸ï¸ <a class="ae le" rel="noopener" target="_blank" href="/feature-selection-in-scikit-learn-dc005dcf38b7">åœ¨scikitä¸­é€‰æ‹©ç‰¹æ€§</a></p><p id="6518" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å†è§ğŸƒ ğŸ’¨</p></div></div>    
</body>
</html>