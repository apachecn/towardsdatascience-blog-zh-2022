<html>
<head>
<title>Stable diffusion using Hugging Face</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨æ‹¥æŠ±è„¸çš„ç¨³å®šæ‰©æ•£</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/stable-diffusion-using-hugging-face-501d8dbdd8#2022-11-09">https://towardsdatascience.com/stable-diffusion-using-hugging-face-501d8dbdd8#2022-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c514" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">å¯¹ç¨³å®šæ‰©æ•£ä¸–ç•Œçš„å…¨é¢ä»‹ç»ä½¿ç”¨<a class="ae kf" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">æ‹¥æŠ±è„¸</a>â€”â€”<a class="ae kf" href="https://github.com/huggingface/diffusers" rel="noopener ugc nofollow" target="_blank">æ‰©æ•£å™¨åº“</a>ä½¿ç”¨æ–‡æœ¬æç¤ºåˆ›å»ºäººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒ</h2></div><h1 id="a29a" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">1.ä»‹ç»</h1><p id="2b89" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ä½ å¯èƒ½å·²ç»çœ‹åˆ°äººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒæœ‰æ‰€ä¸Šå‡ï¼Œè¿™æ˜¯å› ä¸ºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å…´èµ·ã€‚ç¨³å®šæ‰©æ•£ç®€å•åœ°è¯´æ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå®ƒå¯ä»¥åœ¨ç»™å®šæ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹ç”Ÿæˆå›¾åƒã€‚</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/bf1adc4be4aaff3fdb63da734f64c54b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HMK6Kw0smilQ9abp.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾1:ç¨³å®šæ‰©æ•£æ¦‚è¿°</p></figure><p id="62ca" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ä»ä¸Šé¢çš„å›¾åƒä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ é€’ä¸€ä¸ªæ–‡æœ¬æç¤ºï¼Œæ¯”å¦‚â€œä¸€åªæˆ´ç€å¸½å­çš„ç‹—â€ï¼Œä¸€ä¸ªç¨³å®šçš„æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆä¸€ä¸ªä»£è¡¨æ–‡æœ¬çš„å›¾åƒã€‚ç›¸å½“æƒŠäººï¼</p><h1 id="d3ac" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">2.ä½¿ç”¨ğŸ¤—æ‰©æ•£å™¨åº“</h1><p id="595e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ä¸ä»»ä½•pythonåº“ä¸€æ ·ï¼Œåœ¨è¿è¡Œå®ƒä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦éµå¾ªç‰¹å®šçš„å®‰è£…æ­¥éª¤ï¼Œä¸‹é¢æ˜¯è¿™äº›æ­¥éª¤çš„æ¦‚è¦ã€‚</p><ol class=""><li id="4f9f" class="mp mq iq la b lb mk le ml lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la ir">æ¥å—è®¸å¯â€” </strong>åœ¨ä½¿ç”¨æ¨¡å‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦å‰å¾€<a class="ae kf" href="https://huggingface.co/CompVis/stable-diffusion-v1-4" rel="noopener ugc nofollow" target="_blank">æ­¤å¤„</a>ä½¿ç”¨æ‚¨çš„æ‹¥æŠ±è„¸å¸æˆ·ç™»å½•ï¼Œç„¶åæ¥å—æ¨¡å‹è®¸å¯ï¼Œä¸‹è½½å¹¶ä½¿ç”¨ç ç ã€‚</li><li id="6dcb" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la ir">ä»¤ç‰Œç”Ÿæˆâ€” </strong>å¦‚æœè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡ä½¿ç”¨æ‹¥æŠ±äººè„¸åº“ï¼Œè¿™å¬èµ·æ¥å¯èƒ½æœ‰ç‚¹å¥‡æ€ªã€‚æ‚¨éœ€è¦è½¬åˆ°è¿™é‡Œçš„<a class="ae kf" href="https://huggingface.co/settings/tokens" rel="noopener ugc nofollow" target="_blank">å¹¶ç”Ÿæˆä¸€ä¸ªä»¤ç‰Œ(æœ€å¥½æœ‰å†™æƒé™)æ¥ä¸‹è½½æ¨¡å‹ã€‚</a></li></ol><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nd"><img src="../Images/7c05eb786bb748c3979b5e44f705eeb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*si8PgxlEKc6hZO_s.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾2:è®¿é—®ä»¤ç‰Œé¡µé¢</p></figure><p id="5379" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">3.<strong class="la ir">å®‰è£…hugging face hubåº“å¹¶ç™»å½•â€” </strong>ç”Ÿæˆä»¤ç‰Œåï¼Œå¤åˆ¶å®ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸‹é¢çš„ä»£ç ä¸‹è½½hugging face hubåº“ã€‚</p><p id="e6dd" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="la ir"> <em class="ne">æ³¨æ„â€” </em> </strong> <em class="ne">ä¸ºäº†ç”¨ä»£ç æ­£ç¡®åœ°æ¸²æŸ“è¿™äº›å†…å®¹ï¼Œæˆ‘æ¨èä½ åœ¨è¿™é‡Œé˜…è¯»</em><a class="ae kf" href="https://aayushmnit.com/posts/2022-11-02-StabeDiffusionP1/2022-11-02-StableDiffusionP1.html" rel="noopener ugc nofollow" target="_blank"><em class="ne"/></a><em class="ne">ã€‚</em></p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="94bc" class="nk kh iq ng b be nl nm l nn no">!pip install huggingface-hub==0.10.1</span></pre><p id="fa99" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ç„¶åä½¿ç”¨ä¸‹é¢çš„ä»£ç ï¼Œä¸€æ—¦è¿è¡Œå®ƒï¼Œå°±ä¼šå‡ºç°ä¸€ä¸ªå°éƒ¨ä»¶ï¼Œç²˜è´´æ‚¨æ–°ç”Ÿæˆçš„ä»¤ç‰Œï¼Œç„¶åå•å‡»ç™»å½•ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="5e96" class="nk kh iq ng b be nl nm l nn no">from huggingface_hub import notebook_login<br/>notebook_login()</span></pre><p id="704b" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">4.I <strong class="la ir">å®‰è£…æ‰©æ•£å™¨å’Œå˜å‹å™¨åº“â€” </strong>ä¸€æ—¦è¯¥è¿‡ç¨‹å®Œæˆï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç å®‰è£…ä¾èµ–é¡¹ã€‚è¿™å°†ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„<a class="ae kf" href="https://github.com/huggingface/diffusers" rel="noopener ugc nofollow" target="_blank">æ‰©æ•£å™¨</a>å’Œ<a class="ae kf" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">å˜å½¢é‡‘åˆš</a>åº“ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="9293" class="nk kh iq ng b be nl nm l nn no">!pip install -qq -U diffusers transformers</span></pre><p id="f484" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">å°±è¿™æ ·ï¼Œç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½ä½¿ç”¨æ‰©æ•£å™¨åº“äº†ã€‚</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="22d4" class="kg kh iq bd ki kj nw kl km kn nx kp kq jw ny jx ks jz nz ka ku kc oa kd kw kx bi translated">3.è¿è¡Œç¨³å®šçš„æ‰©æ•£â€”â€”é«˜å±‚ç®¡é“</h1><p id="4581" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ç¬¬ä¸€æ­¥æ˜¯ä»æ‰©æ•£å™¨åº“ä¸­å¯¼å…¥<code class="fe ob oc od ng b">StableDiffusionPipeline</code>ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="f25a" class="nk kh iq ng b be nl nm l nn no">from diffusers import StableDiffusionPipeline</span></pre><p id="4cc2" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ä¸‹ä¸€æ­¥æ˜¯åˆå§‹åŒ–ç®¡é“ä»¥ç”Ÿæˆå›¾åƒã€‚ç¬¬ä¸€æ¬¡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ—¶ï¼Œå®ƒä¼šå°†æ¨¡å‹ä»hugging faceæ¨¡å‹ä¸­å¿ƒä¸‹è½½åˆ°æ‚¨çš„æœ¬åœ°æœºå™¨ä¸Šã€‚æ‚¨å°†éœ€è¦ä¸€å°GPUæœºå™¨æ¥è¿è¡Œè¿™æ®µä»£ç ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="cd95" class="nk kh iq ng b be nl nm l nn no">pipe = StableDiffusionPipeline.from_pretrained('CompVis/stable-diffusion-v1-4').to('cuda')</span></pre><p id="aef3" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ç°åœ¨è®©æˆ‘ä»¬ä¼ é€’ä¸€ä¸ªæ–‡æœ¬æç¤ºå¹¶ç”Ÿæˆä¸€ä¸ªå›¾åƒã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="6c89" class="nk kh iq ng b be nl nm l nn no"># Initialize a prompt<br/>prompt = "a dog wearing hat"<br/># Pass the prompt in the pipeline<br/>pipe(prompt).images[0]</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/54f915c62e02227ce6fa3edec5540c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*udODoCD9e37_Az8I.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾3:ç”±æ‰©æ•£ç®¡é“äº§ç”Ÿçš„å›¾åƒçš„ä¾‹å­ã€‚</p></figure><h1 id="184d" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">4.äº†è§£ç¨³å®šæ‰©æ•£çš„æ ¸å¿ƒè¦ç´ </h1><p id="b3c0" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">å¦‚ä¸Šæ‰€ç¤ºçš„æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚ç¨³å®šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç‰¹æ®Šçš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º<strong class="la ir">æ½œåœ¨æ‰©æ•£</strong>æ¨¡å‹ã€‚ä»–ä»¬åœ¨è¿™ç¯‡è®ºæ–‡ä¸­é¦–æ¬¡æå‡ºäº†<a class="ae kf" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆ</a>ã€‚åŸå§‹æ‰©æ•£æ¨¡å‹å¾€å¾€ä¼šæ¶ˆè€—æ›´å¤šçš„å†…å­˜ï¼Œå› æ­¤åˆ›å»ºäº†æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå®ƒå¯ä»¥åœ¨ç§°ä¸º<code class="fe ob oc od ng b">Latent</code>ç©ºé—´çš„ä½ç»´ç©ºé—´ä¸­è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ã€‚åœ¨é«˜å±‚æ¬¡ä¸Šï¼Œæ‰©æ•£æ¨¡å‹æ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå…¶è¢«é€æ­¥è®­ç»ƒåˆ°<code class="fe ob oc od ng b">denoise</code>éšæœºé«˜æ–¯å™ªå£°ï¼Œä»¥å¾—åˆ°ç»“æœï¼Œå³<code class="fe ob oc od ng b">image</code>ã€‚åœ¨<code class="fe ob oc od ng b">latent diffusion</code>ä¸­ï¼Œæ¨¡å‹è¢«è®­ç»ƒåœ¨ä¸€ä¸ªè¾ƒä½çš„ç»´åº¦ä¸ŠåšåŒæ ·çš„è¿‡ç¨‹ã€‚</p><p id="5db7" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ½œåœ¨æ‰©æ•£æœ‰ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†</p><ol class=""><li id="b8b5" class="mp mq iq la b lb mk le ml lh mr ll ms lp mt lt mu mv mw mx bi translated">ä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸€ä¸ª<a class="ae kf" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">å‰ªè¾‘æ–‡æœ¬ç¼–ç å™¨</a></li><li id="eb65" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">è‡ªåŠ¨ç¼–ç å™¨ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå˜å‹è‡ªåŠ¨ç¼–ç å™¨ä¹Ÿç§°ä¸ºVAE</li><li id="6ecd" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">ä¸€ä¸ª<a class="ae kf" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> Uå½¢ç½‘</a></li></ol><p id="ede6" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬æ·±å…¥è¿™äº›ç»„ä»¶ï¼Œäº†è§£å®ƒä»¬åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­çš„ç”¨é€”ã€‚æˆ‘å°†å°è¯•é€šè¿‡ä»¥ä¸‹ä¸‰ä¸ªé˜¶æ®µæ¥è§£é‡Šè¿™äº›ç»„æˆéƒ¨åˆ†</p><ol class=""><li id="61c0" class="mp mq iq la b lb mk le ml lh mr ll ms lp mt lt mu mv mw mx bi translated"><strong class="la ir"> <em class="ne">åŸºç¡€çŸ¥è¯†:ä»€ä¹ˆè¿›å…¥ç»„ä»¶ï¼Œä»€ä¹ˆä»ç»„ä»¶ä¸­å‡ºæ¥</em></strong>â€”â€”è¿™æ˜¯ç†è§£â€œæ•´ä¸ªæ¸¸æˆâ€çš„<a class="ae kf" href="https://www.fast.ai/posts/2016-10-08-teaching-philosophy.html" rel="noopener ugc nofollow" target="_blank">è‡ªä¸Šè€Œä¸‹å­¦ä¹ æ–¹æ³•</a>çš„ä¸€ä¸ªé‡è¦ä¸”å…³é”®çš„éƒ¨åˆ†</li><li id="276c" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la ir"> <em class="ne">æ›´æ·±å±‚æ¬¡çš„è§£é‡Šè¿ç”¨ğŸ¤—ä»£ç ã€‚</em></strong>â€”â€”è¿™ä¸€éƒ¨åˆ†å°†æä¾›å¯¹æ¨¡å‹ä½¿ç”¨ä»£ç äº§ç”Ÿä»€ä¹ˆçš„æ›´å¤šç†è§£</li><li id="03d0" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><strong class="la ir"> <em class="ne">å®ƒä»¬åœ¨ç¨³å®šæ‰©æ•£ç®¡é“ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆ</em> </strong> â€”è¿™å°†è®©ä½ å¯¹è¿™ç§æˆåˆ†åœ¨ç¨³å®šæ‰©æ•£è¿‡ç¨‹ä¸­çš„ä½œç”¨æœ‰ä¸€ä¸ªç›´è§‚çš„è®¤è¯†ã€‚è¿™å°†æœ‰åŠ©äºä½ å¯¹æ‰©æ•£è¿‡ç¨‹çš„ç›´è§‰</li></ol><h1 id="2f53" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">5.å‰ªè¾‘æ–‡æœ¬ç¼–ç å™¨</h1><h2 id="e260" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">5.1åŸºç¡€çŸ¥è¯†â€”ä»€ä¹ˆè¿›å‡ºç»„ä»¶ï¼Ÿ</h2><p id="6428" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">CLIP(å¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ)æ–‡æœ¬ç¼–ç å™¨å°†æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆæ½œåœ¨ç©ºé—´æ¥è¿‘çš„æ–‡æœ¬åµŒå…¥ï¼Œå°±åƒé€šè¿‡CLIPæ¨¡å‹å¯¹å›¾åƒè¿›è¡Œç¼–ç ä¸€æ ·ã€‚</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi or"><img src="../Images/401593f8496db0d0acc857c31e5834c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lG2abynBvLOYGBgc.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾4:å‰ªè¾‘æ–‡æœ¬ç¼–ç å™¨</p></figure><h2 id="8051" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">2.2ä½¿ç”¨æ›´æ·±å…¥çš„è§£é‡ŠğŸ¤—å¯†ç </h2><p id="55f5" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹éƒ½ä¸ç†è§£æ–‡æœ¬æ•°æ®ã€‚å¯¹äºä»»ä½•ç†è§£æ–‡æœ¬æ•°æ®çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éƒ½éœ€è¦å°†è¿™ä¸ªæ–‡æœ¬è½¬æ¢æˆä¿å­˜æ–‡æœ¬å«ä¹‰çš„æ•°å­—ï¼Œç§°ä¸º<code class="fe ob oc od ng b">embeddings</code>ã€‚å°†æ–‡æœ¬è½¬æ¢æˆæ•°å­—çš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ã€‚<strong class="la ir"> <em class="ne">è®°å·åŒ–å™¨</em></strong>â€”â€”å°†æ¯ä¸ªå•è¯åˆ†è§£æˆå­å•è¯ï¼Œç„¶åä½¿ç”¨æŸ¥æ‰¾è¡¨å°†å®ƒä»¬è½¬æ¢æˆæ•°å­—<br/> 2ã€‚<strong class="la ir"> <em class="ne"> Token_To_Embeddingç¼–ç å™¨</em></strong>â€”â€”å°†é‚£äº›æ•°å­—å­è¯è½¬æ¢æˆåŒ…å«è¯¥æ–‡æœ¬è¡¨ç¤ºçš„è¡¨ç¤º</p><p id="2eca" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æˆ‘ä»¬é€šè¿‡ä»£ç æ¥çœ‹ä¸€ä¸‹ã€‚æˆ‘ä»¬å°†ä»å¯¼å…¥ç›¸å…³çš„å·¥ä»¶å¼€å§‹ã€‚</p><p id="ee8d" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="la ir"> <em class="ne">æ³¨â€” </em> </strong> <em class="ne">è¦ç”¨ä»£ç æ­£ç¡®åœ°æ¸²æŸ“è¿™äº›å†…å®¹ï¼Œæˆ‘æ¨èä½ åœ¨è¿™é‡Œé˜…è¯»</em><a class="ae kf" href="https://aayushmnit.com/posts/2022-11-05-StableDiffusionP2/2022-11-05-StableDiffusionP2.html" rel="noopener ugc nofollow" target="_blank"><em class="ne"/></a><em class="ne">ã€‚</em></p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="df6f" class="nk kh iq ng b be nl nm l nn no">import torch, logging<br/>## disable warnings<br/>logging.disable(logging.WARNING)  <br/>## Import the CLIP artifacts <br/>from transformers import CLIPTextModel, CLIPTokenizer<br/>## Initiating tokenizer and encoder.<br/>tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16)<br/>text_encoder = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16).to("cuda")</span></pre><p id="f65b" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªæç¤ºç¬¦å¹¶å¯¹å…¶è¿›è¡Œæ ‡è®°ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="1634" class="nk kh iq ng b be nl nm l nn no">prompt = ["a dog wearing hat"]<br/>tok =tokenizer(prompt, padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt") <br/>print(tok.input_ids.shape)<br/>tok</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi os"><img src="../Images/9145b1c26602192c5ccf417a1f5370e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_oFRDav1Yq6EhL0OraUqWg.png"/></div></div></figure><p id="d2da" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">A <code class="fe ob oc od ng b">tokenizer</code>ä»¥å­—å…¸çš„å½¢å¼è¿”å›ä¸¤ä¸ªå¯¹è±¡- <br/> 1ã€‚<code class="fe ob oc od ng b"><strong class="la ir"><em class="ne">input_ids</em></strong></code> -ä¸€ä¸ªå¤§å°ä¸º1x77çš„å¼ é‡ä½œä¸ºä¸€ä¸ªæç¤ºè¢«ä¼ é€’å¹¶å¡«å……åˆ°77çš„æœ€å¤§é•¿åº¦ã€‚<code class="fe ob oc od ng b"><em class="ne">49406</em></code>æ˜¯å¼€å§‹æ ‡è®°ï¼Œ<code class="fe ob oc od ng b"><em class="ne">320</em></code>æ˜¯ç»™äºˆå•è¯â€œaâ€çš„æ ‡è®°ï¼Œ<code class="fe ob oc od ng b"><em class="ne">1929</em></code>æ˜¯ç»™äºˆå•è¯â€œdogâ€çš„æ ‡è®°ï¼Œ<code class="fe ob oc od ng b"><em class="ne">3309</em></code>æ˜¯ç»™äºˆå•è¯â€œwearâ€çš„æ ‡è®°ï¼Œ<code class="fe ob oc od ng b"><em class="ne">3801</em></code>æ˜¯ç»™äºˆå•è¯â€œhatâ€çš„æ ‡è®°ï¼Œ<code class="fe ob oc od ng b"><em class="ne">49407</em></code>æ˜¯æ–‡æœ¬ç»“æŸæ ‡è®°ï¼Œé‡å¤ç›´åˆ°å¡«å……é•¿åº¦ä¸º77ã€‚<br/> 2ã€‚<code class="fe ob oc od ng b"><strong class="la ir"><em class="ne">attention_mask</em></strong></code> - <code class="fe ob oc od ng b">1</code>è¡¨ç¤ºåµŒå…¥å€¼ï¼Œ<code class="fe ob oc od ng b">0</code>è¡¨ç¤ºå¡«å……ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="fac7" class="nk kh iq ng b be nl nm l nn no">for token in list(tok.input_ids[0,:7]): <br/>    print(f"{token}:{tokenizer.convert_ids_to_tokens(int(token))}")</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi ot"><img src="../Images/d832a1e05d4a4f46dff46305ee527382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aYze8-Ilc3lzcgIchBg2w.png"/></div></div></figure><p id="153d" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹<code class="fe ob oc od ng b">Token_To_Embedding Encoder</code>ï¼Œå®ƒæ¥å—ç”±è®°å·èµ‹äºˆå™¨ç”Ÿæˆçš„<code class="fe ob oc od ng b">input_ids</code>,å¹¶å°†å®ƒä»¬è½¬æ¢æˆåµŒå…¥-</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="6f42" class="nk kh iq ng b be nl nm l nn no">emb = text_encoder(tok.input_ids.to("cuda"))[0].half()<br/>print(f"Shape of embedding : {emb.shape}")<br/>emb</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi ou"><img src="../Images/3eac8bddd01cdaf58bc489b95e19b9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jmrK7CQ3jOwOGVp5dNyCfA.png"/></div></div></figure><p id="75a2" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šé¢çœ‹åˆ°çš„ï¼Œæ¯ä¸ªå¤§å°ä¸º1x77çš„æ ‡è®°åŒ–è¾“å…¥ç°åœ¨å·²ç»è¢«è½¬æ¢ä¸º1x77x768å½¢çŠ¶åµŒå…¥ã€‚æ‰€ä»¥ï¼Œæ¯ä¸ªå•è¯éƒ½åœ¨ä¸€ä¸ª768ç»´çš„ç©ºé—´ä¸­è¢«è¡¨ç°å‡ºæ¥ã€‚</p><h1 id="1c8e" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">5.3ä»–ä»¬åœ¨ç¨³å®šæ‰©æ•£ç®¡é“ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆ</h1><p id="4980" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ç¨³å®šæ‰©æ•£ä»…ä½¿ç”¨å‰ªè¾‘è®­ç»ƒçš„ç¼–ç å™¨æ¥å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥ã€‚è¿™æˆä¸ºU-netçš„è¾“å…¥ä¹‹ä¸€ã€‚åœ¨é«˜å±‚æ¬¡ä¸Šï¼ŒCLIPä½¿ç”¨å›¾åƒç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨æ¥åˆ›å»ºåœ¨æ½œåœ¨ç©ºé—´ä¸­ç›¸ä¼¼çš„åµŒå…¥ã€‚è¿™ç§ç›¸ä¼¼æ€§è¢«æ›´ç²¾ç¡®åœ°å®šä¹‰ä¸º<a class="ae kf" href="https://arxiv.org/abs/1807.03748" rel="noopener ugc nofollow" target="_blank">å¯¹æ¯”ç›®æ ‡</a>ã€‚å…³äºCLIPå¦‚ä½•è®­ç»ƒçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒè¿™ä¸ª<a class="ae kf" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">å¼€æ”¾AIåšå®¢</a>ã€‚</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/e64fa9a7e5b65ba9413c9220057eaa11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/0*4XvUWf4NK7gvDQjP.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾5: CLIPé¢„å…ˆè®­ç»ƒäº†ä¸€ä¸ªå›¾åƒç¼–ç å™¨å’Œä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œä»¥é¢„æµ‹åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸­å“ªäº›å›¾åƒä¸å“ªäº›æ–‡æœ¬é…å¯¹ã€‚ä¿¡ç”¨â€” <a class="ae kf" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> OpenAI </a></p></figure><h1 id="2049" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">6.VAE â€”å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨</h1><h2 id="e119" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">6.1åŸºç¡€çŸ¥è¯†â€”ä»€ä¹ˆè¿›å‡ºç»„ä»¶ï¼Ÿ</h2><p id="6bdc" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨åŒ…å«ä¸¤éƒ¨åˆ†- <br/> 1ã€‚<code class="fe ob oc od ng b">Encoder</code>å°†å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä½ç»´æ½œåœ¨è¡¨ç¤º<br/> 2ã€‚<code class="fe ob oc od ng b">Decoder</code>è·å–æ½œåƒå¹¶å°†å…¶è½¬æ¢å›å›¾åƒ</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi ow"><img src="../Images/291731162277ed2bacca600ba0c21169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kKahWKJ-kGJ4TAin.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾6:ä¸€ä¸ªå˜åŒ–çš„è‡ªåŠ¨ç¼–ç å™¨ã€‚åŸé¸Ÿ<a class="ae kf" href="https://lafeber.com/pet-birds/wp-content/uploads/2018/06/Scarlet-Macaw-2.jpg" rel="noopener ugc nofollow" target="_blank"> picåŠŸåŠ³</a>ã€‚</p></figure><p id="9696" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šé¢çœ‹åˆ°çš„ï¼Œç¼–ç å™¨å°±åƒä¸€ä¸ªå‹ç¼©å™¨ï¼Œå°†å›¾åƒå‹ç¼©åˆ°æ›´ä½çš„ç»´åº¦ï¼Œè§£ç å™¨ä»å‹ç¼©ç‰ˆæœ¬ä¸­é‡æ–°åˆ›å»ºåŸå§‹å›¾åƒã€‚</p><blockquote class="ox oy oz"><p id="a7e0" class="ky kz ne la b lb mk jr ld le ml ju lg pa mm lj lk pb mn ln lo pc mo lr ls lt ij bi translated"><strong class="la ir">æ³¨æ„:</strong>ç¼–è§£ç å‹ç¼©-è§£å‹ç¼©ä¸æ˜¯æ— æŸçš„ã€‚</p></blockquote><h2 id="68ab" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">6.2æ›´æ·±å…¥çš„è§£é‡Šä½¿ç”¨ğŸ¤—å¯†ç </h2><p id="b49c" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">è®©æˆ‘ä»¬é€šè¿‡ä»£ç æ¥çœ‹çœ‹VAEã€‚æˆ‘ä»¬å°†ä»å¯¼å…¥æ‰€éœ€çš„åº“å’Œä¸€äº›è¾…åŠ©å‡½æ•°å¼€å§‹ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="954c" class="nk kh iq ng b be nl nm l nn no">## To import an image from a URL <br/>from fastdownload import FastDownload  <br/>## Imaging  library <br/>from PIL import Image <br/>from torchvision import transforms as tfms  <br/>## Basic libraries <br/>import numpy as np <br/>import matplotlib.pyplot as plt <br/>%matplotlib inline  <br/>## Loading a VAE model <br/>from diffusers import AutoencoderKL <br/>vae = AutoencoderKL.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="vae", torch_dtype=torch.float16).to("cuda")<br/>def load_image(p):<br/>   '''     <br/>   Function to load images from a defined path     <br/>   '''    <br/>    return Image.open(p).convert('RGB').resize((512,512))<br/>def pil_to_latents(image):<br/>    '''     <br/>    Function to convert image to latents     <br/>    '''     <br/>    init_image = tfms.ToTensor()(image).unsqueeze(0) * 2.0 - 1.0   <br/>    init_image = init_image.to(device="cuda", dtype=torch.float16)<br/>    init_latent_dist = vae.encode(init_image).latent_dist.sample() * 0.18215     <br/>    return init_latent_dist  <br/>def latents_to_pil(latents):     <br/>    '''     <br/>    Function to convert latents to images     <br/>    '''     <br/>    latents = (1 / 0.18215) * latents     <br/>    with torch.no_grad():         <br/>        image = vae.decode(latents).sample     <br/>    <br/>    image = (image / 2 + 0.5).clamp(0, 1)     <br/>    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()      <br/>    images = (image * 255).round().astype("uint8")     <br/>    pil_images = [Image.fromarray(image) for image in images]        <br/>    return pil_images</span></pre><p id="60a6" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æˆ‘ä»¬ä»ç½‘ä¸Šä¸‹è½½ä¸€å¼ å›¾ç‰‡å§ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="53ce" class="nk kh iq ng b be nl nm l nn no">p = FastDownload().download('https://lafeber.com/pet-birds/wp-content/uploads/2018/06/Scarlet-Macaw-2.jpg')<br/>img = load_image(p)<br/>print(f"Dimension of this image: {np.array(img).shape}")<br/>img</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pd"><img src="../Images/d6cd14200b5f32360f829cc6da49f7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*FcVbFfR0Cdj4--FKMxFlNw.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾7:åŸé¸Ÿ<a class="ae kf" href="https://lafeber.com/pet-birds/wp-content/uploads/2018/06/Scarlet-Macaw-2.jpg" rel="noopener ugc nofollow" target="_blank"> picä¿¡ç”¨</a>ã€‚</p></figure><p id="3ca2" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨VAEç¼–ç å™¨æ¥å‹ç¼©è¿™ä¸ªå›¾åƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<code class="fe ob oc od ng b">pil_to_latents</code>è¾…åŠ©å‡½æ•°ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="6cc2" class="nk kh iq ng b be nl nm l nn no">latent_img = pil_to_latents(img)<br/>print(f"Dimension of this latent representation: {latent_img.shape}")</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pe"><img src="../Images/367c3f231281dff5df1ce2b5617ed374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rbD7ix_5EKVY9wScRl1x-g.png"/></div></div></figure><p id="1507" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æˆ‘ä»¬å¯ä»¥çœ‹åˆ°VAEæ˜¯å¦‚ä½•å°†ä¸€ä¸ª3 x 512 x 512çš„å›¾åƒå‹ç¼©æˆ4 x 64 x 64çš„å›¾åƒçš„ã€‚è¿™æ˜¯48å€çš„å‹ç¼©æ¯”ï¼è®©æˆ‘ä»¬æƒ³è±¡è¿™å››ä¸ªæ½œåœ¨è¡¨å¾çš„æ¸ é“ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="8160" class="nk kh iq ng b be nl nm l nn no">fig, axs = plt.subplots(1, 4, figsize=(16, 4))<br/>for c in range(4):<br/>    axs[c].imshow(latent_img[0][c].detach().cpu(), cmap='Greys')</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pf"><img src="../Images/946541b1bc03d099b25fd83c9af7b74a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gPRqgpdKRZlQfurR.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾8:æ¥è‡ªVAEç¼–ç å™¨çš„æ½œåœ¨è¡¨ç¤ºçš„å¯è§†åŒ–ã€‚</p></figure><p id="5e7f" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è¿™ç§æ½œåœ¨çš„è¡¨ç¤ºåœ¨ç†è®ºä¸Šåº”è¯¥æ•æ‰åˆ°å¾ˆå¤šå…³äºåŸå§‹å›¾åƒçš„ä¿¡æ¯ã€‚è®©æˆ‘ä»¬å¯¹è¿™ä¸ªè¡¨ç¤ºä½¿ç”¨è§£ç å™¨ï¼Œçœ‹çœ‹æˆ‘ä»¬å¾—åˆ°ä»€ä¹ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<code class="fe ob oc od ng b">latents_to_pil</code>åŠ©æ‰‹å‡½æ•°ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="79ec" class="nk kh iq ng b be nl nm l nn no">decoded_img = latents_to_pil(latent_img)<br/>decoded_img[0]</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/c80ebe54bdd01ca807f4ba6ff5fa1aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*p2A9QXZdlXB-aHk5.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾9:æ¥è‡ªVAEè§£ç å™¨çš„è§£ç æ½œåœ¨è¡¨ç¤ºçš„å¯è§†åŒ–ã€‚</p></figure><p id="8346" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ä»ä¸Šå›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒVAEè§£ç å™¨èƒ½å¤Ÿä»48xå‹ç¼©çš„æ½œåœ¨å›¾åƒä¸­æ¢å¤åŸå§‹å›¾åƒã€‚ä»¤äººå°è±¡æ·±åˆ»ï¼</p><blockquote class="ox oy oz"><p id="0923" class="ky kz ne la b lb mk jr ld le ml ju lg pa mm lj lk pb mn ln lo pc mo lr ls lt ij bi translated"><strong class="la ir">æ³¨æ„:</strong>å¦‚æœä½ ä»”ç»†çœ‹è§£ç å›¾åƒï¼Œå®ƒä¸åŸå§‹å›¾åƒä¸ä¸€æ ·ï¼Œæ³¨æ„çœ¼ç›å‘¨å›´çš„å·®å¼‚ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆVAEç¼–ç å™¨/è§£ç å™¨ä¸æ˜¯æ— æŸå‹ç¼©ã€‚</p></blockquote><h2 id="c65b" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">6.3ä»–ä»¬åœ¨ç¨³å®šæ‰©æ•£ç®¡é“ä¸­çš„è§’è‰²æ˜¯ä»€ä¹ˆ</h2><p id="3eec" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ç¨³å®šçš„æ‰©æ•£å¯ä»¥åœ¨æ²¡æœ‰VAEåˆ†é‡çš„æƒ…å†µä¸‹å®Œæˆï¼Œä½†æ˜¯æˆ‘ä»¬ä½¿ç”¨VAEçš„åŸå› æ˜¯ä¸ºäº†å‡å°‘ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒçš„è®¡ç®—æ—¶é—´ã€‚æ½œåœ¨æ‰©æ•£æ¨¡å‹å¯ä»¥åœ¨ç”±VAEç¼–ç å™¨äº§ç”Ÿçš„è¿™ä¸ª<em class="ne">æ½œåœ¨ç©ºé—´</em>ä¸­æ‰§è¡Œæ‰©æ•£ï¼Œå¹¶ä¸”ä¸€æ—¦æˆ‘ä»¬æœ‰äº†ç”±æ‰©æ•£è¿‡ç¨‹äº§ç”Ÿçš„æˆ‘ä»¬æœŸæœ›çš„æ½œåœ¨è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨VAEè§£ç å™¨å°†å®ƒä»¬è½¬æ¢å›é«˜åˆ†è¾¨ç‡å›¾åƒã€‚ä¸ºäº†æ›´ç›´è§‚åœ°ç†è§£å˜ä½“è‡ªåŠ¨ç¼–ç å™¨ä»¥åŠå®ƒä»¬æ˜¯å¦‚ä½•è¢«è®­ç»ƒçš„ï¼Œè¯·é˜…è¯»Irhum Shafkatçš„åšå®¢ã€‚</p><h1 id="c8fa" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">7.uç½‘æ¨¡å‹</h1><h2 id="1163" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">7.1åŸºç¡€çŸ¥è¯†â€”ä»€ä¹ˆè¿›å‡ºç»„ä»¶ï¼Ÿ</h2><p id="0fc2" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">U-Netæ¨¡å‹æ¥å—ä¸¤ä¸ªè¾“å…¥- <br/> 1ã€‚<code class="fe ob oc od ng b">Noisy latent</code>æˆ–<code class="fe ob oc od ng b">Noise</code> -å™ªå£°æ½œä¼æ˜¯ç”±VAEç¼–ç å™¨(åœ¨æä¾›åˆå§‹å›¾åƒçš„æƒ…å†µä¸‹)äº§ç”Ÿçš„å…·æœ‰é™„åŠ å™ªå£°çš„æ½œä¼ï¼Œæˆ–è€…åœ¨æˆ‘ä»¬æƒ³è¦ä»…åŸºäºæ–‡æœ¬æè¿°åˆ›å»ºéšæœºæ–°å›¾åƒçš„æƒ…å†µä¸‹ï¼Œå®ƒå¯ä»¥æ¥å—çº¯å™ªå£°è¾“å…¥<br/> 2ã€‚<code class="fe ob oc od ng b">Text embeddings</code> -åŸºäºå‰ªè¾‘çš„åµŒå…¥ç”±è¾“å…¥çš„æ–‡æœ¬æç¤ºç”Ÿæˆ</p><p id="0f5b" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">U-Netæ¨¡å‹çš„è¾“å‡ºæ˜¯è¾“å…¥å™ªå£°æ½œåŠ¿åŒ…å«çš„é¢„æµ‹å™ªå£°æ®‹å·®ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒé¢„æµ‹ä»å™ªå£°æ½œä¼æ—¶é—´ä¸­å‡å»çš„å™ªå£°ï¼Œä»¥è¿”å›åŸå§‹çš„å»å™ªå£°æ½œä¼æ—¶é—´ã€‚</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pg"><img src="../Images/55f7d11c10056f784a8a2a172dd213e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4CMZbQvwXaSjQRRX.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾10:ä¸€ä¸ªUç½‘è¡¨ç¤ºã€‚</p></figure><h2 id="e7cd" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">7.2æ›´æ·±å…¥çš„è§£é‡Šä½¿ç”¨ğŸ¤—å¯†ç </h2><p id="c0f2" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">è®©æˆ‘ä»¬é€šè¿‡ä»£ç å¼€å§‹çœ‹U-Netã€‚æˆ‘ä»¬å°†ä»å¯¼å…¥æ‰€éœ€çš„åº“å’Œå¯åŠ¨æˆ‘ä»¬çš„U-Netæ¨¡å‹å¼€å§‹ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="04b2" class="nk kh iq ng b be nl nm l nn no">from diffusers import UNet2DConditionModel, LMSDiscreteScheduler<br/>## Initializing a scheduler<br/>scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear", num_train_timesteps=1000)<br/>## Setting number of sampling steps<br/>scheduler.set_timesteps(51)<br/>## Initializing the U-Net model<br/>unet = UNet2DConditionModel.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="unet", torch_dtype=torch.float16).to("cuda")</span></pre><p id="18c5" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ‚¨å¯èƒ½å·²ç»ä»ä¸Šé¢çš„ä»£ç ä¸­æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬ä¸ä»…å¯¼å…¥äº†<code class="fe ob oc od ng b">unet</code>ï¼Œè¿˜å¯¼å…¥äº†<code class="fe ob oc od ng b">scheduler</code>ã€‚<code class="fe ob oc od ng b">schedular</code>çš„ç›®çš„æ˜¯ç¡®å®šåœ¨æ‰©æ•£è¿‡ç¨‹çš„ç»™å®šæ­¥éª¤ä¸­æœ‰å¤šå°‘å™ªå£°æ·»åŠ åˆ°æ½œåœ¨å™ªå£°ä¸­ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹schedularå‡½æ•°</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/852e20bb88c7491d3a15e4d41b57eada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/0*plvYlrxI8jw34z9g.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾11:é‡‡æ ·è®¡åˆ’å¯è§†åŒ–ã€‚</p></figure><p id="465c" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ‰©æ•£è¿‡ç¨‹éµå¾ªè¿™ä¸ªé‡‡æ ·æ—¶é—´è¡¨ï¼Œæˆ‘ä»¬ä»é«˜å™ªå£°å¼€å§‹ï¼Œå¹¶é€æ¸å¯¹å›¾åƒå»å™ªã€‚è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹è¿™ä¸ªè¿‡ç¨‹-</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="e5ac" class="nk kh iq ng b be nl nm l nn no">noise = torch.randn_like(latent_img) # Random noise<br/>fig, axs = plt.subplots(2, 3, figsize=(16, 12))<br/>for c, sampling_step in enumerate(range(0,51,10)):<br/>    encoded_and_noised = scheduler.add_noise(latent_img, noise, timesteps=torch.tensor([scheduler.timesteps[sampling_step]]))<br/>    axs[c//3][c%3].imshow(latents_to_pil(encoded_and_noised)[0])<br/>    axs[c//3][c%3].set_title(f"Step - {sampling_step}")</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pi"><img src="../Images/11b44c411c1f90ff486c80bfcfdd7736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KczbjUFsEQRXlA5h.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾12:é€šè¿‡æ­¥éª¤çš„å™ªå£°è¿›å±•ã€‚</p></figure><p id="c970" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬çœ‹çœ‹U-Netæ˜¯å¦‚ä½•å»é™¤å›¾åƒä¸­çš„å™ªå£°çš„ã€‚è®©æˆ‘ä»¬ä»ç»™å›¾åƒæ·»åŠ ä¸€äº›å™ªå£°å¼€å§‹ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="e1d3" class="nk kh iq ng b be nl nm l nn no">encoded_and_noised = scheduler.add_noise(latent_img, noise, timesteps=torch.tensor([scheduler.timesteps[40]])) latents_to_pil(encoded_and_noised)[0]</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/f7c4518900d640351a388fec8c634879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*lHl3YGQ28Ge07ToY.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾13:é¦ˆå…¥U-Netçš„å™ªå£°è¾“å…¥ã€‚</p></figure><p id="fed4" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬æµè§ˆä¸€ä¸‹U-Netï¼Œè¯•ç€å»å™ªè¿™ä¸ªå›¾åƒã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="0bbd" class="nk kh iq ng b be nl nm l nn no">## Unconditional textual prompt<br/>prompt = [""]<br/>## Using clip model to get embeddings<br/>text_input = tokenizer(prompt, padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt")<br/>with torch.no_grad(): <br/>    text_embeddings = text_encoder(<br/>        text_input.input_ids.to("cuda")<br/>    )[0]<br/>    <br/>## Using U-Net to predict noise    <br/>latent_model_input = torch.cat([encoded_and_noised.to("cuda").float()]).half()<br/>with torch.no_grad():<br/>    noise_pred = unet(<br/>        latent_model_input,40,encoder_hidden_states=text_embeddings<br/>    )["sample"]<br/>## Visualize after subtracting noise <br/>latents_to_pil(encoded_and_noised- noise_pred)[0]</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/059bca6fe75c5b5dd9a27eb8b3ed11b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*egUdeUd-AoR_LwyF.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾14:æ¥è‡ªU-Netçš„å»å™ªå£°è¾“å‡º</p></figure><p id="16fa" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šé¢çœ‹åˆ°çš„ï¼ŒU-Netçš„è¾“å‡ºæ¯”é€šè¿‡çš„åŸå§‹å™ªå£°è¾“å…¥æ›´æ¸…æ™°ã€‚</p><h2 id="9f3c" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">7.3ä»–ä»¬åœ¨ç¨³å®šæ‰©æ•£ç®¡é“ä¸­çš„è§’è‰²æ˜¯ä»€ä¹ˆ</h2><p id="213f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">æ½œåœ¨æ‰©æ•£ä½¿ç”¨U-Neté€šè¿‡å‡ ä¸ªæ­¥éª¤é€æ¸å‡å»æ½œåœ¨ç©ºé—´ä¸­çš„å™ªå£°ï¼Œä»¥è¾¾åˆ°æ‰€éœ€çš„è¾“å‡ºã€‚æ¯èµ°ä¸€æ­¥ï¼Œæ·»åŠ åˆ°å»¶è¿Ÿä¸­çš„å™ªå£°é‡å°±ä¼šå‡å°‘ï¼Œç›´åˆ°æˆ‘ä»¬å¾—åˆ°æœ€ç»ˆçš„å»å™ªè¾“å‡ºã€‚u-ç½‘æœ€åˆæ˜¯ç”±<a class="ae kf" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">æœ¬æ–‡</a>ä»‹ç»çš„ï¼Œç”¨äºç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚U-Netå…·æœ‰ç”±ResNetå—ç»„æˆçš„ç¼–ç å™¨å’Œè§£ç å™¨ã€‚ç¨³å®šæ‰©æ•£U-Netè¿˜å…·æœ‰äº¤å‰æ³¨æ„å±‚ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿæ ¹æ®æ‰€æä¾›çš„æ–‡æœ¬æè¿°æ¥è°ƒèŠ‚è¾“å‡ºã€‚äº¤å‰æ³¨æ„å±‚é€šå¸¸åœ¨ResNetå—ä¹‹é—´è¢«æ·»åŠ åˆ°U-Netçš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†ã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œäº†è§£æ›´å¤šå…³äºè¿™ä¸ªU-Netæ¶æ„<a class="ae kf" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb#scrollTo=wW8o1Wp0zRkq" rel="noopener ugc nofollow" target="_blank">çš„ä¿¡æ¯ã€‚</a></p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="5d4a" class="kg kh iq bd ki kj nw kl km kn nx kp kq jw ny jx ks jz nz ka ku kc oa kd kw kx bi translated">8.æŠŠæ‰€æœ‰ä¸œè¥¿æ”¾åœ¨ä¸€èµ·ï¼Œç†è§£æ‰©æ•£è¿‡ç¨‹</h1><p id="8c67" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘å±•ç¤ºäº†å¦‚ä½•å®‰è£…ğŸ¤—æ‰©æ•£å™¨åº“å¼€å§‹ç”Ÿæˆæ‚¨è‡ªå·±çš„äººå·¥æ™ºèƒ½å›¾åƒå’Œç¨³å®šæ‰©æ•£ç®¡é“çš„å…³é”®ç»„ä»¶ï¼Œå³å‰ªè¾‘æ–‡æœ¬ç¼–ç å™¨ï¼ŒVAEå’ŒU-Netã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†å°è¯•æŠŠè¿™äº›å…³é”®éƒ¨åˆ†æ”¾åœ¨ä¸€èµ·ï¼Œå¹¶åšä¸€ä¸ªäº§ç”Ÿå›¾åƒçš„æ‰©æ•£è¿‡ç¨‹çš„æ¼”ç»ƒã€‚</p><h2 id="f00c" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">8.1æ¦‚è¿°-æ‰©æ•£è¿‡ç¨‹</h2><p id="26db" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">ç¨³å®šæ‰©æ•£æ¨¡å‹é‡‡ç”¨æ–‡æœ¬è¾“å…¥å’Œç§å­ã€‚æ–‡æœ¬è¾“å…¥ç„¶åé€šè¿‡å‰ªè¾‘æ¨¡å‹ä»¥ç”Ÿæˆå¤§å°ä¸º77Ã—768çš„æ–‡æœ¬åµŒå…¥ï¼Œå¹¶ä¸”ç§å­ç”¨äºç”Ÿæˆå¤§å°ä¸º4Ã—64Ã—64çš„é«˜æ–¯å™ªå£°ï¼Œè¯¥é«˜æ–¯å™ªå£°æˆä¸ºç¬¬ä¸€æ½œåƒè¡¨ç¤ºã€‚</p><blockquote class="ox oy oz"><p id="323d" class="ky kz ne la b lb mk jr ld le ml ju lg pa mm lj lk pb mn ln lo pc mo lr ls lt ij bi translated">æ³¨æ„â€”æ‚¨ä¼šæ³¨æ„åˆ°åœ¨å›¾åƒä¸­æåˆ°äº†ä¸€ä¸ªé¢å¤–çš„ç»´åº¦(1x ),å¦‚ç”¨äºæ–‡æœ¬åµŒå…¥çš„1x77x768ï¼Œè¿™æ˜¯å› ä¸ºå®ƒè¡¨ç¤ºæ‰¹é‡å¤§å°ä¸º1ã€‚</p></blockquote><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi pj"><img src="../Images/362376c3b3cc955e6090b8888258a9d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z5eQUBRBVtgD3Vgv.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾15:æ‰©æ•£è¿‡ç¨‹ã€‚</p></figure><p id="7dd2" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">æ¥ä¸‹æ¥ï¼ŒU-Netè¿­ä»£åœ°å»é™¤éšæœºæ½œåƒè¡¨ç¤ºçš„å™ªå£°ï¼ŒåŒæ—¶ä»¥æ–‡æœ¬åµŒå…¥ä¸ºæ¡ä»¶ã€‚U-Netçš„è¾“å‡ºæ˜¯é¢„æµ‹çš„å™ªå£°æ®‹å·®ï¼Œè¯¥å™ªå£°æ®‹å·®ç„¶åè¢«ç”¨äºé€šè¿‡è°ƒåº¦å™¨ç®—æ³•æ¥è®¡ç®—æ¡ä»¶å»¶è¿Ÿã€‚è¿™ä¸ªå»å™ªå’Œæ–‡æœ¬è°ƒèŠ‚çš„è¿‡ç¨‹é‡å¤Næ¬¡(æˆ‘ä»¬å°†ä½¿ç”¨50æ¬¡)ä»¥æ£€ç´¢æ›´å¥½çš„æ½œåƒè¡¨ç¤ºã€‚ä¸€æ—¦è¯¥è¿‡ç¨‹å®Œæˆï¼Œæ½œåƒè¡¨ç¤º(4x64x64)ç”±VAEè§£ç å™¨è§£ç ï¼Œä»¥æ£€ç´¢æœ€ç»ˆçš„è¾“å‡ºå›¾åƒ(3x512x512)ã€‚</p><blockquote class="ox oy oz"><p id="2898" class="ky kz ne la b lb mk jr ld le ml ju lg pa mm lj lk pb mn ln lo pc mo lr ls lt ij bi translated">æ³¨æ„â€”â€”è¿™ç§è¿­ä»£å»å™ªæ˜¯è·å¾—è‰¯å¥½è¾“å‡ºå›¾åƒçš„é‡è¦æ­¥éª¤ã€‚å…¸å‹çš„æ­¥é•¿èŒƒå›´æ˜¯30â€“80ã€‚ç„¶è€Œï¼Œæœ‰<a class="ae kf" href="https://arxiv.org/abs/2202.00512" rel="noopener ugc nofollow" target="_blank">æœ€è¿‘çš„è®ºæ–‡</a>å£°ç§°é€šè¿‡ä½¿ç”¨è’¸é¦æŠ€æœ¯å°†å…¶å‡å°‘åˆ°4-5æ­¥ã€‚</p></blockquote><h2 id="1021" class="of kh iq bd ki og oh dn km oi oj dp kq lh ok ol ks ll om on ku lp oo op kw oq bi translated">8.2é€šè¿‡ä»£ç ç†è§£æ‰©æ•£è¿‡ç¨‹</h2><p id="cd88" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">è®©æˆ‘ä»¬ä»å¯¼å…¥æ‰€éœ€çš„åº“å’ŒåŠ©æ‰‹å‡½æ•°å¼€å§‹ã€‚ä¸Šé¢å·²ç»è§£é‡Šäº†æ‰€æœ‰è¿™äº›ã€‚</p><p id="4659" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="la ir"> <em class="ne">æ³¨æ„â€” </em> </strong> <em class="ne">ä¸ºäº†ç”¨ä»£ç æ­£ç¡®åœ°æ¸²æŸ“è¿™äº›å†…å®¹ï¼Œæˆ‘æ¨èä½ åœ¨è¿™é‡Œé˜…è¯»</em> <a class="ae kf" href="https://aayushmnit.com/posts/2022-11-07-StableDiffusionP3/2022-11-07-StableDiffusionP3.html" rel="noopener ugc nofollow" target="_blank"> <em class="ne">ã€‚</em> </a></p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="5cbd" class="nk kh iq ng b be nl nm l nn no">import torch, logging<br/>## disable warnings<br/>logging.disable(logging.WARNING)  <br/>## Imaging  library<br/>from PIL import Image<br/>from torchvision import transforms as tfms<br/>## Basic libraries<br/>import numpy as np<br/>from tqdm.auto import tqdm<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>from IPython.display import display<br/>import shutil<br/>import os<br/>## For video display<br/>from IPython.display import HTML<br/>from base64 import b64encode<br/><br/>## Import the CLIP artifacts <br/>from transformers import CLIPTextModel, CLIPTokenizer<br/>from diffusers import AutoencoderKL, UNet2DConditionModel, LMSDiscreteScheduler<br/>## Initiating tokenizer and encoder.<br/>tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16)<br/>text_encoder = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14", torch_dtype=torch.float16).to("cuda")<br/>## Initiating the VAE<br/>vae = AutoencoderKL.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="vae", torch_dtype=torch.float16).to("cuda")<br/>## Initializing a scheduler and Setting number of sampling steps<br/>scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear", num_train_timesteps=1000)<br/>scheduler.set_timesteps(50)<br/>## Initializing the U-Net model<br/>unet = UNet2DConditionModel.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="unet", torch_dtype=torch.float16).to("cuda")<br/>## Helper functions<br/>def load_image(p):<br/>    '''<br/>    Function to load images from a defined path<br/>    '''<br/>    return Image.open(p).convert('RGB').resize((512,512))<br/>def pil_to_latents(image):<br/>    '''<br/>    Function to convert image to latents<br/>    '''<br/>    init_image = tfms.ToTensor()(image).unsqueeze(0) * 2.0 - 1.0<br/>    init_image = init_image.to(device="cuda", dtype=torch.float16) <br/>    init_latent_dist = vae.encode(init_image).latent_dist.sample() * 0.18215<br/>    return init_latent_dist<br/>def latents_to_pil(latents):<br/>    '''<br/>    Function to convert latents to images<br/>    '''<br/>    latents = (1 / 0.18215) * latents<br/>    with torch.no_grad():<br/>        image = vae.decode(latents).sample<br/>    image = (image / 2 + 0.5).clamp(0, 1)<br/>    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()<br/>    images = (image * 255).round().astype("uint8")<br/>    pil_images = [Image.fromarray(image) for image in images]<br/>    return pil_images<br/>def text_enc(prompts, maxlen=None):<br/>    '''<br/>    A function to take a texual promt and convert it into embeddings<br/>    '''<br/>    if maxlen is None: maxlen = tokenizer.model_max_length<br/>    inp = tokenizer(prompts, padding="max_length", max_length=maxlen, truncation=True, return_tensors="pt") <br/>    return text_encoder(inp.input_ids.to("cuda"))[0].half()</span></pre><p id="c941" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">ä¸‹é¢çš„ä»£ç æ˜¯<code class="fe ob oc od ng b"><a class="ae kf" href="https://github.com/huggingface/diffusers/blob/269109dbfbbdbe2800535239b881e96e1828a0ef/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py" rel="noopener ugc nofollow" target="_blank">StableDiffusionPipeline.from_pretrained</a></code>å‡½æ•°ä¸­çš„ç²¾ç®€ç‰ˆæœ¬ï¼Œæ˜¾ç¤ºäº†æ‰©æ•£è¿‡ç¨‹çš„é‡è¦éƒ¨åˆ†ã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="8c63" class="nk kh iq ng b be nl nm l nn no">def prompt_2_img(prompts, g=7.5, seed=100, steps=70, dim=512, save_int=False):<br/>    """<br/>    Diffusion process to convert prompt to image<br/>    """<br/>    <br/>    # Defining batch size<br/>    bs = len(prompts) <br/>    <br/>    # Converting textual prompts to embedding<br/>    text = text_enc(prompts) <br/>    <br/>    # Adding an unconditional prompt , helps in the generation process<br/>    uncond =  text_enc([""] * bs, text.shape[1])<br/>    emb = torch.cat([uncond, text])<br/>    <br/>    # Setting the seed<br/>    if seed: torch.manual_seed(seed)<br/>    <br/>    # Initiating random noise<br/>    latents = torch.randn((bs, unet.in_channels, dim//8, dim//8))<br/>    <br/>    # Setting number of steps in scheduler<br/>    scheduler.set_timesteps(steps)<br/>    <br/>    # Adding noise to the latents <br/>    latents = latents.to("cuda").half() * scheduler.init_noise_sigma<br/>    <br/>    # Iterating through defined steps<br/>    for i,ts in enumerate(tqdm(scheduler.timesteps)):<br/>        # We need to scale the i/p latents to match the variance<br/>        inp = scheduler.scale_model_input(torch.cat([latents] * 2), ts)<br/>        <br/>        # Predicting noise residual using U-Net<br/>        with torch.no_grad(): u,t = unet(inp, ts, encoder_hidden_states=emb).sample.chunk(2)<br/>            <br/>        # Performing Guidance<br/>        pred = u + g*(t-u)<br/>        <br/>        # Conditioning  the latents<br/>        latents = scheduler.step(pred, ts, latents).prev_sample<br/>        <br/>        # Saving intermediate images<br/>        if save_int: <br/>            if not os.path.exists(f'./steps'):<br/>                os.mkdir(f'./steps')<br/>            latents_to_pil(latents)[0].save(f'steps/{i:04}.jpeg')<br/>            <br/>    # Returning the latent representation to output an image of 3x512x512<br/>    return latents_to_pil(latents)</span></pre><p id="e958" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå‡½æ•°æ˜¯å¦å¦‚é¢„æœŸçš„é‚£æ ·å·¥ä½œã€‚</p><pre class="lv lw lx ly gt nf ng nh bn ni nj bi"><span id="3b47" class="nk kh iq ng b be nl nm l nn no">images = prompt_2_img(["A dog wearing a hat", "a photograph of an astronaut riding a horse"], save_int=False)<br/>for img in images:display(img)</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/e6a8a3f547d68fb7e7f05cf6325c728f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*mUmPjuPxYcONUhCp.png"/></div></figure><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6484f7b8384838451dd60696dd9507cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*UOs9da2t6TV6WFfD.png"/></div></figure><p id="0343" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">çœ‹èµ·æ¥å®ƒæ­£åœ¨å·¥ä½œï¼å› æ­¤ï¼Œè®©æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£è¯¥å‡½æ•°çš„è¶…å‚æ•°ã€‚<br/> 1ã€‚<code class="fe ob oc od ng b">prompt</code> -è¿™æ˜¯æˆ‘ä»¬ç”¨æ¥ç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤ºã€‚ç±»ä¼¼äºæˆ‘ä»¬åœ¨ç¬¬1éƒ¨åˆ†<br/> 2ä¸­çœ‹åˆ°çš„<code class="fe ob oc od ng b">pipe(prompt)</code>å‡½æ•°ã€‚<code class="fe ob oc od ng b">g</code>æˆ–<code class="fe ob oc od ng b">guidance scale</code>â€”â€”è¿™æ˜¯ä¸€ä¸ªå†³å®šå›¾åƒåº”è¯¥å¤šæ¥è¿‘æ–‡æœ¬æç¤ºçš„å€¼ã€‚è¿™ä¸ä¸€ç§åä¸º<a class="ae kf" href="https://benanne.github.io/2022/05/26/guidance.html" rel="noopener ugc nofollow" target="_blank">åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼</a>çš„æŠ€æœ¯æœ‰å…³ï¼Œè¯¥æŠ€æœ¯æé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚æŒ‡å¯¼æ¯”ä¾‹å€¼è¶Šé«˜ï¼Œè¶Šæ¥è¿‘æ–‡æœ¬æç¤º<br/> 3ã€‚<code class="fe ob oc od ng b">seed</code> -è®¾ç½®ç”Ÿæˆåˆå§‹é«˜æ–¯å™ªå£°æ½œä¼æ—¶é—´çš„ç§å­<br/> 4ã€‚<code class="fe ob oc od ng b">steps</code> -ç”Ÿæˆæœ€ç»ˆå»¶è¿Ÿæ‰€é‡‡å–çš„å»å™ªæ­¥éª¤æ•°ã€‚<br/> 5ã€‚<code class="fe ob oc od ng b">dim</code> -å›¾åƒçš„å°ºå¯¸ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›®å‰æ­£åœ¨ç”Ÿæˆæ­£æ–¹å½¢å›¾åƒï¼Œå› æ­¤åªéœ€è¦ä¸€ä¸ªå€¼<br/> 6ã€‚<code class="fe ob oc od ng b">save_int</code> -è¿™æ˜¯å¯é€‰çš„ï¼Œä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ä¿å­˜ä¸­é—´æ½œåƒï¼Œæœ‰åŠ©äºå¯è§†åŒ–ã€‚</p><p id="63a9" class="pw-post-body-paragraph ky kz iq la b lb mk jr ld le ml ju lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹ä»å™ªå£°åˆ°æœ€ç»ˆå›¾åƒçš„ç”Ÿæˆè¿‡ç¨‹ã€‚</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/dbbea614dfa77bacb682ed9137fe4d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*sRMNCDKvviQwRrNa.gif"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾16:å»å™ªæ­¥éª¤å¯è§†åŒ–ã€‚</p></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="853c" class="kg kh iq bd ki kj nw kl km kn nx kp kq jw ny jx ks jz nz ka ku kc oa kd kw kx bi translated">9.ç»“è®º</h1><p id="4804" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">æˆ‘å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»å®ƒï¼Œå¹¶éšæ—¶ä½¿ç”¨æˆ‘çš„ä»£ç ï¼Œå¹¶å°è¯•ç”Ÿæˆæ‚¨çš„å›¾åƒã€‚æ­¤å¤–ï¼Œå¦‚æœå¯¹ä»£ç æˆ–åšå®¢å¸–å­æœ‰ä»»ä½•åé¦ˆï¼Œè¯·éšæ—¶è”ç³»LinkedInæˆ–ç»™æˆ‘å‘ç”µå­é‚®ä»¶ï¼Œåœ°å€æ˜¯aayushmnit@gmail.comã€‚</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="7a24" class="kg kh iq bd ki kj nw kl km kn nx kp kq jw ny jx ks jz nz ka ku kc oa kd kw kx bi translated">10.å‚è€ƒ</h1><ul class=""><li id="5d82" class="mp mq iq la b lb lc le lf lh pk ll pl lp pm lt pn mv mw mx bi translated"><a class="ae kf" href="https://www.fast.ai/posts/part2-2022-preview.html" rel="noopener ugc nofollow" target="_blank"> Fast.aiè¯¾ç¨‹â€”â€”ã€Šä»æ·±åº¦å­¦ä¹ åŸºç¡€åˆ°ç¨³å®šæ‰©æ•£ã€‹å‰ä¸¤èŠ‚</a></li><li id="9a9f" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt pn mv mw mx bi translated"><a class="ae kf" href="https://huggingface.co/blog/stable_diffusion" rel="noopener ugc nofollow" target="_blank">ğŸ§¨æ‰©æ•£å™¨çš„ç¨³å®šæ‰©æ•£</a></li><li id="7dc8" class="mp mq iq la b lb my le mz lh na ll nb lp nc lt pn mv mw mx bi translated"><a class="ae kf" href="https://bipinkrishnan.github.io/posts/getting-started-in-the-world-of-stable-diffusion/" rel="noopener ugc nofollow" target="_blank">ç¨³å®šæ‰©æ•£ä¸–ç•Œå…¥é—¨</a></li></ul></div></div>    
</body>
</html>